[
{
	"uri": "/about-this-site/",
	"title": "About This Site",
	"tags": [],
	"description": "",
	"content": "  This section to techniques for graphics and analyses, including:\n how to organise your data during data entry how to manipulate and manage your data so there is transparency and version control instructions for running statistical analyses with sample code in R or other relevant software (first see Getting started with R) the rationale for the technique in plain language (why is it used) how to interpret the results and assumptions that you need to check visualisation of your results and ways to effectively communicate the results in scientific reports or publications where to go for further help  This site integrates different techniques used by researchers and postgraduates at the University of New South Wales, Australia, who have provided their knowledge and skills to assist others develop skills for rigorous environmental science.\nSome resources were developed initially to assist with teaching quantitative skills to undergraduate and postgraduate students in the School of Biological, Earth and Environmental Sciences at the University of New South Wales, supported by a Learning and Teaching Innovation Grant to Associate Professor Alistair Poore, Dr Will Cornwell, Professor Iain Suthers and Professor Richard Kingsford.\nSite administrators:\nAssociate Professor Alistair Poore\nAssociate Professor Will Cornwell\nPage authors: Keryn Bain, Rachel Blakey, Stephanie Brodie, Corey Callaghan, Will Cornwell, Kingsley Griffin, Matt Holland, James Lavender, Andrew Letten, Shinichi Nakagawa, Shaun Nielsen, Alistair Poore, Gordana Popovic, Fiona Robinson and Jakub Stoklosa.\nLast updated:\n## [1] \u0026quot;Tue Jan 18 17:45:49 2022\u0026quot; "
},
{
	"uri": "/getting-started-with-r/",
	"title": "Getting Started with R",
	"tags": [],
	"description": "",
	"content": "  Throughout this site, instructions for statistical analyses, data management and graphical techniques are provided in the software language R. R is a free, open source language that has rapidly become standard usage in the biological and environmental sciences. Apart from the cost, the language has the benefits of being able to explicitly share methods with colleague, and a very active community of people who are developing packages that will run very many types of analyses and graphics.\nBefore you get started with making graphics and doing analyses, you will need to:\n Install R and learn the basics of using R\n Think about project management to plan how you are going to organise your files   Data entry After collecting data, being able to enter those data and import into various software packages are obviously essential skills for students and researchers in the environmental sciences. You might think that you just write the numbers in a spreadsheet package and open that file in another piece of software, but there is actually quite a bit to be learnt about tidy ways to enter the data and import that data without errors.\nOn these pages, we give some guidance for data entry that will save a lot of time when it comes to analysing data and making effective figures. We also describe the types and structure of data objects in R that you will see once you have imported your data.\n Data entry - organising data when first entering it into a spreadsheet.\n Importing data into R\n Data types and structure - better understanding data objects in R   Further help \nThe British Ecological Society’s Guide to Data Management in Ecology and Evolution Author: Alistair Poore Last updated:\n## [1] \u0026quot;Tue Jan 18 17:46:01 2022\u0026quot;  "
},
{
	"uri": "/getting-started-with-r/installing_r_rstudio/",
	"title": "Installing R and R Studio",
	"tags": [],
	"description": "",
	"content": "  \nWe recommend using R Studio as a user friendly interface for using R.\nFirst, install the latest version of R - download from here\nSecond, install the latest version of R Studio - download from here Setting the working directory \nOnce you have installed R and R Studio, you need to set the working directory. This is the location on your computer where any data files to imported can be found, and where any R scripts (the files that save your code) will be saved.\nIn R studio, you can set the working directory with the menus (Session \u0026gt;\u0026gt; Set Working Directory \u0026gt;\u0026gt; Choose Directory) or with a line of code that gives the path of the folder on your computer:\nsetwd(\u0026quot;Drive:/Folder1/Folder2\u0026quot;) If you are working with any of the example data files on this site, you will first need to download them to a folder on your computer and specify that folder as the working directory.  The layout of R Studio \nR Studio has four panels:\nThe top left panel is the editor (or script window) you can view your R script. Running code from here is a simple as Ctrl+Enter when the cursor is on the line or lines of code that you want to execute.\nThe bottom left panel is the console (or command window) where you can also run lines of code (write code next to \u0026gt; and press Enter), but also where any text or numerical output will appear.\nThe top right is the workspace window that lists the various R objects that you are currently using. These can be data sets or objects created by various analyses.\nThe panel on the bottom right has: lists of the files in your working directory the R packages that you are currently using any graphical output in the Plots window help files (accessed by ? preceding any bit of code)\nYou can change the size of these by dragging the edges of the windows.  Saving your code in a script \nYou should save all the code you use for a given analysis or graphic. Use the menus in R Studio to create a new R script (File \u0026gt;\u0026gt; New \u0026gt;\u0026gt; R script) and save that with the disk icon or menu (File \u0026gt;\u0026gt; Save). See Good practice for writing scripts for advice on how to structure these files.  Installing R packages \nIf your required analyses or graphics need a package that is not in the initial installation of R, then new packages can be installed from the menus (Tools \u0026gt;\u0026gt; Install packages) or from the panel on the bottom right. Once installed, they can be loaded with the library function (recommended) or by ticking the little box next to the package name (not recommended). It is better practice to use the library function in your script as that will remind you what packages need to be loaded.\nFor example, this code will load the package maptools if it is installed on your computer.\nlibrary(maptools) \n Further help \nOur help modules on Good practice for writing scripts and Importing data and data cleaning\nOnline help with R Studio\nOnline training in R Author: Alistair Poore Last updated:\n## [1] \u0026quot;Tue Jan 18 17:46:13 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/making_new_variables/",
	"title": "Making New Variables",
	"tags": [],
	"description": "",
	"content": "  Being able to make new variables from those already in your data set is an essential skill for data manipulation prior to making graphs or doing analyses. These new variables could be a transformed variable that you would like to analyse, a new variable that is a function of existing ones, or a new set of labels for your samples.\nTo demonstrate a few of the commonly used functions in R for doing this, let’s consider a data set on the feeding specificity of marine herbivores on five species of macroalgae. Twenty replicate individuals of each of seven species of macroalgae were collected from Sydney Harbour, and the abundance of seven species of herbivorous crustacean recorded from each replicate sample (data from Poore et al. 2000).\nDownload the data set, Herbivore_specialisation.csv, and load into R.\nHerbivores \u0026lt;- read.csv(file = \u0026quot;Making new variables/Herbivore_specialisation.csv\u0026quot;, header = TRUE) The first two columns are categorical variables that label the samples as coming from each of the five habitats or as being collected during the day or the night. The third column is the replicate number per combination of habitat and day/night. The fourth column is the biomass of the habitat sampled and the rest of the columns are the counts of each herbivore species in each sample. Adding a new variable \nAdding a new variable to an existing data frame can be done by assigning the outcome of a given function to a new variable name in the following fashion.\nHerbivores$log_Mass \u0026lt;- log(Herbivores$Mass) Herbivores$Ampithoe \u0026lt;- Herbivores$Ampithoe_caddi + Herbivores$Ampithoe_kava + Herbivores$Ampithoe_ngana The first line creates a new variable called log_Mass which is the log of the variable Mass from the Herbivores data frame.\nThe second line creates a new variable called Ampithoe which is the sum of the abundances for each of the three species of Ampithoe in the data set.\nHaving to reference both the data frame and the variable name in these expressions can get pretty messy, so we recommend using functions from the package dplyr which allow us to just use variable names. First, load the package:\nlibrary(dplyr) The function mutate is then used to create new variables. To achieve the same result as the above code, we would use:\nHerbivores \u0026lt;- mutate(Herbivores, log_Mass = log(Mass)) Herbivores \u0026lt;- mutate(Herbivores, Ampithoe = Ampithoe_caddi + Ampithoe_kava + Ampithoe_ngana) Even neater is to run several things at once. We could create both of those new variables and many others with single block of code. For example:\nHerbivores \u0026lt;- mutate(Herbivores, log_Mass = log(Mass), # log of Mass Ampithoe = Ampithoe_caddi + Ampithoe_kava + Ampithoe_ngana, # sum of three columns Total_abundance = rowSums(Herbivores[,5:12]), # sum of columns 5-12 with all abundance data Total_abundance_perGram = Total_abundance/Mass # abundance as numbers per g of habitat ) The arguments of mutate are simply the name of the data frame followed by any number of expressions that create new variables.\nIn the above examples, note that the new variables have been added to the existing data frame, and all old variables have been kept. You can use transmute if you want to drop the original variables.\nThese functions become especially powerful when combined with some of the others in dplyr. See our pages on subsetting and summarising data.  Renaming a variable \ndplyr offers a straightforward function, rename, to change the name of any variable. For example, to change Mass to Biomass, we simply use:\nHerbivores \u0026lt;- rename(Herbivores, Biomass = Mass) \n Uniting several columns into one \nCombining the content of several columns into a single column can be useful to provide a different set of labels for rows in your data set, or new levels of a categorical variable that you may want to use in graphs. The function unite in the package tidyr allows us to do this very easily. First, install and load this package into R.\nlibrary(tidyr) If we wanted to make a new categorical variable where each level was the unique combination of habitat and day/night, we would use:\nHerbivores \u0026lt;- unite(Herbivores, \u0026quot;Habitat_DayNight\u0026quot;, c(Habitat, DayNight), sep=\u0026quot;_\u0026quot;) The arguments of unite' are: * the data frame to be used (in this case Herbivores) * the name of the new variable (in this case \"Habitat_DayNight\") * the columns to be united, withinc()` * the character used to separate the values in each column being united (in this case “_“)\nView the data frame again and you will notice the new variable, and the fact that the old ones have been removed. It is a better idea to keep them, by adding remove=FALSE\nHerbivores \u0026lt;- unite(Herbivores, \u0026quot;Habitat_DayNight\u0026quot;, c(Habitat, DayNight), sep=\u0026quot;_\u0026quot;, remove=FALSE) \n Separating one column into several \nSeparating content from one column into several separate variables is also very useful if the levels of categorical variables in the original data set are actually combinations of more than one variable. The function separate in tidyr does this.\nFor example, if we wanted to contrast the abundance of herbivores among the genera of algae being used as habitat (rather than individual species), we would need to make a new variable that held only the genus names. We can use separate to make two new columns, one for genus and one for species, from the values in the Habitat variable.\nHerbivores \u0026lt;- separate(Herbivores, Habitat, c(\u0026quot;Genus\u0026quot;,\u0026quot;species\u0026quot;), sep=\u0026quot;_\u0026quot;, remove=FALSE) The arguments of separate' are: * the data frame to be used (in this case Herbivores) * the name of the new variable to be separated (in this case \"Habitat\") * the names of the new variables, withinc()(in this case \"Genus\" and \"species\") * the character used to separate the values in the column being separated (in this case \"_\") * theremove=FALSE` means we keep the variable being separated in the new version of the data frame\nNote that this was only possible because there was a character separating the two variables in the text of the one to be separated (e.g., we couldn’t do this is if the species names in the Habitat variable were originally GenusSpecies, rather than Genus_species).  Further help \nType ?mutate, ?unite, and ?separate for the R help for these functions.\nData wrangling with dplyr and tidyr cheat sheet produced by Rstudio. Some images above were sourced from this document.\nIntroducing tidyr Author: Alistair Poore Last updated:\n## [1] \u0026quot;Tue Jan 18 17:45:59 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/",
	"title": "Data Manipulation",
	"tags": [],
	"description": "",
	"content": "  Having skills in organising and summarising data is crucial for students and researchers in all sciences. On these pages, we give some guidance for manipulating data in ways that can save a lot of time when it comes to analysing data and making effective figures.\nData manipulation using the packages dplyr, tidyr and reshape2.\n Making new variables Subsetting data - selecting rows and columns\n Summarising data - extracting summary statistics\n Combining data sets - joining entire data sets, or parts by matching rows Reshaping data between wide and long formats\n  ###Further help The British Ecological Society’s Guide to Data Management in Ecology and Evolution Author: Alistair Poore Last updated:\n## [1] \u0026quot;Tue Jan 18 17:45:55 2022\u0026quot; "
},
{
	"uri": "/getting-started-with-r/project_managment/",
	"title": "Basic Project Management",
	"tags": [],
	"description": "",
	"content": "  Having your data files, R scripts and outputs organised is very helpful for keeping track of what you are working on and for sharing data or scripts with colleagues or supervisors. Try and avoid a folder on your computer that is a big mix of spreadsheets, images, word processing documents etc. How you organise your files is your choice, but a little bit of planning and project organization at the beginning will pay lots of dividends down the road. Here are our suggestions for keeping your projects neatly organised.\nSetting up an organised project folder \nCreate a folder on your computer for each project. This could be a course you are currently doing, a chapter of your thesis or a research project of any kind. Within that folder, include the following things:\n A data folder (including meta-data) An outputs folder (with subfolders “Figures” and “Tables” and possibly “Supplementary Material”) An R script that will run the data manipulation, analyses and create figures required for the project (try to keep this R script short and readable) A folder for R functions (if used) usually called “R” A folder for writing and references called “Manuscripts”  The data folder should hold the raw data (usually entered in a spreadsheet program). After you finish entering your data, you should aim to keep these data untouched; all the things you want to do with the data, such as data cleaning and subsetting, summarising data into table, running statistical analyses or creating figures, can be done via R scripts. This keeps a record of everything you do. Think of this script(s) as the lab notebook for a data scientist. Intermediate outputs are good–separate these from the raw data and save them in the outputs folder.\nOne goal of this project organization is that your data processing and analysis is entirely reproducible, and as such both the data and exact methods can be shared with colleagues and supervisors, who can then repeat and hopefully build on your analyses. Also, although you might know all the files and steps at the moment, think of yourself in a year once you’ve moved on to other jobs or projects; try to be nice to your future self and keep good notes. In contrast, if you used a point–and–click or spreadsheet program to do important steps in your analysis, you’ll need to remember all the steps taken to recreate the analyses or figures. Most analyses at some point get too complicated for this to be tractable.\n Using R Studio’s project files \nAn easy way to access all these files is to use a project file. In R Studio, you can create a new project file with File, New Project. You will then be asked if you want a new directory or to associate it with an existing directory.\nChoose this second option to have a project file associated with the folder that you created above.\nOnce created, you can open your project by directly clicking on that file or from File, Open if you have R Studio open already. Once open, you will see your directory structure in the files panel on the bottom right of R Studio and all your scripts and data are easily accessible.\nA big benefit of using a project file is that when you import data, you do not need to specify the working directory with setwd. R Studio will look within the folder that contains the project file. When using read.csv(\"\"), press tab repeatedly when you are within the \"\" to choose the local folders and files:\nread.csv(\u0026quot;/Data/Survey_data.csv\u0026quot;) The data file is found with a relative file path, rather than the alternatives of a full path in the read.csv function or setting the working directory then using read.csv\nread.csv(\u0026quot;C:/Work/Data/Survey_data.csv\u0026quot;) setwd(\u0026quot;C:/Work/Data\u0026quot;) read.csv(file=\u0026quot;Survey_data.csv\u0026quot;) Similarly, when you output a file (e.g., figures or tables), you can store than in your outputs folder (away from the raw data)\nwrite.csv(\u0026quot;/Outputs/Survey_summary_table.csv\u0026quot;) You can now simply copy your whole project folder to any other computer (desktop to laptop, student to supervisor etc.) and your code will always work without having to change the working directory for every machine.\nIf you have mutiple R project files, you can easily swap between them by clicking on the project name on the top right of R Studio.  Further help \nR Studio’s help with using projects Our introduction to version control for keeping track of revisions to project files. Author: Alistair Poore \u0026amp; Will Cornwell Last updated:\n## [1] \u0026quot;Tue Jan 18 17:46:16 2022\u0026quot;  "
},
{
	"uri": "/coding-skills/",
	"title": "Coding Skills",
	"tags": [],
	"description": "",
	"content": "  "
},
{
	"uri": "/getting-started-with-r/data_entry/",
	"title": "Data Entry",
	"tags": [],
	"description": "",
	"content": "  Data is the life-blood of science. As part of the scientific process, we invest an enormous amount of time collecting, analysing and presenting data. Before we can analyse data, however, we typically need to get it into a format that can be interpreted by others, and more importantly by the software used for analysis. Do this well and you can save yourself a lot of time; do this badly and you may end up wasting considerable time ‘cleaning’ and structuring the data to make it usable. What should a data set look like? \nMost data sets consist of rectangular tables of values (usually numbers or text). Each value belongs to a variable and an observation. A variable consists of values of the same type (e.g., temperature, duration or abundance). An observation consists of all values measured on the same unit (e.g., plot or individual). The convention is to store variables in columns and observations in rows.\nHere is an abridged data set from some insect sampling that shows you the desired format. It consists of five variables and data from the first nine replicate observations. Note the first row consists of a header listing the names of each variable in each column. The variables are:\nSite, with two possible values reflecting the habitat type (woodland or rainforest) Method, with two possible values reflecting the sampling technique (leaflitter or lighttrap) Insect, with the possible values reflecting the type of insect (ant, beetle, springtail, wasp, moth or termite). Number, with values reflecting the abundance of each insect in each observation. Group, with one possible value reflecting the identity of the collector (A, B, C etc.)   ## Site Method Insect Number Group ## 1 woodland leaflitter ant 26 A ## 2 woodland leaflitter beetle 8 A ## 3 woodland leaflitter springtail 6 A ## 4 woodland lighttrap beetle 8 A ## 5 woodland lighttrap wasp 1 A ## 6 woodland lighttrap moth 1 A ## 7 rainforest leaflitter ant 16 A ## 8 rainforest leaflitter termite 2 A ## 9 rainforest leaflitter springtail 63 A \nThis table is structured so that new data can be added with ease. For instance, we may wish to combine the data for multiple ‘collecting groups’, in which case it is straight-forward to add news rows to the existing dataset. If an additional set of samples has new insect species, we do not need to add new columns for each new species, just new values for the Insect variable. This is known as a long format. Some analyses (e.g., contrasts of species composition) will require each species as a separate column. See our Reshaping data for help on swapping between long and wide formats.  6 Golden rules of data entry \n1. Each column should contain only one type of information (i.e., text, numbers, dates, boolean). For instance, if text is inserted within or below the dataset, R or other analysis software will try to interpret the text as a value in the corresponding column. Similarly, if summary text is provided above the data (a common mistake), this will be interpreted as the first line or header of the actual data.\n2. Extensive metadata (e.g., site descriptions) should usually be documented in a separate file, but if sufficiently brief it can useful to include this information in its own column in the data table.\n3. Only use ASCII characters (upper and lower case English letters, numbers and common punctuation marks) for file names, variable names, and data values.\n4. Although it won’t affect analyses, to aid with visualisation of the raw data, it is good practise to order fixed variables first, followed by measured variables. In Table 1, Site and Method are fixed in that we know them in advance of data collection, whereas Insect and Number are measured. This, however, is not a hard and fast rule. For instance, we may want to order Group last as this information will typically be treated as metadata rather than data of actual interest for the analysis.\n5. Do not manipulate the raw data once digitized. Ideally the raw data should be treated as ‘read-only’ and any further transformations or manipulations should be done using saved R scripts (or an alternative programming language). This avoids accidentally inserting errors into the raw data each time you want to tweak something.\n6. Finally, always store data as .csv or .txt NOT .xls, .xlsx or other proprietary formats as those cannot be easily read into R or shared with collaborators. Text files do not require specific software to be read.  Further help \nOnce your data is entered in .csv or .txt format, see Importing data for help on importing into R.\nBorer, ET, EW Seabloom, MB Jones \u0026amp; M Schildhauer. 2009. Some simple guidelines for effective data management. Bulletin of the Ecological Society of America, 90: 205-214. link Wickham, H. 2014. Tidy data. Journal of Statistical Software, 59:(10). link \nAuthor: Andrew Letten Last updated:\n## [1] \u0026quot;Tue Jan 18 17:46:04 2022\u0026quot;  "
},
{
	"uri": "/getting-started-with-r/importing-data/",
	"title": "Importing Data",
	"tags": [],
	"description": "",
	"content": "  Before we can run any data analyses or create figures in R, we need to import that data into R. Preparing and cleaning the data for analyses is essential and often more time consuming than the statistical analyses themselves. It is unusual for raw data to be in the correct format and without errors. Data cleaning is the process of identifying and fixing any problems so data can be analysed easily.\nImporting data is a major challenge for beginners. This module will give instructions for one of most common ways we import data, and some of challenges you may face and how to overcome them. Some of these issues can be avoided by following good data entry and management practices (first read Data entry to get help with this. Importing data as a data frame \nWe recommend entering data into a spreadsheet program (e.g., Excel), and saving that data as a comma separated values (.csv) file. These are easily read into R and shared among users with different spreadsheet programs.\nIn this module, we are going to use a sample data set on feeding behaviour of a marine snail to demonstrate how to import the data, and the most common issues that arise with data import and cleaning in R.\nFirst, save the data file, Snail_feeding.csv to your working directory. See Getting started with R for help on for setting the working directory.\nSecond, import the data file to a data frame called Snail_feeding with the read.csv function.\nSnail_feeding \u0026lt;- read.csv(\u0026quot;Snail_feeding.csv\u0026quot;) \n Cleaning data frames \nWhen you use read.csv, R uses several default arguments which can be altered to ensure your data are imported with fewer errors. Have a look at the help file within R (by typing ?read.csv to familiarise yourself with some of these arguments.\nThe ones that are particularly useful are:\nheader = T - specifying this at T (i.e., TRUE) will ensure that the values in the first row of your data are treated as variable names.\nstrip.white = T - this will remove trailing and leading white space from factors. This is a common typing error made during data entry (i.e., “males” vs. “males_”). If we set this as TRUE, they both become “males”, otherwise R will think there are two different levels.\nna.strings = \"\" - this will ensure that empty cells are replaced by NA (the way R records missing data). Annoyingly, R imports missing values within characters/factors types as a value ““. Using na.strings = \"\" will insert NAs instead. In addition, if you have coded missing values as something other then blank space you can define that missing value using this argument (i.e na.strings = c(\"\", \"-\", \"*\")).\nPutting all these together in the read.csv function will give us a cleaner data frame.\nSnail_feeding \u0026lt;- read.csv(\u0026quot;Snail_feeding.csv\u0026quot;, header = T, strip.white = T, na.strings = \u0026quot;\u0026quot;) \n Checking the data \nIf something is a character when it should be numeric you might see messages such as “‘x’ must be numeric” or “non-numeric argument to binary operator”. Likewise, if something is a factor when it should be character, some character operations might fail. To avoid some of these issues, check your data using str and summary before analyses.\nstr enables you to check the structure of your data and that your variables are the correct type (i.e., numeric, characters, integers, or factors). See Data types and structure for explanations of these different types.\nstr(Snail_feeding) ## \u0026#39;data.frame\u0026#39;: 768 obs. of 12 variables: ## $ Snail.ID: int 1 1 1 1 1 1 1 1 1 1 ... ## $ Sex : chr \u0026quot;male\u0026quot; \u0026quot;male\u0026quot; \u0026quot;males\u0026quot; \u0026quot;male\u0026quot; ... ## $ Size : chr \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; ... ## $ Feeding : logi FALSE FALSE FALSE FALSE FALSE TRUE ... ## $ Distance: chr \u0026quot;0.17\u0026quot; \u0026quot;0.87\u0026quot; \u0026quot;0.22\u0026quot; \u0026quot;0.13\u0026quot; ... ## $ Depth : num 1.66 1.26 1.43 1.46 1.21 1.56 1.62 162 1.96 1.93 ... ## $ Temp : int 21 21 18 19 21 21 20 20 19 19 ... ## $ X : logi NA NA NA NA NA NA ... ## $ X.1 : logi NA NA NA NA NA NA ... ## $ X.2 : logi NA NA NA NA NA NA ... ## $ X.3 : logi NA NA NA NA NA NA ... ## $ X.4 : logi NA NA NA NA NA NA ... summary allows you to look at basic statistics for each of your variables and can be used to identify any obvious typos (i.e., extreme maximums or minimums relative to the mean or median or extra groups within a categorical vector).\nsummary(Snail_feeding) ## Snail.ID Sex Size Feeding Distance Depth Temp X X.1 X.2 X.3 X.4 ## Min. : 1.00 Length:768 Length:768 Mode :logical Length:768 Min. : 1.000 Min. :18.00 Mode:logical Mode:logical Mode:logical Mode:logical Mode:logical ## 1st Qu.: 4.75 Class :character Class :character FALSE:502 Class :character 1st Qu.: 1.260 1st Qu.:19.00 NA\u0026#39;s:768 NA\u0026#39;s:768 NA\u0026#39;s:768 NA\u0026#39;s:768 NA\u0026#39;s:768 ## Median : 8.50 Mode :character Mode :character TRUE :266 Mode :character Median : 1.510 Median :19.00 ## Mean : 8.50 Mean : 1.716 Mean :19.49 ## 3rd Qu.:12.25 3rd Qu.: 1.760 3rd Qu.:20.00 ## Max. :16.00 Max. :162.000 Max. :21.00 ## NA\u0026#39;s :6 Note that for the factor of sex, errors in data entry resulted in five levels (female, female s, male, Male and males) when there should be only two. See below for the fix.  Common problems when importing data \nYou don’t get the number of columns or rows you expect If you see a bunch of extra columns (X, X.1,X.2,X.3 etc) or rows in your data frame filled with NAs its likely because a character (most likely white space(i.e. space bar or tab) was entered in cells beyond your actual data in Excel. This problem can be avoided during data entry by removing all the colors/formatting and emptying columns/rows except for those needed.\nIf the problem is still there we can tackle it in R, by indexing within square brackets dataframe[row, column]. For example, the following code will replace the data frame in this example with one that only includes the first 7 columns and removes the 5 unwanted ones (X, X.1,X.2,X.3 etc).\nSnail_feeding \u0026lt;- Snail_feeding[,1:7] The package dplyr has several very neat functions for subsetting rows and columns - see Subsetting data for help with these.\nIf you had very many columns and didn’t want to count them, you could use logic (\u0026amp;, or, ==, \u0026gt;, \u0026lt; , !=) to remove the unwanted rows and columns. We don’t want to remove all NAs, only additional rows and columns that are entirely filled with NAs. These have the property of the number of NAs being equal to the number of rows in a given column (or number of columns in a given row).\nWe do this by selecting columns from our data frame where the column sum, colSums, of all the NAs, \u0026gt;is.na, in our data frame are not equal, != to the number of rows, nrow, of our data frame. Using the same logic you can do this for rows as well.\n# Selects rows that are not entirely NA Snail_feeding \u0026lt;- Snail_feeding[, colSums(is.na(Snail_feeding)) != nrow(Snail_feeding)] # Select columns that are not entirely NA Snail_feeding \u0026lt;- Snail_feeding[rowSums(is.na(Snail_feeding)) != ncol(Snail_feeding), ]  \nThe columns are not the type of data you expect Characters as factors When data frames are imported into R, characters are automatically coerced as factors. For statistical work this makes a lot of sense; we are more likely to want to work over factors (defined earlier) than over characters. Factors are fantastic when one is doing statistical analysis and actually exploring the data. However, prior to that when one is reading, cleaning, troubleshooting, merging and generally manipulating the data, factors are a total pain.\nYou can use the argument stringsAsFactors=FALSE when importing the data to avoid automatic coercion to factors or you can use as.character to convert individual vectors to characters.\nTip: Use factors as late as possible in the analysis process. Set stringsAsFactors=FALSE when importing your data, and when you need factors someplace within your script, then coerce the data to a factor.\nFactors as integers In this data frame, Snail ID is an integer where it should be a factor or character. This is because in the original data sheet Snail ID was coded using numbers. This is a common problem and is easy to fix. Simply use as.factor() or as.character(), and then class() to check our coercion worked. Remember to use $ to access the vector from within the data frame.\nSnail_feeding$Snail \u0026lt;- as.factor(Snail_feeding$Snail) class(Snail_feeding$Snail) ## [1] \u0026quot;factor\u0026quot; \nNumerics as characters (factors) Due to the automatic coercion in R, any non-numeric digits within a numerical variable will result in the whole variable being coerced to a character (R imports as factors). In this example, the variable Distance has been imported as a factor with 768 levels, when we would like it to be a numerical variable. This indicates a typo somewhere within the distance vector. Such typos are common (e.g., accidentally using comma instead of full stop when entering decimals), but a little trickier to solve.\nWith a small data set, it is quickest to go back to the original data and find the error. Once fixed, import again and the variable should now be numeric.\nWith a larger data set, we have the problem of needing to find the typos. Unfortunately, we can’t just convert our data straight into numeric from a vector of type Factor. This is because of the levels attribute (see Data types and structure). If you try and convert a factor directly to a numerical variable, the values become a number that corresponds to the number of levels (1:n, ordered alphabetically or ascending) rather than the actual value.\nThus, we must first convert to a character and then to a numeric. When converting to a numeric, you will get a warning message, NAs introduced by coercion. This is because the non numeric values (i.e., our typos) cannot be coerced to a numeric and get replaced by NA.\nWe can use this to our advantage, is.na in combination with which will identify where the typos or missing values are within the vector.\nSnail_feeding$Distance \u0026lt;- as.character(Snail_feeding$Distance) Snail_feeding$Distance \u0026lt;- as.numeric(Snail_feeding$Distance) ## Warning: NAs introduced by coercion which(is.na(Snail_feeding$Distance)) ## [1] 682 755 This tells us that something weird happened in rows 682 and 755. Now we have identified where the problem is, it is simple to replace values within our data frame with correct values (go back to your original datasheet). You could either fix the error in the data set and import again, or replace values in R by indexing within square bracketsand assigning, \u0026lt;-, the new value. Use which(is.na()) to check if your fix worked.\nSnail_feeding[682,\u0026quot;Distance\u0026quot;] \u0026lt;- 0.356452 Snail_feeding[755,\u0026quot;Distance\u0026quot;]\u0026lt;- 0.42336 which(is.na(Snail_feeding$Distance)) ## integer(0) \nYou have more variable levels then expected One of the most important steps in any data analyses or processing task is to verify that your data values are correct. For example a variable called “Sex” would be expected to have only two levels. However in our data frame it has five levels (see str and summary above).\nYou can check the levels of a factor, or unique character values with levels (for factors only), or unique (for characters and factors).\nlevels(Snail_feeding$Sex) ## NULL unique (Snail_feeding$Sex) ## [1] \u0026quot;male\u0026quot; \u0026quot;males\u0026quot; \u0026quot;Male\u0026quot; \u0026quot;female\u0026quot; \u0026quot;female s\u0026quot; There are several typos which we can correct with unique and which and the logical operators == (equals) and | (or) to identify and replace typos.\nTo replace any values that are are “males” or “Male” with “male”, we would use:\nSnail_feeding$Sex[which(Snail_feeding$Sex == \u0026quot;males\u0026quot; | Snail_feeding$Sex == \u0026quot;Male\u0026quot;)] \u0026lt;- \u0026quot;male\u0026quot; To replace any values that are “female s” with “female”, we would use:\nSnail_feeding$Sex[which(Snail_feeding$Sex == \u0026quot;female s\u0026quot;)] \u0026lt;- \u0026quot;female\u0026quot; Check it worked using unique, but also look what happens when you check levels.\nunique(Snail_feeding$Sex) ## [1] \u0026quot;male\u0026quot; \u0026quot;female\u0026quot; levels(Snail_feeding$Sex) ## NULL When we use unique to check our categories there are just male and female, however when we look at levels we still have the five different levels including the typos. This is because of the behavior of factors. Once the levels have been defined, they will still be there regardless if they are included in any samples. As our extra levels were typos not true levels, we should remove these from the attributes.\nfactor will remove extra levels from a vector.\nSnail_feeding$Sex \u0026lt;- factor(Snail_feeding$Sex) levels(Snail_feeding$Sex) ## [1] \u0026quot;female\u0026quot; \u0026quot;male\u0026quot; \nNumeric typos Using summary above is a useful tool to check for potential typos within our numeric variables. Compare the Max or Min against the Median of each numeric variable. If either value is an order of magnitude greater or less then your median it could be a typo. For example look at the max depth, this looks like the decimal point has been forgotten.\nAgain we, can use logical operators and indexing to identify potential numeric typos. Given all the values of our depth variable appear to be between 1 and 2 (based on inter quartile ranges from summary), we will look for rows with a depth greater then 2.\nSnail_feeding[which(Snail_feeding$Depth \u0026gt; 2), ] ## Snail.ID Sex Size Feeding Distance Depth Temp Snail ## 8 1 male small TRUE 0.6 162 20 1 There is only 1 row. After confirming with our original data that this is in fact a typo we will replace it with the real value. Selecting the row and column we replace the value 162 with 1.62.\nSnail_feeding[which(Snail_feeding$Depth \u0026gt; 2),6] \u0026lt;- 1.62 \n Why do this in R ? \nYou might be wondering why go through the trouble of fixing this in R? Why not just go to the .csv file and fix all the problems directly. It is usually OK to do this if you know the problem is a typo etc. However to maintain data integrity it is important to have a record of every change that has been made to your original data set. By doing all the manipulations and fixes in R, you are also keeping a record of all the changes that are occurring to your data.\nAlso, you may want to start to explore data before you have collected the entire data set. If you set up a script that checks all of these things before making graphs and running analyses, it is quick to run the script again on the full data once you have it all. The script acts to remind you of all the things to check and is better at picking up typos than you are in a huge spreadsheet.  The final check \nFinally, once you have checked and fixed all the problems in your data re run str and summary. Actually it is a good idea to run these functions regularly throughout data cleaning to keep tabs on any changes you make.\nstr(Snail_feeding) ## \u0026#39;data.frame\u0026#39;: 768 obs. of 8 variables: ## $ Snail.ID: int 1 1 1 1 1 1 1 1 1 1 ... ## $ Sex : Factor w/ 2 levels \u0026quot;female\u0026quot;,\u0026quot;male\u0026quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Size : chr \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; ... ## $ Feeding : logi FALSE FALSE FALSE FALSE FALSE TRUE ... ## $ Distance: num 0.17 0.87 0.22 0.13 0.36 0.84 0.69 0.6 0.85 0.59 ... ## $ Depth : num 1.66 1.26 1.43 1.46 1.21 1.56 1.62 1.62 1.96 1.93 ... ## $ Temp : int 21 21 18 19 21 21 20 20 19 19 ... ## $ Snail : Factor w/ 16 levels \u0026quot;1\u0026quot;,\u0026quot;2\u0026quot;,\u0026quot;3\u0026quot;,\u0026quot;4\u0026quot;,..: 1 1 1 1 1 1 1 1 1 1 ... summary(Snail_feeding) ## Snail.ID Sex Size Feeding Distance Depth Temp Snail ## Min. : 1.00 female:384 Length:768 Mode :logical Min. :0.0000 Min. :1.000 Min. :18.00 1 : 48 ## 1st Qu.: 4.75 male :384 Class :character FALSE:502 1st Qu.:0.2775 1st Qu.:1.260 1st Qu.:19.00 2 : 48 ## Median : 8.50 Mode :character TRUE :266 Median :0.5100 Median :1.510 Median :19.00 3 : 48 ## Mean : 8.50 Mean :0.5120 Mean :1.507 Mean :19.49 4 : 48 ## 3rd Qu.:12.25 3rd Qu.:0.7500 3rd Qu.:1.760 3rd Qu.:20.00 5 : 48 ## Max. :16.00 Max. :1.0000 Max. :2.000 Max. :21.00 6 : 48 ## NA\u0026#39;s :6 (Other):480 \n Further help \nIntro to data cleaning in R by de jonge and van de Loo\nR-bloggers- common errors in table import Author: Keryn Bain Last updated:\n## [1] \u0026quot;Tue Jan 18 17:46:10 2022\u0026quot;  "
},
{
	"uri": "/getting-started-with-r/data_types_structure/",
	"title": "Data Types + Structure",
	"tags": [],
	"description": "",
	"content": "  One of the most common sources of frustration for beginners in R is dealing with different data structures and types. Here is an overview of the most important data structures, types and how to check and manipulate them.\nThe terms ‘structure’ and ‘type’ are often used interchangable. To avoid confusion, for this help page, data structure refers whether the data is a vector, matrix or data frame etc. and type refers to whether the data or variable is an integer, character or numeric etc. One dimensional data (vectors) \nThe most basic data structure in R is a vector, a one-dimensional set of numbers or characters. This is the data structure that you will work with the most, albeit from within a data frame (see below). Vectors can be either atomic or list, atomic vectors differ to lists in that all elements within an atomic vector must be of the same type (see below). For the most part we work with atomic vector and the following help file refers to this type of data.\nCommon types of vectors \nCommon types of atomic vectors are logical, integer, numeric (i.e., double), character and factor. You can easily create each of these data types by using c(). In the integer example, the L forces R to consider those numbers as integers rather than numerical. eg_logical \u0026lt;- c(T, T, T, F, F) eg_integer \u0026lt;- c(1L, 6L, 1L, 5L, 4L) eg_numeric \u0026lt;- c(0, 2.3, 2.45, 2.99, -1.1) eg_character \u0026lt;- c(\u0026quot;things\u0026quot;, \u0026quot;in\u0026quot;, \u0026quot;apostrophe\u0026quot; ,\u0026quot;are\u0026quot;, \u0026quot;characters\u0026quot;) eg_factor \u0026lt;- factor(c(\u0026quot;NSW\u0026quot;, \u0026quot;NSW\u0026quot;, \u0026quot;ACT\u0026quot;, \u0026quot;WA\u0026quot;, \u0026quot;WA\u0026quot;)) \n Factors (a special data type) \nNotice how I couldn’t just use the c() to create a factor. Though factors look (and behave for the most part) like characters, they are actually a special type of integer with predefined categories, known as levels. The factor in this example has three levels: NSW, ACT and WA.\nYou can check how many levels any factor has using:\nlevels(eg_factor) ## [1] \u0026quot;ACT\u0026quot; \u0026quot;NSW\u0026quot; \u0026quot;WA\u0026quot; This makes them behave differently to integers. Once created, factors can only contain a pre-defined set levels. For example, if you collecting data from sites across Australia you could have the fixed number of states as a factor, but it would be better to have a variable like site as a character if you were going to add data from more sites later on.\nBy default, R will always sort levels in alphabetical order. If you want your factors to be ordered (i.e., small, medium, high), use ordered to define the sequence you would like the levels to be presented. This is particularly useful for graphics to present the categories along an x axis in a more logical order.\nsizes \u0026lt;- factor(c(\u0026quot;small\u0026quot;, \u0026quot;large\u0026quot;, \u0026quot;large\u0026quot;, \u0026quot;small\u0026quot;, \u0026quot;medium\u0026quot;)) sizes ## [1] small large large small medium ## Levels: large medium small sizes \u0026lt;- ordered(sizes, levels = c(\u0026quot;small\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;large\u0026quot;)) sizes ## [1] small large large small medium ## Levels: small \u0026lt; medium \u0026lt; large See here for more info on ordered factors.  Checking data types \nYou can check the data type of any vector using the class or is functions.\nclass(eg_logical) ## [1] \u0026quot;logical\u0026quot; is.integer(eg_integer) ## [1] TRUE is.factor(eg_factor) ## [1] TRUE \n Automatic coercion \nAs all elements within an atomic vector must be the same type, combining different types will coerce the data to the most flexible. Types from least to most flexible are: logical, integer, double, and character. For example, combining and integers and character will produce a character vector. This is something to be aware whilst manipulating your own data, especially when merging data frames.\neg_coerced \u0026lt;- c(\u0026quot;tricks\u0026quot;, 1, 2, 3, 4) class(eg_coerced) ## [1] \u0026quot;character\u0026quot; \n Coercing data \nIf you find your data is the wrong type, you can use the as functions to coerce data from one type to another. Be aware of what happens to your data after coercion. For example, coercing logical to numeric replaces F with 0s and Ts with 1s and any nonsensical coercion (like trying to make character “NSW” into a numeric) will result in NAs.\nas.numeric(eg_logical) ## [1] 1 1 1 0 0 as.numeric(eg_character) ## Warning: NAs introduced by coercion ## [1] NA NA NA NA NA \n  Two dimensional data (matrices and data frames) \nFor the most part, we tend to work with two dimensional data containing both columns and rows. Like the one dimensional vectors, they come in two forms: matrices, where all vectors must be of all the same type of data, and data frames, which can be made up of vectors containing different data types. Matrices \nMatrices are easily constructed in R and can you check if its a matrix using the class function. For example, to make a matrix with 3 rows and 2 columns with 6 values:\neg_matrix \u0026lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 3, ncol = 2) ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 Think of matrices as atomic vectors with dimensions; the number of rows and columns. Like atomic matrices, you can check the type of data with is and coerce using the as functions.\nis.logical(eg_matrix) ## [1] FALSE as.numeric(eg_logical) ## [1] 1 1 1 0 0 \n Data frames \nThe most common data structure we work with is the data frame. Data frames are just a collection of atomic vectors of equal length stuck together. They are different to matrices as they can contain vectors of different types.\nTo make a simple data frame that combines three of the vectors we made above, we could use:\neg_data_frame \u0026lt;- data.frame(eg_character, eg_factor, eg_numeric) ## eg_character eg_factor eg_numeric ## 1 things NSW 0.00 ## 2 in NSW 2.30 ## 3 apostrophe ACT 2.45 ## 4 are WA 2.99 ## 5 characters WA -1.10 More commonly, we import data entered into a spreadsheet straight into a data frame using read.csv (see help Importing data).\nTo check the data types within a data frame, use the str function. This gives an output listing for each column (i.e., variables) and the respective data type.\nstr(eg_data_frame) ## \u0026#39;data.frame\u0026#39;: 5 obs. of 3 variables: ## $ eg_character: chr \u0026quot;things\u0026quot; \u0026quot;in\u0026quot; \u0026quot;apostrophe\u0026quot; \u0026quot;are\u0026quot; ... ## $ eg_factor : Factor w/ 3 levels \u0026quot;ACT\u0026quot;,\u0026quot;NSW\u0026quot;,\u0026quot;WA\u0026quot;: 2 2 1 3 3 ## $ eg_numeric : num 0 2.3 2.45 2.99 -1.1 Note that data types can change. In this example, the character vector has been coerced to a factor in the process of making the data frame.\nIf you wish to check the data type of just one variable, or change that variable to another type, we use $ to access that variable from within the data frame. For example:\nstr(eg_data_frame$eg_character) ## chr [1:5] \u0026quot;things\u0026quot; \u0026quot;in\u0026quot; \u0026quot;apostrophe\u0026quot; \u0026quot;are\u0026quot; \u0026quot;characters\u0026quot; levels(eg_data_frame$eg_factor) ## [1] \u0026quot;ACT\u0026quot; \u0026quot;NSW\u0026quot; \u0026quot;WA\u0026quot; is.numeric(eg_data_frame$numeric) ## [1] FALSE \n  Further help \nFurther information on data types in R can be found here and here Author: Keryn Bain Last updated:\n## [1] \u0026quot;Tue Jan 18 17:46:07 2022\u0026quot;  "
},
{
	"uri": "/",
	"title": "Learn Theme for Hugo",
	"tags": [],
	"description": "",
	"content": "Documentation website This current documentation has been statically generated with Hugo with a simple command : hugo -t hugo-theme-learn \u0026ndash; source code is available here at GitHub\nAutomatically published and hosted thanks to Netlify. Read more about Automated HUGO deployments with Netlify\n "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]