[
{
	"uri": "/about-this-site/",
	"title": "About This Site",
	"tags": [],
	"description": "",
	"content": "  This site is a brief introduction to techniques for data organisation, graphics, and analyses, including:\n how to organise your data during data entry how to manipulate and manage your data so there is transparency and version control instructions for running statistical analyses with sample code in R or other relevant software (first see Getting started with R) the rationale for the technique in plain language (why is it used) how to interpret the results and assumptions that you need to check visualisation of your results and ways to effectively communicate the results in scientific reports or publications where to go for further help  This site integrates different techniques used by researchers and postgraduates at the University of New South Wales, Australia, who have provided their knowledge and skills to assist others develop skills for rigorous environmental science.\nSome resources were developed initially to assist with teaching quantitative skills to undergraduate and postgraduate students in the School of Biological, Earth and Environmental Sciences at the University of New South Wales, supported by a Learning and Teaching Innovation Grant to Associate Professor Alistair Poore, Dr Will Cornwell, Professor Iain Suthers and Professor Richard Kingsford.\nSite administrators:\nAssociate Professor Alistair Poore\nAssociate Professor Will Cornwell\nPage authors: Keryn Bain, Rachel Blakey, Stephanie Brodie, Corey Callaghan, Will Cornwell, Kingsley Griffin, Matt Holland, James Lavender, Andrew Letten, Shinichi Nakagawa, Shaun Nielsen, Alistair Poore, Gordana Popovic, Fiona Robinson and Jakub Stoklosa.\nLast updated:\n## [1] \u0026quot;Thu Jan 20 14:28:40 2022\u0026quot; Contributors Thanks to them  for making Open Source Software a better place !\n "
},
{
	"uri": "/graphics/basic-plotting/",
	"title": "Basic Plotting in R",
	"tags": [],
	"description": "",
	"content": "  R has a very wide range of functions and packages for visualising data. Here is some help for some very simple plots using the base functions in R for data with:\n one continuous variable - histograms and box plots\n two continuous variables - scatter plots\n one continuous vs categorical variables - box plots and bar plots  "
},
{
	"uri": "/coding-skills/good-practice/",
	"title": "Good Practices for Code",
	"tags": [],
	"description": "",
	"content": "  library(formatR) When undertaking any project that involves data analyses in R, it is a very good idea to save all the code needed to run any analyses or make any figures in an R script.\nR scripts are very useful when collaborating with others as you can share your methods. We also tend to reuse and adapt scripts for future projects, so you may need to read a script you wrote months or even years ago. It is important to format your script for easy transfer across computers and for easy interpretation by others (and yourself). It is the digital equivalent of being organised and avoiding the problem of never knowing where anything is.\nIf you have never made an R script, first read Getting started with R. Creating a project directory \nGood script and data management practices often start before you even open R-Studio. For every project you should start by creating a project folder on your computer. This is where you keep all your data, scripts and outputs (plots and tables) and will be referred to as your project directory. Some people like to further organise project directories by creating more folders such as “Data”, “R_scripts” or “Outputs”, how you manage your project directory is up to you. Data integrity. Once data entry is completed and saved in your project directory (see Data entry, this should be the last time you lay eyes on the raw data. Any manipulation, removal of outliers, renaming variables etc should be conducted in R. This maintains the integrity of your original data and provides a record in your R script of exactly what changes have been made to your dataset.  General script format \nThe following notes outline the general layout and ordering you should follow when writing your scripts. If everyone is using the same general format, reading and understanding each other’s (and your own) scripts will be much easier.\nFirstly, all scripts should start with a title, author details, a brief description of the scripts purpose and the data being used and copyright and legal stuff (Probably not while in university, but later in life you’ll want to remember this). For example,\n# Title: Time series analyses # Author details: Author: John Smith, Contact details: John.Smith@unsw.edu.au # Script and data info: This script performs a time series analyses on count data. # Data consists of counts of bird species. # Data was collected in the hunter valley region between 1990 and 1991. # Copyright statement: This script is the product of UNSW etc. All comments need to start with # to distinguish them from executable code.\nYou should then include some code that will set your working directory and import your data. Ideally, setting your working directory as your project directory.\nsetwd(\u0026quot;C:/Users/JohnSmith/My_project_directory\u0026quot;) my.data \u0026lt;- read.csv(\u0026quot;my_data.csv\u0026quot;, sep = \u0026quot;,\u0026quot;, header = T, check.names = FALSE) To save time later and avoid annoying error messages, ensure all the packages and functions needed for you analyses are loaded into R, this includes libraries or any function scripts you have written yourself. Each package is loaded with the library.\nlibrary(car) library(lme4) library(Reshape2) library(ggplot2) source(\u0026quot;R_scripts/myfunctions.R\u0026quot;) Finally, before you start running any data analyses you may need to conduct some housekeeping on your data (checking the structure of the data set, looking for missing values, changing variable types etc). See Data structure and Importing data for help with these issues.\nPutting all this together, the beginning of a script will look something like the following.\n# Title: Time series analyses # Author details: Author: John Smith, Contact details: John.Smith@unsw.edu.au # Script and data info: This script performs a time series analyses on count data. # Data consists of counts of bird species. # Data was collected in the Hunter Valley region between 1990 and 1991. # Copyright statement: This script is the product of UNSW etc. setwd(\u0026quot;C:/Users/JohnSmith/myprojectdirectory\u0026quot;) my.data \u0026lt;- read.csv(\u0026quot;mydata.csv\u0026quot;, sep = \u0026quot;,\u0026quot;, header = T, check.names = FALSE) library(car) library(lme4) library(Reshape2) library(ggplot2) source(\u0026quot;R_scripts/myfunctions.R\u0026quot;) # Checking data structure summary(my.data) str(my.data) my.data[which(is.na(my.data)), ] levels(my.data$variable1) # Data cleaning my.data$variable1 \u0026lt;- as.numeric(my.data$variable1) # changed to numeric. my.data[is.na(my.data)] \u0026lt;- 0 # replace NAs with zeros. my.data[6, 4] \u0026lt;- 46.01 # replace value 4601 with 46.01. # begin data analyses. \n Style guide \n“Good coding is like using correct punctuation. You can manage without it, but it sure makes things easier to read.” - Hadley Wickham.\nThere are many different styles of coding (none of which are better or worse). The point of style guides is to have a common vocabulary. When working with others, its a good idea to agree on a common style before the project gets too far along.\nThe following guide is based on the Google’s R style guide and Hadley Wickham’s Style Guide. If you haven’t already adopted a consistent coding style these are good places to start.  Notation and naming \nFile and folder names When naming your project folders, data files, script files, or any other files for that matter, there are number of things that need to be considered. Files may be copied or transferred across different operating systems (e.g Windows, Mac, or UNIX ) and we need to name our files for transfer-ability. In addition, file names must be unique and indicative of what the file contains. Consider the following rules when naming your own folders and files.\nFirstly, avoid “special” characters. Special characters include things such as file separators (e.g. colons, forward-slash, and backslash), non-alphabetical and non-numerical symbols ( e.g., ? T $ ?), punctuation marks ( e.g., full stops, commas, parentheses, quotations marks, and operators ) and, the most common mistake, avoid white space characters (spaces, tabs, new lines and embedded returns).\nGive your files meaningful names; avoid filenames such as “project1” and “project2” or “data1.csv” and “data2.csv”, instead use things like “bird_movement.csv”, “snail_feeding.csv” or “diurnal_movement_data.csv” and “yearly_movement_data.csv”. For R scripts, file names should end in .R (i.e., “predict_diurnal_movements.R”).\nAlthough current file systems allow 255 character limits, it is good practice to shorten files names. Try keep file names between 1 and 3 words long. If you add dates to a filename, remember to avoid using special characters, consider underscore or dashes to separate out days-months-years.\nIt is absolutely crucial that file names be unique, especially if you work in a collaborative environment, and especially if you frequently copy files to a server. If you don’t have a system for how you keep file names unique, you risk overwriting them and losing all your data. Object names in R Variable names should all be in lower case with words separated by dots where as Function names have initial capital letters and no dots. Generally, variables names should be nouns and function names should be verbs. For ease of typing, it is OK to shorten words and use abbreviations so long as they still identify and describe the object they are naming. Strive for names that are concise and meaningful, refrain from calling variable names single letters and, where possible, avoid using existing function and variable names.\nGood examples\n# variables bird.mvment \u0026lt;- read.csv(\u0026quot;bird_movement.csv\u0026quot;) bird.mvment.mdl \u0026lt;- lm(counts ~ location, data = bird.mvmnt) bird.mvment$log.counts \u0026lt;- log(bird.mvmnt$counts) # functions CalcStandardError \u0026lt;- function (x){ sd(x)/sqrt(length(x)) } Bad examples\n# variables data \u0026lt;- read.csv(\u0026quot;bird_movement.csv\u0026quot;) # uninformative, especially if you had to load two datasets. Bird.Mvment_Mdl \u0026lt;- lm(counts ~ location, data = bird.mvmnt) # inconsistent naming format. bird.mvment$log \u0026lt;- log(bird.mvmnt$counts) # uninformative and used function name to label variable. # functions S \u0026lt;- function (x){ # S is uninformative. sd(x)/sqrt(length(x)) } \n Guidelines for adding comments \nAdding comments to your script When you go back and edit or work on projects in the future it is surprising how much you’ll forget. It is thus essential to accurately comment your code for both solo and team projects. However, you can have too many comments. Descriptive and informative names and expressive code can abolish the need for many comments and over commenting can scripts that are messy and hard to read. This is a skill that develops over time and with practice. As you get better at coding you will find yourself commenting less and less - “Code doesn’t lie, but comments can”.\nIn general, comments should NOT state the obvious, they should be consistent with what they describe, it should be clear what line or block of code they are referring to and they should be readable by any future handler.\nEntire commented lines should begin with # and one space; short comments can be placed after code proceeded by two spaces, # and then one space.\nTip: Use commented lines of # —— to break up your script into readable chunks.\nGood examples\nbird.count \u0026lt;- 10 # Creates histogram of frequency of bird counts. hist(bird_movement$counts, breaks = \u0026quot;scott\u0026quot;, # method for choosing number of buckets main = \u0026quot;Histogram: bird counts\u0026quot;) Bad examples\nx \u0026lt;- 10 # Bird counts - unneccesary, simply name the variable \u0026#39;bird.count\u0026#39; hist(bird_movement$counts, breaks = \u0026quot;scott\u0026quot;,### method for choosing number of buckets - looks messy. main = \u0026quot;Histogram: bird counts\u0026quot;) # Creates histogram of frequency of bird counts. - place comment before code.  \nAdding comments to functions Function comments should contain, a brief description of the function (one sentence), a list of function arguments with a description of each (including data type) and a description of the return value. Function comments should be written immediately below the function definition line.\nSee Writing simple functions for help on creating functions in R.\nGood example\nCalculateStandardError \u0026lt;- function (x){ # Computes the sample standard error # # Arguments: # x: Vector whose standard error is to be calculated. x must have length greater than one, # with no missingn values. # # Return: # The standard error of x se\u0026lt;-sd(x)/sqrt(length(x)) return(se) } \n Syntax \nAssignment Always use \u0026lt;- when assigning names to objects and avoid using = for assignment. Even though this distinction doesn’t matter for the majority of the time, it is a good habit to use \u0026lt;- as this can be used anywhere, whereas the operator = is only allowed at the top level. In addition = closely resembles ==, which is the logical operator for equals to.\nGood example\nbird.count \u0026lt;- bird.mvments$counts Bad example\nbird.count = bird.mvments$counts \nLine length The maximum line length should be 80 characters. This fits comfortable on a printed page with a reasonably sized font. If you find yourself running out of space, you may need to condense some of the work into a separate function.\nThis is how long 80 characters is. Try not to type more than 80 on a single line. \nSpacing Place spaces around all binary operators (=, +, -, \u0026lt;-, ==, ! = ), the exception to this is colons (:) and commas(,). Just like regular English, always put a space after a comma and never before.\nGood examples\nbird.mvments[which(bird.mvments == max(bird.mvments)), ] bird.var \u0026lt;- bird.mvments[, 4:10] Bad examples\nbird.mvments[which(bird.mvments==max(bird.mvments)),] # spaces needed between operators and after comma. bird.var \u0026lt;- bird.mvments[ ,4 : 10] # space goes after comma not before, remove space around :. bird.var\u0026lt;-bird.mvments[, 4:10] # space needed around \u0026lt;-.  Place a space before parentheses, except in a function call. Do not place space around code within parentheses or square brackets except after a comma.\nGood examples\nfor (i in 1:20) { bird.means[[i]] \u0026lt;- mean(bird.mvments$bird.count[[i]]) } mean(bird.mvments$bird.count) bird.mvments[2, ] Bad examples\nfor(i in 1:20) { # space needed betwen for and (i in 1:20). bird.means[[i]] \u0026lt;- mean (bird.mvments$bird.count[[i]]) # remove space after mean. } mean( bird.mvments$bird.count ) # remove space around code. bird.mvments[2,] # needs a space after comma.  \nCurley braces {} Curly braces are used in loops and to set up logical conditions. An opening curly brace should never go on its own line and should always be followed by a new line. A closing curly brace should always go on its own line, unless followed by else, which should be contained within outward facing curly braces \u0026gt;}else{. Always indent the code within curly braces.\nGood examples\nfor (i in 1:20) { bird.means[[i]] \u0026lt;- mean(bird.mvments$bird.count[[i]]) } if (y == 0) { log(x) } else { y ^ x } Bad examples\nfor (i in 1:20) { bird.means[[i]] \u0026lt;- mean(bird.mvments$bird.count[[i]]) # opening curly followed by new line } for (i in 1:20) { bird.means[[i]] \u0026lt;- mean(bird.mvments$bird.count[[i]])} # closing curly needs new line. if (y == 0) { log(x) } else { # inclose else within }{. y ^ x } \nIndentation Never use tabs or mix tabs and spaces when indenting your code. When indenting, use two spaces, except when using parentheses where you align a new line with the first character within the parenthesis or square brackets.\nGood examples\nCalcStandardError \u0026lt;- function (x){ se\u0026lt;-sd(x)/sqrt(length(x)) return(se) } bird.mvments[which(bird.mvments$counts == max(bird.mvments$counts)), 10:ncols(bird.mvments)] Bad examples\nCalcStandardError \u0026lt;- function (x){ se\u0026lt;-sd(x)/sqrt(length(x)) # indent two spaces. return(se) } bird.mvments[which(bird.mvments$counts == max(bird.mvments$counts)), 10:ncols(bird.mvments)] # align with the square brackets.  \n Further help \nFor more info see Hadley Wickham’s style guide which is based of the Google style guide.\nYou may now be thinking about all the scripts that you have made that need to be be reformatted. As is commonplace in R, someone has created a package to help with this. The formatR package by Yihui Xie has a neat little function called tidy_source(). This isn’t a fix all, but can go a long way in making horrible scripts look legible. See An introduction to format R or type ?tidy_source() for details on how to use this package. Author: Keryn F Bain Last updated:\n## [1] \u0026quot;Wed Jan 19 15:06:46 2022\u0026quot;  "
},
{
	"uri": "/statistics/catagorical/goodness-of-fit/",
	"title": "Goodness of Fit",
	"tags": [],
	"description": "",
	"content": "  \\(\\chi^2\\) goodness of fit tests are used to test whether the counts of observations belonging to two or more categories differ from those under an expected model. For example, what is the likelihood of a sample of 60 women and 40 men in a class coming from a population where the sex ratio is actually 1:1? In this example, there is a single categorical variable of sex, with two categories of male and female. \nThe test statistic is:\n\\(\\chi^{2} = \\sum_{i=1}^{k} \\frac{(O_{i}-E_{i})^2}{E_{i}}\\)\n\nwhere O and E are the observed and expected numbers in each of the categories from 1 to k.\nThe observed numbers come from your actual observations, in this example 60 and 40.The expected numbers are from a theoretical expectation of the frequencies under the model being tested. In this example, if you were testing against an expectation of a male:female ratio of 1:1, then you would expect 50 women and 50 men in a sample of 100 people.\nFor this example,\n\\(\\chi^2 = \\frac{(60-50)^2}{50}+\\frac{(40-50)^2}{50}\\) Running the analysis \nYou can calculate \\(\\chi^2\\) pretty easily with a calculator. You would then need to determine the probability of obtaining that \\(\\chi^2\\) value from the known probability distribution of \\(\\chi^2\\).\npchisq(x, df,lower.tail = FALSE) with x = your value of \\(\\chi^2\\), and degrees of freedom (df) = number of categories-1. The lower.tail = FALSE bit gives you the probability that \\(\\chi^2\\) is greater than your value.\nAlternatively, you can do all of this in one go with the chisq.test function.\nchisq.test(x, p)  where x = the observed data (i.e., counts in each category) and p are the expected probabilities for each category.\nIn this example we would use:\nchisq.test(x = c(60,40), p = c(0.5,0.5)) where x is the observed range of numbers and p has the expected probabilities.\nNote that it is very important that you use the actual counts as your observed data, not their proportions (i.e., 60 and 40, not 0.6 and 0.4). This makes sense if you understand that a sex ratio of 6:4 in a sample of 10 people is more likely to occur by chance when sampling from an equal sex ratio than a ratio of 600:400 in a sample of 1000 people.\nYou are not constrained to just two categories, or an expectation that the counts in each are equal. For example, to test whether the counts 10, 20 and 70 in three categories came from a population with expected frequencies of 0.25, 0.25 and 0.5, you would use:\nchisq.test(x = c(10,20,70), p = c(0.25,0.25,0.5)) \n Interpreting the results \nThe output from a goodness of fit test is very simple: the value of \\(\\chi^2\\), the degrees of freedom (number of categories - 1) and the p-value. The p-value gives the likelihood of your observed counts coming from a population with the expected frequencies that you specified.\n## ## Chi-squared test for given probabilities ## ## data: c(60, 40) ## X-squared = 4, df = 1, p-value = 0.0455 In the sex ratio example, you should have obtained a p-value of 0.0455, which tells us that it is unlikely to obtain a sample of 60 women and 40 men from a population with an equal sex ratio. We would then conclude that they were likely to be sampled from a population that did not have an equal sex ratio.\nTo explore which of the categories had more observations than expected, or had fewer observations than expected, look at the standardised residuals.\nchisq.test(x = c(60,40), p = c(0.5,0.5))$residuals These are the differences between the observed and expected, standardised by the square root of the expected. These are standardised because any contrast of the absolute differences (observed - expected) can be misleading when the size of the expected values vary. For example, a difference of 5 from an expectation of 10 is an increase of 50%, but a difference of 5 from an expectation of 100 is only a 5% change.\nExploring the residuals becomes important when there are more than two categories in the test, as the \\(\\chi^2\\) test will only tell you if the observed frequencies differ from the expected across all categories, not which particular category is over- or under-represented.  Assumptions to check \nIndependence. The \\(\\chi^2\\) test assumes that the observations are classfied into each category independently of each other. This is a sampling design issue and is usually avoided by random sampling. In the sex ratio example, there would be problems is you deliberately chose women to add to your sample if you thought that you had enough men already.\nSample size. The \\(\\chi^2\\) statistic can only be reliably compared to the \\(\\chi^2\\) distribution if sample sizes are sufficiently large. You should check that at least 20% of the expected frequencies are larger than 5. You can see the expected counts for each category by adding $expected to the end of your \\(\\chi^2\\) test. For example,\nchisq.test(x = c(60,40), p = c(0.5,0.5))$expected If this assumption has not been met, you could combine categories (if you have more than two), run a randomisation test or consider log-linear modelling.  Communicating the results \nWritten. The results of a \\(\\chi^2\\) goodness of fit test can be easily presented in the text of a results section. For example, “The sex ratio of the class of 100 students differed significantly from a 1:1 ratio (”\\(\\chi^2\\) = 4, df = 1, P = 0.0455).”\nVisual. Count data are best presented as a bar plot with the counts on the Y axis and the categories on the X axis\nbarplot(c(60,40),xlab = \u0026#39;Sex\u0026#39;, ylab = \u0026#39;Count\u0026#39;, names=c(\u0026#39;Female\u0026#39;,\u0026#39;Male\u0026#39;)) See the graphing modules for making better versions of these figures that are suitable for reports or publications.  Further help \nType ?chisq.test to get the R help for this function.\nQuinn and Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Chapter 14. Analyzing frequencies.\nMcKillup (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Chapter 20.2 Comparing observed and expected frequencies: the chi-square test for goodness of fit. Author: Alistair Poore Last updated:\n## [1] \u0026quot;Mon Jan 24 12:25:37 2022\u0026quot;  "
},
{
	"uri": "/getting-started-with-r/installing-r-rstudio/",
	"title": "Installing R and R Studio",
	"tags": [],
	"description": "",
	"content": "  We recommend using R Studio as a user friendly interface for using R.\nFirst, install the latest version of R - download from here\nSecond, install the latest version of R Studio - download from here Setting the working directory \nOnce you have installed R and R Studio, you need to set the working directory. This is the location on your computer where any data files to imported can be found, and where any R scripts (the files that save your code) will be saved.\nIn R studio, you can set the working directory with the menus (Session \u0026gt;\u0026gt; Set Working Directory \u0026gt;\u0026gt; Choose Directory) or with a line of code that gives the path of the folder on your computer:\nsetwd(\u0026quot;Drive:/Folder1/Folder2\u0026quot;) If you are working with any of the example data files on this site, you will first need to download them to a folder on your computer and specify that folder as the working directory.  The layout of R Studio \nR Studio has four panels:\nThe top left panel is the editor (or script window) you can view your R script. Running code from here is a simple as Ctrl+Enter when the cursor is on the line or lines of code that you want to execute.\nThe bottom left panel is the console (or command window) where you can also run lines of code (write code next to \u0026gt; and press Enter), but also where any text or numerical output will appear.\nThe top right is the workspace window that lists the various R objects that you are currently using. These can be data sets or objects created by various analyses.\nThe panel on the bottom right has: lists of the files in your working directory the R packages that you are currently using any graphical output in the Plots window help files (accessed by ? preceding any bit of code)\nYou can change the size of these by dragging the edges of the windows.  Saving your code in a script \nYou should save all the code you use for a given analysis or graphic. Use the menus in R Studio to create a new R script (File \u0026gt;\u0026gt; New \u0026gt;\u0026gt; R script) and save that with the disk icon or menu (File \u0026gt;\u0026gt; Save). See Good practice for writing scripts for advice on how to structure these files.  Installing R packages \nIf your required analyses or graphics need a package that is not in the initial installation of R, then new packages can be installed from the menus (Tools \u0026gt;\u0026gt; Install packages) or from the panel on the bottom right. Once installed, they can be loaded with the library function (recommended) or by ticking the little box next to the package name (not recommended). It is better practice to use the library function in your script as that will remind you what packages need to be loaded.\nFor example, this code will load the package maptools if it is installed on your computer.\nlibrary(maptools) \n Further help \nOur help modules on Good practice for writing scripts and Importing data and data cleaning\nOnline help with R Studio\nOnline training in R Author: Alistair Poore Last updated:\n## [1] \u0026quot;Wed Jan 19 10:49:49 2022\u0026quot;  "
},
{
	"uri": "/graphics/spatial-vis/interactive/",
	"title": "Interactive maps in R",
	"tags": [],
	"description": "",
	"content": "             Being able to produce interactive maps on the fly can greatly speed up exploratory analysis and is a useful tool for displaying data that would be less informative on a static map.\nLeaflet is an open source JavaScript library that is used to create interactive maps on websites. In this post we will look at the the leaflet R package and create some cool interactive maps!\nInstallation The leaflet R package can be installed from CRAN by running:\ninstall.packages(\u0026quot;leaflet\u0026quot;)  Basics Creating a basic interactive map is simple!\nlibrary(leaflet) leaflet() %\u0026gt;% addTiles()  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]}]},\"evals\":[],\"jsHooks\":[]} The Leaflet R package has been designed to be used with pipes (%\u0026gt;%), which makes it easy to add layers and controls such as a scale bar and a mini map.\nMost of the time however we will have an area or a study site that we are interested in that we want to view:\nleaflet() %\u0026gt;% addTiles() %\u0026gt;% addScaleBar() %\u0026gt;% setView(lng = 151.2, lat = -33.86, zoom = 10) %\u0026gt;% addMiniMap()  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addMiniMap\",\"args\":[null,null,\"bottomright\",150,150,19,19,-5,false,false,false,false,false,false,{\"color\":\"#ff7800\",\"weight\":1,\"clickable\":false},{\"color\":\"#000000\",\"weight\":1,\"clickable\":false,\"opacity\":0,\"fillOpacity\":0},{\"hideText\":\"Hide MiniMap\",\"showText\":\"Show MiniMap\"},[]]}],\"setView\":[[-33.86,151.2],10,[]]},\"evals\":[],\"jsHooks\":[]}  Markers Lets plot some species occurence data from GBIF using the rgbif package: We will be displaying all eucalypt observations within the Macquarie Marshes region:\n## Getting the data # install.packages(\u0026#39;gbif\u0026#39;) library(rgbif) gbif_query \u0026lt;- occ_search(genusKey = 7493935, geometry = rgbif::gbif_bbox2wkt(minx = 147.8,miny = -30.6,maxx = 147.4,maxy = -31)) euc \u0026lt;- gbif_query$data euc$label \u0026lt;- paste(euc$name, \u0026#39;|\u0026#39;, euc$vernacularName, \u0026#39;|\u0026#39;, euc$year, \u0026#39;-\u0026#39;, month.abb[euc$month]) ## Warning: Unknown or uninitialised column: `vernacularName`. ## Creating a map base \u0026lt;- leaflet() %\u0026gt;% addTiles() %\u0026gt;% addScaleBar() %\u0026gt;% setView(lat = mean(euc$decimalLatitude), lng = mean(euc$decimalLongitude), zoom = 10) base %\u0026gt;% addMarkers(lng = euc$decimalLongitude, lat = euc$decimalLatitude, label = euc$label)  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addMarkers\",\"args\":[[-30.750814,-30.703291,-30.604462,-30.604462,-30.769092,-30.921591,-30.703291,-30.601113,-30.703291,-30.810721,-30.815145,-30.753627,-30.640037,-30.60431,-30.921591,-30.945585,-30.753627,-30.719613,-30.753627,-30.601113,-30.719613,-30.766362,-30.767348,-30.704111,-30.704111,-30.656114,-30.65522,-30.766121,-30.921591,-30.660411,-30.701996,-30.718844,-30.766362,-30.656114,-30.750814,-30.656114,-30.753627,-30.937148,-30.604462,-30.719613,-30.60431,-30.954014,-30.60431,-30.704111,-30.927857,-30.879618,-30.814503,-30.939658,-30.813377,-30.930152,-30.930152,-30.928292,-30.939658,-30.91317,-30.791342,-30.729886,-30.604363,-30.802549,-30.729886,-30.937148,-30.703291,-30.91317,-30.60431,-30.766362,-30.640037,-30.701996,-30.753627,-30.767348,-30.766362,-30.753627,-30.815145,-30.769092,-30.753627,-30.814503,-30.766362,-30.704111,-30.810721,-30.766121,-30.604462,-30.601113,-30.921591,-30.813377,-30.604462,-30.750814,-30.616533,-30.659222,-30.618136,-30.701186,-30.957967,-30.623736,-30.698339,-30.616533,-30.911464,-30.980719,-30.701186,-30.967936,-30.985558,-30.65522,-30.879618,-30.954014,-30.718844,-30.719613,-30.656114,-30.930152,-30.660411,-30.928292,-30.945585,-30.927857,-30.921452,-30.769092,-30.655197,-30.660409,-30.769092,-30.766392,-30.655197,-30.655197,-30.766392,-30.921452,-30.701973,-30.766392,-30.937037,-30.604462,-30.753627,-30.640037,-30.656114,-30.703291,-30.60431,-30.921591,-30.815145,-30.601113,-30.718844,-30.767348,-30.937148,-30.769092,-30.753627,-30.753627,-30.719613,-30.813377,-30.703291,-30.750814,-30.766362,-30.718844,-30.704111,-30.769092,-30.719613,-30.766362,-30.815145,-30.814503,-30.810721,-30.604462,-30.640037,-30.815145,-30.766362,-30.60431,-30.750814,-30.65522,-30.660411,-30.701996,-30.749466,-30.766121,-30.921591,-30.750814,-30.704111,-30.704082,-30.754485,-30.766131,-30.829983,-30.76399,-30.700046,-30.704082,-30.766225,-30.761738,-30.76399,-30.791342,-30.930152,-30.939658,-30.930152,-30.930152,-30.928292,-30.879618,-30.939658,-30.91317,-30.656114,-30.945585,-30.945585,-30.656114,-30.601113,-30.65522,-30.766362,-30.815145,-30.640037,-30.703291,-30.921591,-30.939658,-30.814503,-30.815145,-30.753627,-30.660411,-30.91317,-30.939658,-30.767348,-30.60431,-30.750814,-30.719613,-30.604462,-30.945585,-30.704111,-30.703291,-30.753627,-30.769092,-30.656114,-30.750814,-30.704111,-30.767348,-30.701996,-30.939658,-30.928292,-30.815145,-30.60431,-30.719613,-30.921591,-30.928292,-30.750814,-30.766121,-30.813377,-30.753627,-30.704111,-30.640037,-30.930152,-30.604462,-30.930152,-30.703291,-30.810721,-30.937148,-30.954014,-30.930152,-30.750814,-30.601113,-30.921591,-30.701996,-30.769092,-30.766362,-30.954014,-30.640037,-30.766362,-30.649431,-30.767348,-30.767348,-30.704111,-30.769092,-30.750814,-30.921591,-30.813377,-30.954014,-30.945585,-30.939658,-30.601113,-30.814503,-30.719613,-30.704111,-30.810721,-30.640037,-30.766362,-30.719613,-30.750814,-30.60431,-30.766121,-30.937148,-30.604462,-30.753627,-30.928292,-30.604462,-30.930152,-30.753627,-30.814503,-30.945585,-30.945585,-30.939658,-30.753627,-30.703291,-30.703291,-30.810721,-30.815145,-30.815145,-30.815145,-30.814503,-30.814503,-30.753627,-30.769092,-30.945585,-30.937148,-30.704111,-30.767348,-30.930152,-30.769092,-30.704111,-30.945585,-30.753627,-30.640037,-30.807249,-30.719613,-30.928292,-30.954014,-30.813377,-30.939658,-30.719613,-30.921591,-30.91317,-30.921591,-30.939658,-30.704111,-30.930152,-30.703291,-30.906377,-30.791342,-30.766362,-30.649431,-30.703291,-30.769092,-30.719613,-30.701996,-30.750814,-30.753627,-30.766121,-30.813377,-30.60431,-30.656114,-30.640037,-30.921591,-30.719613,-30.750814,-30.65522,-30.769092,-30.719613,-30.939658,-30.604462,-30.815145,-30.939658,-30.750814,-30.930152,-30.937148,-30.815145,-30.601113,-30.769092,-30.814503,-30.814503,-30.656114,-30.60431,-30.604462,-30.928292,-30.701996,-30.704111,-30.704111,-30.753627,-30.791342,-30.703291,-30.766121,-30.704111,-30.879618,-30.703291,-30.766612,-30.82503,-30.839146,-30.840318,-30.769828,-30.766362,-30.939658,-30.928292,-30.930152,-30.930152,-30.719613,-30.766121,-30.767348,-30.939658,-30.767348,-30.879618,-30.928292,-30.766371,-30.879618,-30.767267,-30.766371,-30.719613,-30.930152,-30.930152,-30.928292,-30.939676,-30.928292,-30.879618,-30.939676,-30.767267,-30.930152,-30.767267,-30.719613,-30.939676,-30.938446,-30.928292,-30.767267,-30.907631,-30.907631,-30.907113,-30.907113,-30.908284,-30.806428,-30.806428,-30.7957,-30.7957,-30.7957,-30.795688,-30.795688,-30.795688,-30.795688,-30.845656,-30.845726,-30.845656,-30.796766,-30.796766,-30.797001,-30.797001,-30.663997,-30.675933,-30.671777,-30.766594,-30.840372,-30.839,-30.766594,-30.839,-30.840372,-30.769828,-30.769828,-30.845441,-30.840318,-30.839146,-30.813377,-30.906377,-30.921591,-30.701996,-30.906377,-30.937148,-30.906377,-30.813377,-30.813377,-30.906377,-30.906377,-30.906377,-30.719613,-30.703291,-30.704111,-30.793352,-30.791342,-30.640037,-30.704111,-30.810721,-30.793452,-30.719613,-30.791342,-30.719613,-30.791342,-30.810721,-30.810721,-30.793452,-30.939658,-30.750814,-30.807249,-30.753627,-30.930152,-30.750814,-30.766121,-30.930152,-30.769092,-30.753627,-30.928292,-30.769092,-30.767348,-30.766362,-30.879618,-30.879618,-30.928292,-30.91317,-30.750814,-30.939658,-30.807249,-30.930152,-30.767267,-30.769137,-30.767267,-30.928292,-30.930152,-30.928292,-30.879618,-30.928292,-30.879618,-30.750813,-30.750813,-30.750813,-30.91272,-30.766371,-30.879618,-30.939676,-30.939676,-30.938446],[147.524845,147.5079,147.575984,147.575984,147.50976,147.543892,147.5079,147.567942,147.5079,147.513252,147.519486,147.544951,147.507757,147.577683,147.543892,147.582867,147.544951,147.591508,147.544951,147.567942,147.591508,147.526873,147.526178,147.508332,147.508332,147.587646,147.59574,147.539285,147.543892,147.597285,147.504593,147.597822,147.526873,147.587646,147.524845,147.587646,147.544951,147.566548,147.575984,147.591508,147.577683,147.578437,147.577683,147.508332,147.733051,147.687375,147.519597,147.741201,147.507903,147.727688,147.727688,147.734331,147.741201,147.504285,147.714527,147.497054,147.506215,147.4692,147.497054,147.566548,147.5079,147.504285,147.577683,147.526873,147.507757,147.504593,147.544951,147.526178,147.526873,147.544951,147.519486,147.50976,147.544951,147.519597,147.526873,147.508332,147.513252,147.539285,147.575984,147.567942,147.543892,147.507903,147.575984,147.524845,147.510589,147.494828,147.512542,147.502992,147.488953,147.505233,147.502228,147.510589,147.554778,147.481078,147.502992,147.479569,147.481461,147.59574,147.687375,147.578437,147.597822,147.591508,147.587646,147.727688,147.597285,147.734331,147.582867,147.733051,147.543637,147.50976,147.595752,147.597311,147.50976,147.526831,147.595752,147.595752,147.526831,147.543637,147.5046,147.526831,147.566653,147.575984,147.544951,147.507757,147.587646,147.5079,147.577683,147.543892,147.519486,147.567942,147.597822,147.526178,147.566548,147.50976,147.544951,147.544951,147.591508,147.507903,147.5079,147.524845,147.526873,147.597822,147.508332,147.50976,147.591508,147.526873,147.519486,147.519597,147.513252,147.575984,147.507757,147.519486,147.526873,147.577683,147.524845,147.59574,147.597285,147.504593,147.525694,147.539285,147.543892,147.524845,147.508332,147.508315,147.548517,147.539278,147.531095,147.510815,147.511105,147.508315,147.537397,147.562657,147.510815,147.714527,147.727688,147.741201,147.727688,147.727688,147.734331,147.687375,147.741201,147.504285,147.587646,147.582867,147.582867,147.587646,147.567942,147.59574,147.526873,147.519486,147.507757,147.5079,147.543892,147.741201,147.519597,147.519486,147.544951,147.597285,147.504285,147.741201,147.526178,147.577683,147.524845,147.591508,147.575984,147.582867,147.508332,147.5079,147.544951,147.50976,147.587646,147.524845,147.508332,147.526178,147.504593,147.741201,147.734331,147.519486,147.577683,147.591508,147.543892,147.734331,147.524845,147.539285,147.507903,147.544951,147.508332,147.507757,147.727688,147.575984,147.727688,147.5079,147.513252,147.566548,147.578437,147.727688,147.524845,147.567942,147.543892,147.504593,147.50976,147.526873,147.578437,147.507757,147.526873,147.519193,147.526178,147.526178,147.508332,147.50976,147.524845,147.543892,147.507903,147.578437,147.582867,147.741201,147.567942,147.519597,147.591508,147.508332,147.513252,147.507757,147.526873,147.591508,147.524845,147.577683,147.539285,147.566548,147.575984,147.544951,147.734331,147.575984,147.727688,147.544951,147.519597,147.582867,147.582867,147.741201,147.544951,147.5079,147.5079,147.513252,147.519486,147.519486,147.519486,147.519597,147.519597,147.544951,147.50976,147.582867,147.566548,147.508332,147.526178,147.727688,147.50976,147.508332,147.582867,147.544951,147.507757,147.674262,147.591508,147.734331,147.578437,147.507903,147.741201,147.591508,147.543892,147.504285,147.543892,147.741201,147.508332,147.727688,147.5079,147.484995,147.714527,147.526873,147.519193,147.5079,147.50976,147.591508,147.504593,147.524845,147.544951,147.539285,147.507903,147.577683,147.587646,147.507757,147.543892,147.591508,147.524845,147.59574,147.50976,147.591508,147.741201,147.575984,147.519486,147.741201,147.524845,147.727688,147.566548,147.519486,147.567942,147.50976,147.519597,147.519597,147.587646,147.577683,147.575984,147.734331,147.504593,147.508332,147.508332,147.544951,147.714527,147.5079,147.539285,147.508332,147.687375,147.5079,147.527501,147.524892,147.545978,147.541843,147.524373,147.526873,147.741201,147.734331,147.727688,147.727688,147.591508,147.539285,147.526178,147.741201,147.526178,147.687375,147.734331,147.526873,147.687375,147.526177,147.526873,147.591508,147.727688,147.727688,147.734331,147.741128,147.734331,147.687375,147.741128,147.526177,147.727688,147.526177,147.591508,147.741128,147.746331,147.734331,147.526177,147.485054,147.485054,147.486066,147.486066,147.489054,147.501229,147.501229,147.489142,147.489142,147.489142,147.490083,147.490083,147.490083,147.490083,147.49087,147.491414,147.49087,147.471744,147.471744,147.471724,147.471724,147.729068,147.75321,147.749409,147.527449,147.541864,147.546322,147.527449,147.546322,147.541864,147.524373,147.524373,147.542332,147.541843,147.545978,147.507903,147.484995,147.543892,147.504593,147.484995,147.566548,147.484995,147.507903,147.507903,147.484995,147.484995,147.484995,147.591508,147.5079,147.508332,147.706651,147.714527,147.507757,147.508332,147.513252,147.706641,147.591508,147.714527,147.591508,147.714527,147.513252,147.513252,147.706641,147.741201,147.524845,147.674262,147.544951,147.727688,147.524845,147.539285,147.727688,147.50976,147.544951,147.734331,147.50976,147.526178,147.526873,147.687375,147.687375,147.734331,147.504285,147.524845,147.741201,147.674262,147.727688,147.526177,147.509761,147.526177,147.734331,147.727688,147.734331,147.687375,147.734331,147.687375,147.525054,147.525054,147.525054,147.608935,147.526873,147.687375,147.741128,147.741128,147.746331],null,null,null,{\"interactive\":true,\"draggable\":false,\"keyboard\":true,\"title\":\"\",\"alt\":\"\",\"zIndexOffset\":0,\"opacity\":1,\"riseOnHover\":false,\"riseOffset\":250},null,null,null,null,[\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus largiflorens F.Muell. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus populnea F.Muell. | | 2017 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus populnea F.Muell. | | 2014 - May\",\"Eucalyptus largiflorens F.Muell. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus largiflorens F.Muell. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]}],\"setView\":[[-30.789030468,147.570597894],10,[]],\"limits\":{\"lat\":[-30.985558,-30.601113],\"lng\":[147.4692,147.75321]}},\"evals\":[],\"jsHooks\":[]}  Clustering markers Nice! but it is a bit cluttered, we can add clustering by specifying the clusterOptions argument to try and solve this issue:\nbase %\u0026gt;% addMarkers(lng = euc$decimalLongitude, lat = euc$decimalLatitude, clusterOptions = markerClusterOptions(), label = euc$label)  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addMarkers\",\"args\":[[-30.750814,-30.703291,-30.604462,-30.604462,-30.769092,-30.921591,-30.703291,-30.601113,-30.703291,-30.810721,-30.815145,-30.753627,-30.640037,-30.60431,-30.921591,-30.945585,-30.753627,-30.719613,-30.753627,-30.601113,-30.719613,-30.766362,-30.767348,-30.704111,-30.704111,-30.656114,-30.65522,-30.766121,-30.921591,-30.660411,-30.701996,-30.718844,-30.766362,-30.656114,-30.750814,-30.656114,-30.753627,-30.937148,-30.604462,-30.719613,-30.60431,-30.954014,-30.60431,-30.704111,-30.927857,-30.879618,-30.814503,-30.939658,-30.813377,-30.930152,-30.930152,-30.928292,-30.939658,-30.91317,-30.791342,-30.729886,-30.604363,-30.802549,-30.729886,-30.937148,-30.703291,-30.91317,-30.60431,-30.766362,-30.640037,-30.701996,-30.753627,-30.767348,-30.766362,-30.753627,-30.815145,-30.769092,-30.753627,-30.814503,-30.766362,-30.704111,-30.810721,-30.766121,-30.604462,-30.601113,-30.921591,-30.813377,-30.604462,-30.750814,-30.616533,-30.659222,-30.618136,-30.701186,-30.957967,-30.623736,-30.698339,-30.616533,-30.911464,-30.980719,-30.701186,-30.967936,-30.985558,-30.65522,-30.879618,-30.954014,-30.718844,-30.719613,-30.656114,-30.930152,-30.660411,-30.928292,-30.945585,-30.927857,-30.921452,-30.769092,-30.655197,-30.660409,-30.769092,-30.766392,-30.655197,-30.655197,-30.766392,-30.921452,-30.701973,-30.766392,-30.937037,-30.604462,-30.753627,-30.640037,-30.656114,-30.703291,-30.60431,-30.921591,-30.815145,-30.601113,-30.718844,-30.767348,-30.937148,-30.769092,-30.753627,-30.753627,-30.719613,-30.813377,-30.703291,-30.750814,-30.766362,-30.718844,-30.704111,-30.769092,-30.719613,-30.766362,-30.815145,-30.814503,-30.810721,-30.604462,-30.640037,-30.815145,-30.766362,-30.60431,-30.750814,-30.65522,-30.660411,-30.701996,-30.749466,-30.766121,-30.921591,-30.750814,-30.704111,-30.704082,-30.754485,-30.766131,-30.829983,-30.76399,-30.700046,-30.704082,-30.766225,-30.761738,-30.76399,-30.791342,-30.930152,-30.939658,-30.930152,-30.930152,-30.928292,-30.879618,-30.939658,-30.91317,-30.656114,-30.945585,-30.945585,-30.656114,-30.601113,-30.65522,-30.766362,-30.815145,-30.640037,-30.703291,-30.921591,-30.939658,-30.814503,-30.815145,-30.753627,-30.660411,-30.91317,-30.939658,-30.767348,-30.60431,-30.750814,-30.719613,-30.604462,-30.945585,-30.704111,-30.703291,-30.753627,-30.769092,-30.656114,-30.750814,-30.704111,-30.767348,-30.701996,-30.939658,-30.928292,-30.815145,-30.60431,-30.719613,-30.921591,-30.928292,-30.750814,-30.766121,-30.813377,-30.753627,-30.704111,-30.640037,-30.930152,-30.604462,-30.930152,-30.703291,-30.810721,-30.937148,-30.954014,-30.930152,-30.750814,-30.601113,-30.921591,-30.701996,-30.769092,-30.766362,-30.954014,-30.640037,-30.766362,-30.649431,-30.767348,-30.767348,-30.704111,-30.769092,-30.750814,-30.921591,-30.813377,-30.954014,-30.945585,-30.939658,-30.601113,-30.814503,-30.719613,-30.704111,-30.810721,-30.640037,-30.766362,-30.719613,-30.750814,-30.60431,-30.766121,-30.937148,-30.604462,-30.753627,-30.928292,-30.604462,-30.930152,-30.753627,-30.814503,-30.945585,-30.945585,-30.939658,-30.753627,-30.703291,-30.703291,-30.810721,-30.815145,-30.815145,-30.815145,-30.814503,-30.814503,-30.753627,-30.769092,-30.945585,-30.937148,-30.704111,-30.767348,-30.930152,-30.769092,-30.704111,-30.945585,-30.753627,-30.640037,-30.807249,-30.719613,-30.928292,-30.954014,-30.813377,-30.939658,-30.719613,-30.921591,-30.91317,-30.921591,-30.939658,-30.704111,-30.930152,-30.703291,-30.906377,-30.791342,-30.766362,-30.649431,-30.703291,-30.769092,-30.719613,-30.701996,-30.750814,-30.753627,-30.766121,-30.813377,-30.60431,-30.656114,-30.640037,-30.921591,-30.719613,-30.750814,-30.65522,-30.769092,-30.719613,-30.939658,-30.604462,-30.815145,-30.939658,-30.750814,-30.930152,-30.937148,-30.815145,-30.601113,-30.769092,-30.814503,-30.814503,-30.656114,-30.60431,-30.604462,-30.928292,-30.701996,-30.704111,-30.704111,-30.753627,-30.791342,-30.703291,-30.766121,-30.704111,-30.879618,-30.703291,-30.766612,-30.82503,-30.839146,-30.840318,-30.769828,-30.766362,-30.939658,-30.928292,-30.930152,-30.930152,-30.719613,-30.766121,-30.767348,-30.939658,-30.767348,-30.879618,-30.928292,-30.766371,-30.879618,-30.767267,-30.766371,-30.719613,-30.930152,-30.930152,-30.928292,-30.939676,-30.928292,-30.879618,-30.939676,-30.767267,-30.930152,-30.767267,-30.719613,-30.939676,-30.938446,-30.928292,-30.767267,-30.907631,-30.907631,-30.907113,-30.907113,-30.908284,-30.806428,-30.806428,-30.7957,-30.7957,-30.7957,-30.795688,-30.795688,-30.795688,-30.795688,-30.845656,-30.845726,-30.845656,-30.796766,-30.796766,-30.797001,-30.797001,-30.663997,-30.675933,-30.671777,-30.766594,-30.840372,-30.839,-30.766594,-30.839,-30.840372,-30.769828,-30.769828,-30.845441,-30.840318,-30.839146,-30.813377,-30.906377,-30.921591,-30.701996,-30.906377,-30.937148,-30.906377,-30.813377,-30.813377,-30.906377,-30.906377,-30.906377,-30.719613,-30.703291,-30.704111,-30.793352,-30.791342,-30.640037,-30.704111,-30.810721,-30.793452,-30.719613,-30.791342,-30.719613,-30.791342,-30.810721,-30.810721,-30.793452,-30.939658,-30.750814,-30.807249,-30.753627,-30.930152,-30.750814,-30.766121,-30.930152,-30.769092,-30.753627,-30.928292,-30.769092,-30.767348,-30.766362,-30.879618,-30.879618,-30.928292,-30.91317,-30.750814,-30.939658,-30.807249,-30.930152,-30.767267,-30.769137,-30.767267,-30.928292,-30.930152,-30.928292,-30.879618,-30.928292,-30.879618,-30.750813,-30.750813,-30.750813,-30.91272,-30.766371,-30.879618,-30.939676,-30.939676,-30.938446],[147.524845,147.5079,147.575984,147.575984,147.50976,147.543892,147.5079,147.567942,147.5079,147.513252,147.519486,147.544951,147.507757,147.577683,147.543892,147.582867,147.544951,147.591508,147.544951,147.567942,147.591508,147.526873,147.526178,147.508332,147.508332,147.587646,147.59574,147.539285,147.543892,147.597285,147.504593,147.597822,147.526873,147.587646,147.524845,147.587646,147.544951,147.566548,147.575984,147.591508,147.577683,147.578437,147.577683,147.508332,147.733051,147.687375,147.519597,147.741201,147.507903,147.727688,147.727688,147.734331,147.741201,147.504285,147.714527,147.497054,147.506215,147.4692,147.497054,147.566548,147.5079,147.504285,147.577683,147.526873,147.507757,147.504593,147.544951,147.526178,147.526873,147.544951,147.519486,147.50976,147.544951,147.519597,147.526873,147.508332,147.513252,147.539285,147.575984,147.567942,147.543892,147.507903,147.575984,147.524845,147.510589,147.494828,147.512542,147.502992,147.488953,147.505233,147.502228,147.510589,147.554778,147.481078,147.502992,147.479569,147.481461,147.59574,147.687375,147.578437,147.597822,147.591508,147.587646,147.727688,147.597285,147.734331,147.582867,147.733051,147.543637,147.50976,147.595752,147.597311,147.50976,147.526831,147.595752,147.595752,147.526831,147.543637,147.5046,147.526831,147.566653,147.575984,147.544951,147.507757,147.587646,147.5079,147.577683,147.543892,147.519486,147.567942,147.597822,147.526178,147.566548,147.50976,147.544951,147.544951,147.591508,147.507903,147.5079,147.524845,147.526873,147.597822,147.508332,147.50976,147.591508,147.526873,147.519486,147.519597,147.513252,147.575984,147.507757,147.519486,147.526873,147.577683,147.524845,147.59574,147.597285,147.504593,147.525694,147.539285,147.543892,147.524845,147.508332,147.508315,147.548517,147.539278,147.531095,147.510815,147.511105,147.508315,147.537397,147.562657,147.510815,147.714527,147.727688,147.741201,147.727688,147.727688,147.734331,147.687375,147.741201,147.504285,147.587646,147.582867,147.582867,147.587646,147.567942,147.59574,147.526873,147.519486,147.507757,147.5079,147.543892,147.741201,147.519597,147.519486,147.544951,147.597285,147.504285,147.741201,147.526178,147.577683,147.524845,147.591508,147.575984,147.582867,147.508332,147.5079,147.544951,147.50976,147.587646,147.524845,147.508332,147.526178,147.504593,147.741201,147.734331,147.519486,147.577683,147.591508,147.543892,147.734331,147.524845,147.539285,147.507903,147.544951,147.508332,147.507757,147.727688,147.575984,147.727688,147.5079,147.513252,147.566548,147.578437,147.727688,147.524845,147.567942,147.543892,147.504593,147.50976,147.526873,147.578437,147.507757,147.526873,147.519193,147.526178,147.526178,147.508332,147.50976,147.524845,147.543892,147.507903,147.578437,147.582867,147.741201,147.567942,147.519597,147.591508,147.508332,147.513252,147.507757,147.526873,147.591508,147.524845,147.577683,147.539285,147.566548,147.575984,147.544951,147.734331,147.575984,147.727688,147.544951,147.519597,147.582867,147.582867,147.741201,147.544951,147.5079,147.5079,147.513252,147.519486,147.519486,147.519486,147.519597,147.519597,147.544951,147.50976,147.582867,147.566548,147.508332,147.526178,147.727688,147.50976,147.508332,147.582867,147.544951,147.507757,147.674262,147.591508,147.734331,147.578437,147.507903,147.741201,147.591508,147.543892,147.504285,147.543892,147.741201,147.508332,147.727688,147.5079,147.484995,147.714527,147.526873,147.519193,147.5079,147.50976,147.591508,147.504593,147.524845,147.544951,147.539285,147.507903,147.577683,147.587646,147.507757,147.543892,147.591508,147.524845,147.59574,147.50976,147.591508,147.741201,147.575984,147.519486,147.741201,147.524845,147.727688,147.566548,147.519486,147.567942,147.50976,147.519597,147.519597,147.587646,147.577683,147.575984,147.734331,147.504593,147.508332,147.508332,147.544951,147.714527,147.5079,147.539285,147.508332,147.687375,147.5079,147.527501,147.524892,147.545978,147.541843,147.524373,147.526873,147.741201,147.734331,147.727688,147.727688,147.591508,147.539285,147.526178,147.741201,147.526178,147.687375,147.734331,147.526873,147.687375,147.526177,147.526873,147.591508,147.727688,147.727688,147.734331,147.741128,147.734331,147.687375,147.741128,147.526177,147.727688,147.526177,147.591508,147.741128,147.746331,147.734331,147.526177,147.485054,147.485054,147.486066,147.486066,147.489054,147.501229,147.501229,147.489142,147.489142,147.489142,147.490083,147.490083,147.490083,147.490083,147.49087,147.491414,147.49087,147.471744,147.471744,147.471724,147.471724,147.729068,147.75321,147.749409,147.527449,147.541864,147.546322,147.527449,147.546322,147.541864,147.524373,147.524373,147.542332,147.541843,147.545978,147.507903,147.484995,147.543892,147.504593,147.484995,147.566548,147.484995,147.507903,147.507903,147.484995,147.484995,147.484995,147.591508,147.5079,147.508332,147.706651,147.714527,147.507757,147.508332,147.513252,147.706641,147.591508,147.714527,147.591508,147.714527,147.513252,147.513252,147.706641,147.741201,147.524845,147.674262,147.544951,147.727688,147.524845,147.539285,147.727688,147.50976,147.544951,147.734331,147.50976,147.526178,147.526873,147.687375,147.687375,147.734331,147.504285,147.524845,147.741201,147.674262,147.727688,147.526177,147.509761,147.526177,147.734331,147.727688,147.734331,147.687375,147.734331,147.687375,147.525054,147.525054,147.525054,147.608935,147.526873,147.687375,147.741128,147.741128,147.746331],null,null,null,{\"interactive\":true,\"draggable\":false,\"keyboard\":true,\"title\":\"\",\"alt\":\"\",\"zIndexOffset\":0,\"opacity\":1,\"riseOnHover\":false,\"riseOffset\":250},null,null,{\"showCoverageOnHover\":true,\"zoomToBoundsOnClick\":true,\"spiderfyOnMaxZoom\":true,\"removeOutsideVisibleBounds\":true,\"spiderLegPolylineOptions\":{\"weight\":1.5,\"color\":\"#222\",\"opacity\":0.5},\"freezeAtZoom\":false},null,[\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus largiflorens F.Muell. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus populnea F.Muell. | | 2017 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus populnea F.Muell. | | 2014 - May\",\"Eucalyptus largiflorens F.Muell. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus largiflorens F.Muell. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]}],\"setView\":[[-30.789030468,147.570597894],10,[]],\"limits\":{\"lat\":[-30.985558,-30.601113],\"lng\":[147.4692,147.75321]}},\"evals\":[],\"jsHooks\":[]}  Colouring markers You can also add circle markers which can have custom colours, and add a legend:\ncolor_function \u0026lt;- colorFactor(\u0026quot;RdYlBu\u0026quot;, domain = NULL) base %\u0026gt;% addCircleMarkers(lng = euc$decimalLongitude, lat = euc$decimalLatitude, color = color_function(euc$name), label = euc$label) %\u0026gt;% addLegend(pal = color_function, values = euc$name)  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addCircleMarkers\",\"args\":[[-30.750814,-30.703291,-30.604462,-30.604462,-30.769092,-30.921591,-30.703291,-30.601113,-30.703291,-30.810721,-30.815145,-30.753627,-30.640037,-30.60431,-30.921591,-30.945585,-30.753627,-30.719613,-30.753627,-30.601113,-30.719613,-30.766362,-30.767348,-30.704111,-30.704111,-30.656114,-30.65522,-30.766121,-30.921591,-30.660411,-30.701996,-30.718844,-30.766362,-30.656114,-30.750814,-30.656114,-30.753627,-30.937148,-30.604462,-30.719613,-30.60431,-30.954014,-30.60431,-30.704111,-30.927857,-30.879618,-30.814503,-30.939658,-30.813377,-30.930152,-30.930152,-30.928292,-30.939658,-30.91317,-30.791342,-30.729886,-30.604363,-30.802549,-30.729886,-30.937148,-30.703291,-30.91317,-30.60431,-30.766362,-30.640037,-30.701996,-30.753627,-30.767348,-30.766362,-30.753627,-30.815145,-30.769092,-30.753627,-30.814503,-30.766362,-30.704111,-30.810721,-30.766121,-30.604462,-30.601113,-30.921591,-30.813377,-30.604462,-30.750814,-30.616533,-30.659222,-30.618136,-30.701186,-30.957967,-30.623736,-30.698339,-30.616533,-30.911464,-30.980719,-30.701186,-30.967936,-30.985558,-30.65522,-30.879618,-30.954014,-30.718844,-30.719613,-30.656114,-30.930152,-30.660411,-30.928292,-30.945585,-30.927857,-30.921452,-30.769092,-30.655197,-30.660409,-30.769092,-30.766392,-30.655197,-30.655197,-30.766392,-30.921452,-30.701973,-30.766392,-30.937037,-30.604462,-30.753627,-30.640037,-30.656114,-30.703291,-30.60431,-30.921591,-30.815145,-30.601113,-30.718844,-30.767348,-30.937148,-30.769092,-30.753627,-30.753627,-30.719613,-30.813377,-30.703291,-30.750814,-30.766362,-30.718844,-30.704111,-30.769092,-30.719613,-30.766362,-30.815145,-30.814503,-30.810721,-30.604462,-30.640037,-30.815145,-30.766362,-30.60431,-30.750814,-30.65522,-30.660411,-30.701996,-30.749466,-30.766121,-30.921591,-30.750814,-30.704111,-30.704082,-30.754485,-30.766131,-30.829983,-30.76399,-30.700046,-30.704082,-30.766225,-30.761738,-30.76399,-30.791342,-30.930152,-30.939658,-30.930152,-30.930152,-30.928292,-30.879618,-30.939658,-30.91317,-30.656114,-30.945585,-30.945585,-30.656114,-30.601113,-30.65522,-30.766362,-30.815145,-30.640037,-30.703291,-30.921591,-30.939658,-30.814503,-30.815145,-30.753627,-30.660411,-30.91317,-30.939658,-30.767348,-30.60431,-30.750814,-30.719613,-30.604462,-30.945585,-30.704111,-30.703291,-30.753627,-30.769092,-30.656114,-30.750814,-30.704111,-30.767348,-30.701996,-30.939658,-30.928292,-30.815145,-30.60431,-30.719613,-30.921591,-30.928292,-30.750814,-30.766121,-30.813377,-30.753627,-30.704111,-30.640037,-30.930152,-30.604462,-30.930152,-30.703291,-30.810721,-30.937148,-30.954014,-30.930152,-30.750814,-30.601113,-30.921591,-30.701996,-30.769092,-30.766362,-30.954014,-30.640037,-30.766362,-30.649431,-30.767348,-30.767348,-30.704111,-30.769092,-30.750814,-30.921591,-30.813377,-30.954014,-30.945585,-30.939658,-30.601113,-30.814503,-30.719613,-30.704111,-30.810721,-30.640037,-30.766362,-30.719613,-30.750814,-30.60431,-30.766121,-30.937148,-30.604462,-30.753627,-30.928292,-30.604462,-30.930152,-30.753627,-30.814503,-30.945585,-30.945585,-30.939658,-30.753627,-30.703291,-30.703291,-30.810721,-30.815145,-30.815145,-30.815145,-30.814503,-30.814503,-30.753627,-30.769092,-30.945585,-30.937148,-30.704111,-30.767348,-30.930152,-30.769092,-30.704111,-30.945585,-30.753627,-30.640037,-30.807249,-30.719613,-30.928292,-30.954014,-30.813377,-30.939658,-30.719613,-30.921591,-30.91317,-30.921591,-30.939658,-30.704111,-30.930152,-30.703291,-30.906377,-30.791342,-30.766362,-30.649431,-30.703291,-30.769092,-30.719613,-30.701996,-30.750814,-30.753627,-30.766121,-30.813377,-30.60431,-30.656114,-30.640037,-30.921591,-30.719613,-30.750814,-30.65522,-30.769092,-30.719613,-30.939658,-30.604462,-30.815145,-30.939658,-30.750814,-30.930152,-30.937148,-30.815145,-30.601113,-30.769092,-30.814503,-30.814503,-30.656114,-30.60431,-30.604462,-30.928292,-30.701996,-30.704111,-30.704111,-30.753627,-30.791342,-30.703291,-30.766121,-30.704111,-30.879618,-30.703291,-30.766612,-30.82503,-30.839146,-30.840318,-30.769828,-30.766362,-30.939658,-30.928292,-30.930152,-30.930152,-30.719613,-30.766121,-30.767348,-30.939658,-30.767348,-30.879618,-30.928292,-30.766371,-30.879618,-30.767267,-30.766371,-30.719613,-30.930152,-30.930152,-30.928292,-30.939676,-30.928292,-30.879618,-30.939676,-30.767267,-30.930152,-30.767267,-30.719613,-30.939676,-30.938446,-30.928292,-30.767267,-30.907631,-30.907631,-30.907113,-30.907113,-30.908284,-30.806428,-30.806428,-30.7957,-30.7957,-30.7957,-30.795688,-30.795688,-30.795688,-30.795688,-30.845656,-30.845726,-30.845656,-30.796766,-30.796766,-30.797001,-30.797001,-30.663997,-30.675933,-30.671777,-30.766594,-30.840372,-30.839,-30.766594,-30.839,-30.840372,-30.769828,-30.769828,-30.845441,-30.840318,-30.839146,-30.813377,-30.906377,-30.921591,-30.701996,-30.906377,-30.937148,-30.906377,-30.813377,-30.813377,-30.906377,-30.906377,-30.906377,-30.719613,-30.703291,-30.704111,-30.793352,-30.791342,-30.640037,-30.704111,-30.810721,-30.793452,-30.719613,-30.791342,-30.719613,-30.791342,-30.810721,-30.810721,-30.793452,-30.939658,-30.750814,-30.807249,-30.753627,-30.930152,-30.750814,-30.766121,-30.930152,-30.769092,-30.753627,-30.928292,-30.769092,-30.767348,-30.766362,-30.879618,-30.879618,-30.928292,-30.91317,-30.750814,-30.939658,-30.807249,-30.930152,-30.767267,-30.769137,-30.767267,-30.928292,-30.930152,-30.928292,-30.879618,-30.928292,-30.879618,-30.750813,-30.750813,-30.750813,-30.91272,-30.766371,-30.879618,-30.939676,-30.939676,-30.938446],[147.524845,147.5079,147.575984,147.575984,147.50976,147.543892,147.5079,147.567942,147.5079,147.513252,147.519486,147.544951,147.507757,147.577683,147.543892,147.582867,147.544951,147.591508,147.544951,147.567942,147.591508,147.526873,147.526178,147.508332,147.508332,147.587646,147.59574,147.539285,147.543892,147.597285,147.504593,147.597822,147.526873,147.587646,147.524845,147.587646,147.544951,147.566548,147.575984,147.591508,147.577683,147.578437,147.577683,147.508332,147.733051,147.687375,147.519597,147.741201,147.507903,147.727688,147.727688,147.734331,147.741201,147.504285,147.714527,147.497054,147.506215,147.4692,147.497054,147.566548,147.5079,147.504285,147.577683,147.526873,147.507757,147.504593,147.544951,147.526178,147.526873,147.544951,147.519486,147.50976,147.544951,147.519597,147.526873,147.508332,147.513252,147.539285,147.575984,147.567942,147.543892,147.507903,147.575984,147.524845,147.510589,147.494828,147.512542,147.502992,147.488953,147.505233,147.502228,147.510589,147.554778,147.481078,147.502992,147.479569,147.481461,147.59574,147.687375,147.578437,147.597822,147.591508,147.587646,147.727688,147.597285,147.734331,147.582867,147.733051,147.543637,147.50976,147.595752,147.597311,147.50976,147.526831,147.595752,147.595752,147.526831,147.543637,147.5046,147.526831,147.566653,147.575984,147.544951,147.507757,147.587646,147.5079,147.577683,147.543892,147.519486,147.567942,147.597822,147.526178,147.566548,147.50976,147.544951,147.544951,147.591508,147.507903,147.5079,147.524845,147.526873,147.597822,147.508332,147.50976,147.591508,147.526873,147.519486,147.519597,147.513252,147.575984,147.507757,147.519486,147.526873,147.577683,147.524845,147.59574,147.597285,147.504593,147.525694,147.539285,147.543892,147.524845,147.508332,147.508315,147.548517,147.539278,147.531095,147.510815,147.511105,147.508315,147.537397,147.562657,147.510815,147.714527,147.727688,147.741201,147.727688,147.727688,147.734331,147.687375,147.741201,147.504285,147.587646,147.582867,147.582867,147.587646,147.567942,147.59574,147.526873,147.519486,147.507757,147.5079,147.543892,147.741201,147.519597,147.519486,147.544951,147.597285,147.504285,147.741201,147.526178,147.577683,147.524845,147.591508,147.575984,147.582867,147.508332,147.5079,147.544951,147.50976,147.587646,147.524845,147.508332,147.526178,147.504593,147.741201,147.734331,147.519486,147.577683,147.591508,147.543892,147.734331,147.524845,147.539285,147.507903,147.544951,147.508332,147.507757,147.727688,147.575984,147.727688,147.5079,147.513252,147.566548,147.578437,147.727688,147.524845,147.567942,147.543892,147.504593,147.50976,147.526873,147.578437,147.507757,147.526873,147.519193,147.526178,147.526178,147.508332,147.50976,147.524845,147.543892,147.507903,147.578437,147.582867,147.741201,147.567942,147.519597,147.591508,147.508332,147.513252,147.507757,147.526873,147.591508,147.524845,147.577683,147.539285,147.566548,147.575984,147.544951,147.734331,147.575984,147.727688,147.544951,147.519597,147.582867,147.582867,147.741201,147.544951,147.5079,147.5079,147.513252,147.519486,147.519486,147.519486,147.519597,147.519597,147.544951,147.50976,147.582867,147.566548,147.508332,147.526178,147.727688,147.50976,147.508332,147.582867,147.544951,147.507757,147.674262,147.591508,147.734331,147.578437,147.507903,147.741201,147.591508,147.543892,147.504285,147.543892,147.741201,147.508332,147.727688,147.5079,147.484995,147.714527,147.526873,147.519193,147.5079,147.50976,147.591508,147.504593,147.524845,147.544951,147.539285,147.507903,147.577683,147.587646,147.507757,147.543892,147.591508,147.524845,147.59574,147.50976,147.591508,147.741201,147.575984,147.519486,147.741201,147.524845,147.727688,147.566548,147.519486,147.567942,147.50976,147.519597,147.519597,147.587646,147.577683,147.575984,147.734331,147.504593,147.508332,147.508332,147.544951,147.714527,147.5079,147.539285,147.508332,147.687375,147.5079,147.527501,147.524892,147.545978,147.541843,147.524373,147.526873,147.741201,147.734331,147.727688,147.727688,147.591508,147.539285,147.526178,147.741201,147.526178,147.687375,147.734331,147.526873,147.687375,147.526177,147.526873,147.591508,147.727688,147.727688,147.734331,147.741128,147.734331,147.687375,147.741128,147.526177,147.727688,147.526177,147.591508,147.741128,147.746331,147.734331,147.526177,147.485054,147.485054,147.486066,147.486066,147.489054,147.501229,147.501229,147.489142,147.489142,147.489142,147.490083,147.490083,147.490083,147.490083,147.49087,147.491414,147.49087,147.471744,147.471744,147.471724,147.471724,147.729068,147.75321,147.749409,147.527449,147.541864,147.546322,147.527449,147.546322,147.541864,147.524373,147.524373,147.542332,147.541843,147.545978,147.507903,147.484995,147.543892,147.504593,147.484995,147.566548,147.484995,147.507903,147.507903,147.484995,147.484995,147.484995,147.591508,147.5079,147.508332,147.706651,147.714527,147.507757,147.508332,147.513252,147.706641,147.591508,147.714527,147.591508,147.714527,147.513252,147.513252,147.706641,147.741201,147.524845,147.674262,147.544951,147.727688,147.524845,147.539285,147.727688,147.50976,147.544951,147.734331,147.50976,147.526178,147.526873,147.687375,147.687375,147.734331,147.504285,147.524845,147.741201,147.674262,147.727688,147.526177,147.509761,147.526177,147.734331,147.727688,147.734331,147.687375,147.734331,147.687375,147.525054,147.525054,147.525054,147.608935,147.526873,147.687375,147.741128,147.741128,147.746331],10,null,null,{\"interactive\":true,\"className\":\"\",\"stroke\":true,\"color\":[\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\"],\"weight\":5,\"opacity\":0.5,\"fill\":true,\"fillColor\":[\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\"],\"fillOpacity\":0.2},null,null,null,null,[\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus largiflorens F.Muell. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus populnea F.Muell. | | 2017 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus populnea F.Muell. | | 2014 - May\",\"Eucalyptus largiflorens F.Muell. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus largiflorens F.Muell. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]},{\"method\":\"addLegend\",\"args\":[{\"colors\":[\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#2C7BB6\"],\"labels\":[\"Eucalyptus camaldulensis Dehnh.\",\"Eucalyptus coolabah Blakely \u0026 Jacobs\",\"Eucalyptus largiflorens F.Muell.\",\"Eucalyptus populnea F.Muell.\"],\"na_color\":null,\"na_label\":\"NA\",\"opacity\":0.5,\"position\":\"topright\",\"type\":\"factor\",\"title\":null,\"extra\":null,\"layerId\":null,\"className\":\"info legend\",\"group\":null}]}],\"setView\":[[-30.789030468,147.570597894],10,[]],\"limits\":{\"lat\":[-30.985558,-30.601113],\"lng\":[147.4692,147.75321]}},\"evals\":[],\"jsHooks\":[]}  Other stuff to try out!  addMeasure() adds a ruler and an area estimator control to the map addProviderTiles() Other tiles (base maps) can be added by using this function. Try out: leaflet() %\u0026gt;% addProviderTiles(provider = providers$CartoDB) ! addLayersControl() adds a selector for choosing multiple layers if you have added them. addRasterImage() creates an image overlay from raster data! addGeoJSON() adds GeoJSON polygons to the interactive map!   Resources:  RStudios leaflet guide rgbif  Author: John Wilshire\nLast updated:\n## [1] \u0026quot;Thu Jan 20 16:18:25 2022\u0026quot;  "
},
{
	"uri": "/statistics/linear-models/linear-regression/interpret-lm-coeffs/",
	"title": "Interpreting Linear Regressions",
	"tags": [],
	"description": "",
	"content": "  The interpretation of coefficients in (generalized) linear models is more subtle than you many realise, and has consequences for how we test hypotheses and report findings. We will start by talking about marginal vs. conditional interpretations of model parameters.\nIn this example, we model plant height as a function of altitude and temperature. These variables are negatively correlated: it is colder the higher you go. We start by simulating some data to reflect this.\nlibrary(mvtnorm) # Specify the sample size N \u0026lt;- 1000 # Specify the correlation between altitude and temperature rho \u0026lt;- -0.4 # This line of code creates two correlated variables X = rmvnorm(N, mean = c(0, 0), sigma = matrix(c(1, rho, rho, 1), 2, 2)) # Extract the first and second columns to vectors named temp and alt and plot temp \u0026lt;- X[,1] alt \u0026lt;- X[,2] plot(temp, alt) Now we can simulate some data for height of plants. Here we say that the mean height of plants is 2 (when all the other variables are 0), as temperature increases by one unit (holding altitude constant), the mean of height will increase by 1 unit (beta[2] = 1), and similarly as you increase altitude by 1 unit (holding temperature constant) then mean height decreases by 1 (beta[3] = -1). Height is then normally distributed with this mean and standard deviation of 2.\nbeta \u0026lt;- c(2, 1, -1) mu \u0026lt;- beta[1]+beta[2]*temp+beta[3] * alt height \u0026lt;- rnorm(N, mu, sd = 2) If we use a linear model to find the coefficients we get what we expect, estimates very close to the true values.\nlm_both \u0026lt;- lm(height ~ temp + alt) data.frame(estimated = round(lm_both$coefficients, 2), true = beta) ## estimated true ## (Intercept) 2.02 2 ## temp 1.01 1 ## alt -1.04 -1 The interpretation of these coefficients is that if you hold everything else in the model constant (i.e., temperature) and add 1 to altitude, then the estimated mean height will decrease by 1.09. Note that the coefficient depends on the units in which altitude is measured. If altitude is in meters then the coefficient tells you what happens when you go up 1 meter.\nThe intercept is the predicted value when all the other variables are set to 0, which sometimes makes sense (here it would be the height of plants at sea level and 0 temperature). Other times 0 is not a meaningful value, and if you would like to interpret the intercept it might make sense to rescale your other variables so that their mean is 0. If you do this, then the intercept is the predicted value when all other variables are at their mean level.\nWhat if now we had a model with just temperature?\nlm1 \u0026lt;- lm(height ~ temp) lm1$coefficients ## (Intercept) temp ## 1.998396 1.446678 The coefficient of temperature is now 1.38, what’s going on? Altitude is an important predictor of plant height, and some of the information about altitude is contained in temperature (remember they are correlated, so as altitude increases temperature decreases). The model accounts for this by changing the effect of temperature to take account of the information it contains about altitude. Notice the coefficient of temperature is wrong by approximately 0.4, the amount of correlation between the variables.\nNote: When statisticians talk about this, they use the words conditional and marginal. Conditional is the effect of a variable when others are held constant (as in lm_both), while marginal is the overall effect (as in lm1). Note: If you use the code above to simulate your own data sets, you will get slightly different values for the coefficients. Testing hypotheses \nThis distinction has a lot of consequences for modelling as well as testing hypothesis. Let’s generate some data where altitude predicts height, and temperature has no (additional) information, and then test for temperature.\nmu \u0026lt;- 2-1*alt height \u0026lt;- rnorm(N, mu, sd = 2) mod_temp \u0026lt;- lm(height ~ temp) summary(mod_temp) ## ## Call: ## lm(formula = height ~ temp) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.2104 -1.4997 0.0369 1.4784 8.3233 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 1.87011 0.07373 25.364 \u0026lt; 2e-16 *** ## temp 0.48504 0.07253 6.687 3.79e-11 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 2.331 on 998 degrees of freedom ## Multiple R-squared: 0.04288, Adjusted R-squared: 0.04192 ## F-statistic: 44.72 on 1 and 998 DF, p-value: 3.787e-11 anova(mod_temp) ## Analysis of Variance Table ## ## Response: height ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## temp 1 243.0 243.039 44.716 3.787e-11 *** ## Residuals 998 5424.3 5.435 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 The output of this model is telling us there is an effect of temperature, even though technically there isn’t. It is not giving us false information if you understand how to interpret model outputs. Because temperature is correlated with altitude, and there is an effect of altitude, when altitude is not in the model, the model tells us overall there is an effect of temperature of increasing height by 0.45 (remember the correlation was 0.4). If our hypothesis is ‘Does plant height change with temperature?’, the answer is yes, the higher the temperature, the taller the plants.\nBut what about altitude? We know the temperature effect we observe is because it is correlated with altitude, temperature does not directly predict height. If we want to know if there is an effect of temperature after controlling for altitude (holding altitude constant, so conditional), then we fit the model with altitude and then test for temperature.\nmod_temp_alt \u0026lt;- lm(height ~ alt + temp) summary(mod_temp_alt) ## ## Call: ## lm(formula = height ~ alt + temp) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.9937 -1.5099 -0.0422 1.4041 6.6359 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 1.89584 0.06662 28.460 \u0026lt;2e-16 *** ## alt -1.03719 0.06893 -15.048 \u0026lt;2e-16 *** ## temp 0.04692 0.07169 0.654 0.513 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 2.106 on 997 degrees of freedom ## Multiple R-squared: 0.22, Adjusted R-squared: 0.2185 ## F-statistic: 140.6 on 2 and 997 DF, p-value: \u0026lt; 2.2e-16 anova(mod_temp_alt) ## Analysis of Variance Table ## ## Response: height ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## alt 1 1245.1 1245.11 280.8313 \u0026lt;2e-16 *** ## temp 1 1.9 1.90 0.4283 0.513 ## Residuals 997 4420.4 4.43 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 The p-value is about 0.95, so we have no evidence of an effect of temperature after controlling for altitude.\nNote: The distinction between conditional and marginal interpretations is also true for generalised linear models and mixed models.  Categorical covariates \nWhen we have categorical covariates (for example treatment), there are a number of ways to code the model, which will give different interpretations for the coefficients. Let’s simulate 120 data points with 40 in each of three levels of a categorical treatment.\nN \u0026lt;- 120 # The effect of treatment trt.n \u0026lt;- rep(c(-1, 0, 1), N/3) mu \u0026lt;- 2+1*trt.n # Labels for the treatment treatment \u0026lt;- factor(rep(c(\u0026quot;low\u0026quot;, \u0026quot;med\u0026quot;, \u0026quot;high\u0026quot;), N/3))#group labels # Create, Y, a normally distributed response variable and plot against treatment Y \u0026lt;- rnorm(N, mu, sd = 2) boxplot(Y ~ treatment) If we put treatment in as a covariate the normal way, the model will choose a reference treatment (here it will be high as the levels get sorted alphabetically), so that the intercept will be the mean of this reference group. The other coefficients will be the differences between the other groups and the reference group.\ncat_lm \u0026lt;- lm(Y ~ treatment) summary(cat_lm) ## ## Call: ## lm(formula = Y ~ treatment) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.8329 -1.0412 -0.0122 1.1283 5.6437 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 2.9685 0.2896 10.252 \u0026lt; 2e-16 *** ## treatmentlow -1.8125 0.4095 -4.426 2.17e-05 *** ## treatmentmed -0.9605 0.4095 -2.346 0.0207 * ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.831 on 117 degrees of freedom ## Multiple R-squared: 0.1436, Adjusted R-squared: 0.1289 ## F-statistic: 9.808 on 2 and 117 DF, p-value: 0.0001154 So here group “high” has a mean of 2.65, and the difference between the means of group “low” and group “high” is -0.66, and the difference between group “med” and group “high” is -1.48. If you would like to have another group as the reference group, you can use relevel to recode your treatment factor.\ntreatment \u0026lt;- relevel(treatment, ref = \u0026quot;low\u0026quot;) cat_lm \u0026lt;- lm(Y ~ treatment) summary(cat_lm) ## ## Call: ## lm(formula = Y ~ treatment) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.8329 -1.0412 -0.0122 1.1283 5.6437 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 1.1560 0.2896 3.992 0.000115 *** ## treatmenthigh 1.8125 0.4095 4.426 2.17e-05 *** ## treatmentmed 0.8520 0.4095 2.081 0.039643 * ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.831 on 117 degrees of freedom ## Multiple R-squared: 0.1436, Adjusted R-squared: 0.1289 ## F-statistic: 9.808 on 2 and 117 DF, p-value: 0.0001154 boxplot(Y ~ treatment) Now the intercept is the mean of group “low”, and all the other coefficients are the differences between group “low” and the others. Another thing you can do is to put -1 in the model to get rid of the intercept, and just have the means of each group as coefficients.\ncat_lm \u0026lt;- lm(Y ~ treatment - 1) summary(cat_lm) ## ## Call: ## lm(formula = Y ~ treatment - 1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.8329 -1.0412 -0.0122 1.1283 5.6437 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## treatmentlow 1.1560 0.2896 3.992 0.000115 *** ## treatmenthigh 2.9685 0.2896 10.252 \u0026lt; 2e-16 *** ## treatmentmed 2.0080 0.2896 6.935 2.39e-10 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 1.831 on 117 degrees of freedom ## Multiple R-squared: 0.5911, Adjusted R-squared: 0.5806 ## F-statistic: 56.38 on 3 and 117 DF, p-value: \u0026lt; 2.2e-16 Now, the three coefficients are the mean of the groups.\nContrasting the coefficients We can also look at contrasts; these are the difference between all pairs of groups. Load the package multcomp and use glht (general linear hypotheses) to examine all pair-wise differences.\nlibrary(multcomp) cont \u0026lt;- glht(cat_lm, linfct = mcp(treatment = \u0026quot;Tukey\u0026quot;)) summary(cont) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = Y ~ treatment - 1) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## high - low == 0 1.8125 0.4095 4.426 \u0026lt;0.001 *** ## med - low == 0 0.8520 0.4095 2.081 0.0983 . ## med - high == 0 -0.9605 0.4095 -2.346 0.0536 . ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## (Adjusted p values reported -- single-step method) Each line of this output compares two groups against one another. The first line, for example, compares the “high” group to the “low” group. So the difference between the means of the “high” and “low” groups is 1.84. The p-values and the confidence intervals given byglht control for multiple testing, which is handy. If you want to see the confidence intervals for the differences between the groups.\nconfint(cont) ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: lm(formula = Y ~ treatment - 1) ## ## Quantile = 2.3741 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## high - low == 0 1.81251 0.84034 2.78468 ## med - low == 0 0.85203 -0.12014 1.82420 ## med - high == 0 -0.96048 -1.93265 0.01169 Note: In a model with multiple covariates, the same rules still apply in terms of conditional and marginal interpretations of coefficients. Interpreting coefficients in generalised linear models In linear models, the interpretation of model parameters is linear, as discussed above. For generalised linear models, now read the tutorial page on interpreting coefficients in those models. Author: Gordana Popovic Last updated:\n## [1] \u0026quot;Fri Jan 21 17:03:40 2022\u0026quot;  "
},
{
	"uri": "/statistics/meta-analysis/meta-analysis-1/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "  Background What is a meta-analysis?\n A meta-analysis is a quantitative summary of studies on the same topic.\n Why do we want to perform a meta-analysis?\nFinding generalities Increasing power and precision Exploring differences between studies Settling controversies from conflicting studies (testing hypotheses) Generating new hypotheses  The process of meta-analysis\nHow many steps involved in meta-analysis?\nOne answer is 5 steps\nFormulating questions \u0026amp; hypothesis or finding a topic Literature search \u0026amp; paper collection Data extraction \u0026amp; coding Meta-analysis \u0026amp; publication bias tests Reporting \u0026amp; publication  We only consider the step iv in this tutorial. You will need to learn the other steps elsewhere. To get you started, we recently wrote an overview paper which divides the process of meta-analysis into 10 questions (Nakagawa et al. 2017). The 10 questions will guide you through judging the quality of a meta-analysis.\nIs the search systematic and transparently documented? What question and what effect size? Is non-independence taken into account? Which meta-analytic model? Is the level of consistency among studies reported? Are the causes of variation among studies investigated? Are effects interpreted in terms of biological importance? Has publication bias been considered? Are results really robust and unbiased? Is the current state (and lack) of knowledge summarized?   Metafor for meta-analysis I think the R package metafor (Viechtbauer 2010) is the most comprehensive meta-analytic software and the author Wolfgang Viechtbauer, who, I have to say, has the coolest name among my friends, is still actively developing it.\nFirst, install and load the metafor package.\nlibrary(metafor) Have a look at the data set named dat.curtis1998 included in the package. If you have to see the other data sets included in this package, try help(package=\"metafor\").\ndat \u0026lt;- get(data(dat.curtis1998)) str(dat) ## \u0026#39;data.frame\u0026#39;: 102 obs. of 20 variables: ## $ id : int 21 22 27 32 35 38 44 63 86 87 ... ## $ paper : int 44 44 121 121 121 121 159 183 209 209 ... ## $ genus : chr \u0026quot;ALNUS\u0026quot; \u0026quot;ALNUS\u0026quot; \u0026quot;ACER\u0026quot; \u0026quot;QUERCUS\u0026quot; ... ## $ species : chr \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRUM\u0026quot; \u0026quot;PRINUS\u0026quot; ... ## $ fungrp : chr \u0026quot;N2FIX\u0026quot; \u0026quot;N2FIX\u0026quot; \u0026quot;ANGIO\u0026quot; \u0026quot;ANGIO\u0026quot; ... ## $ co2.ambi: num 350 350 350 350 350 350 350 395 350 350 ... ## $ co2.elev: num 650 650 700 700 700 700 700 795 700 700 ... ## $ units : chr \u0026quot;ul/l\u0026quot; \u0026quot;ul/l\u0026quot; \u0026quot;ppm\u0026quot; \u0026quot;ppm\u0026quot; ... ## $ time : int 47 47 59 70 64 50 730 365 365 365 ... ## $ pot : chr \u0026quot;0.5\u0026quot; \u0026quot;0.5\u0026quot; \u0026quot;2.6\u0026quot; \u0026quot;2.6\u0026quot; ... ## $ method : chr \u0026quot;GC\u0026quot; \u0026quot;GC\u0026quot; \u0026quot;GH\u0026quot; \u0026quot;GH\u0026quot; ... ## $ stock : chr \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; ... ## $ xtrt : chr \u0026quot;FERT\u0026quot; \u0026quot;FERT\u0026quot; \u0026quot;NONE\u0026quot; \u0026quot;NONE\u0026quot; ... ## $ level : chr \u0026quot;HIGH\u0026quot; \u0026quot;CONTROL\u0026quot; \u0026quot;.\u0026quot; \u0026quot;.\u0026quot; ... ## $ m1i : num 6.82 2.6 2.99 5.91 4.61 ... ## $ sd1i : num 1.77 0.667 0.856 1.742 1.407 ... ## $ n1i : int 3 5 5 5 4 5 3 3 20 16 ... ## $ m2i : num 3.94 2.25 1.93 6.62 4.1 ... ## $ sd2i : num 1.116 0.328 0.552 1.631 1.257 ... ## $ n2i : int 5 5 5 5 4 3 3 3 20 16 ... This data set is from the paper by Curtis and Wang (1998). They looked at the effect of increased CO\\(_2\\) on plant traits (mainly changes in biomass). So we have information on control group (1) and experimental group (2) (m = mean, sd = standard deviation) along with species information and experimental details. In meta-analysis, these variables are often referred to as ‘moderators’ (we will get to this a bit later).\n Calculating ‘standardized’ effect sizes To compare the effect of increased CO\\(_2\\) across multiple studies, we first need to calculate an effect size for each study - a metric that quantifies the difference between our control and experimental groups.\nThere are several ‘standardized’ effect sizes, which are unit-less. When we have two groups to compare, we use two types of effect size statistics. The first one is standardized mean difference (SMD or also known as Cohen’s \\(d\\) or Hedge’s \\(d\\) or \\(g\\); some subtle differences between them, but we do not worry about them for now):\n\\[\\begin{equation} \\mathrm{SMD}=\\frac{\\bar{x}_{E}-\\bar{x}_{C}}{\\sqrt{\\frac{(n_{C}-1)sd^2_{C}+(n_{E}-1)sd^2_{E}}{n_{C}+n_{E}-2}}} \\end{equation}\\] where \\(\\bar{x}_{C}\\) and \\(\\bar{x}_{E}\\) are the means of the control and experimental group, respectively, \\(sd\\) is sample standard deviation (\\(sd^2\\) is sample variance) and \\(n\\) is sample size.\nAnd its sample error variance is:\n\\[\\begin{equation} se^2_{\\mathrm{SMD}}= \\frac{n_{C}+n_{E}}{n_{C}n_{E}}+\\frac{\\mathrm{SMD}^2}{2(n_{C}+n_{E})} \\end{equation}\\]\nThe square root of this is referred to as ‘standard error’ (or the standard deviation of the estimate – confused?). The inverse of this (\\(1/se^2\\)) is used as ‘weight’, but things are bit more complicated than this as we will find out below.\nAnother common index is called ‘response ratio’, which is usually presented in its natural logarithm form (lnRR):\n\\[\\begin{equation} \\mathrm{lnRR}=\\ln\\left({\\frac{\\bar{x}_{E}}{\\bar{x}_{C}}}\\right) \\end{equation}\\]\nAnd its sampling error variance is:\n\\[\\begin{equation} se^2_\\mathrm{lnRR}=\\frac{sd^2_{C}}{n_{C}\\bar{x}^2_{C}}+\\frac{sd^2_{E}}{n_{E}\\bar{x}^2_{E}} \\end{equation}\\]\nLet’s get these using the function escalc in metafor. To obtain the standardised mean difference, we use:\n# SMD SMD \u0026lt;- escalc(measure = \u0026quot;SMD\u0026quot;, n1i = dat$n1i, n2i = dat$n2i, m1i = dat$m1i, m2i = dat$m2i, sd1i = dat$sd1i, sd2i = dat$sd2i) where n1i and n2i are the sample sizes, m1i and m2i are the means, and sd1i and sd2i the standard deviations from each study.\nThe oject created now has an effect size (yi) and its variance (vi) for each study\n## yi vi ## 1 1.8222 0.7408 ## 2 0.5922 0.4175 ## 3 1.3286 0.4883 ## 4 -0.3798 0.4072 ## 5 0.3321 0.5069 ## 6 2.5137 0.9282 To obtain the response ratio (log transformed ratio of menas), we would use:\nlnRR \u0026lt;- escalc(measure = \u0026quot;ROM\u0026quot;, n1i = dat$n1i, n2i = dat$n2i, m1i = dat$m1i, m2 = dat$m2i, sd1i = dat$sd1i, sd2i = dat$sd2i) The original paper used lnRR so we will use it, but you may want to repeat analysis below using SMD to see whether results are consistent.\nAdd the effect sizes to the original data set with cbind or bind_cols from the package dplyr\nlibrary(dplyr) dat \u0026lt;- bind_cols(dat, lnRR) You should see yi (effec size) and vi (sampling variance) are added.\n## \u0026#39;data.frame\u0026#39;: 102 obs. of 22 variables: ## $ id : int 21 22 27 32 35 38 44 63 86 87 ... ## $ paper : int 44 44 121 121 121 121 159 183 209 209 ... ## $ genus : chr \u0026quot;ALNUS\u0026quot; \u0026quot;ALNUS\u0026quot; \u0026quot;ACER\u0026quot; \u0026quot;QUERCUS\u0026quot; ... ## $ species : chr \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRUM\u0026quot; \u0026quot;PRINUS\u0026quot; ... ## $ fungrp : chr \u0026quot;N2FIX\u0026quot; \u0026quot;N2FIX\u0026quot; \u0026quot;ANGIO\u0026quot; \u0026quot;ANGIO\u0026quot; ... ## $ co2.ambi: num 350 350 350 350 350 350 350 395 350 350 ... ## $ co2.elev: num 650 650 700 700 700 700 700 795 700 700 ... ## $ units : chr \u0026quot;ul/l\u0026quot; \u0026quot;ul/l\u0026quot; \u0026quot;ppm\u0026quot; \u0026quot;ppm\u0026quot; ... ## $ time : int 47 47 59 70 64 50 730 365 365 365 ... ## $ pot : chr \u0026quot;0.5\u0026quot; \u0026quot;0.5\u0026quot; \u0026quot;2.6\u0026quot; \u0026quot;2.6\u0026quot; ... ## $ method : chr \u0026quot;GC\u0026quot; \u0026quot;GC\u0026quot; \u0026quot;GH\u0026quot; \u0026quot;GH\u0026quot; ... ## $ stock : chr \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; ... ## $ xtrt : chr \u0026quot;FERT\u0026quot; \u0026quot;FERT\u0026quot; \u0026quot;NONE\u0026quot; \u0026quot;NONE\u0026quot; ... ## $ level : chr \u0026quot;HIGH\u0026quot; \u0026quot;CONTROL\u0026quot; \u0026quot;.\u0026quot; \u0026quot;.\u0026quot; ... ## $ m1i : num 6.82 2.6 2.99 5.91 4.61 ... ## $ sd1i : num 1.77 0.667 0.856 1.742 1.407 ... ## $ n1i : int 3 5 5 5 4 5 3 3 20 16 ... ## $ m2i : num 3.94 2.25 1.93 6.62 4.1 ... ## $ sd2i : num 1.116 0.328 0.552 1.631 1.257 ... ## $ n2i : int 5 5 5 5 4 3 3 3 20 16 ... ## $ yi : num 0.547 0.143 0.438 -0.113 0.117 ... ## ..- attr(*, \u0026quot;ni\u0026quot;)= int [1:102] 8 10 10 10 8 8 6 6 40 32 ... ## ..- attr(*, \u0026quot;measure\u0026quot;)= chr \u0026quot;ROM\u0026quot; ## $ vi : num 0.0385 0.0175 0.0328 0.0295 0.0468 ... Visualising effect size. We can visualize point estimates (effect size) and their 95% confidence intervals, CIs (based on sampling error variance) by using the forest function, which draws a forest plot for us.\nforest(dat$yi, dat$vi) The problem you see is that when there are many studies, a forest plot does not really work (unless you have very large screen!). Let’s look at just the first 12 studies.\nforest(dat$yi[1:12], dat$vi[1:12]) We can calculate many different kinds of effect sizes with escalc; other common effect size statistics include \\(Zr\\) (Fisher’s z-transformed correlation). By the way, along with my colleagues, I have proposed a new standardized effect size called lnCVR (the log of coefficient of variation ratio – mouthful!), which compares the variability of two groups rather than means. See whether you can calculate it with these data. Actually, the development version of metafor, let you do this with escalc– github page. lnCVR is called “CVR” in escalc. Actually, if you re-analysis this data with lnCVR, you may be able to publish a paper! Nobody has done it yet. Do it tonight!\nOnce you have calculated effect sizes, move on to the next page: Meta-analysis 2: fixed-effect and random-effect models\n Further help (references) Go to the metafor package’s website. There you find many worked examples.\nCurtis, P. S., and X. Z. Wang. 1998. A meta-analysis of elevated CO2 effects on woody plant mass, form, and physiology. Oecologia 113:299-313. Nakagawa, S., R. Poulin, K. Mengersen, K. Reinhold, L. Engqvist, M. Lagisz, and A. M. Senior. 2015. Meta-analysis of variation: ecological and evolutionary applications and beyond. Methods in Ecology and Evolution 6:143-152. Viechtbauer, W. 2010. Conducting meta-analyses in R with the metafor package. Journal of Statistical Software 36:1-48. Authors: Shinichi Nakagawa and Malgorzata (Losia) Lagisz Last updated:\n## [1] \u0026quot;Mon Jan 24 12:56:42 2022\u0026quot;  "
},
{
	"uri": "/statistics/meta-analysis/meta-analysis-2/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "  Background What is a meta-analysis?\n A meta-analysis is a quantitative summary of studies on the same topic.\n Why do we want to perform a meta-analysis?\nFinding generalities Increasing power and precision Exploring differences between studies Settling controversies from conflicting studies (testing hypotheses) Generating new hypotheses  The process of meta-analysis\nHow many steps involved in meta-analysis?\nOne answer is 5 steps\nFormulating questions \u0026amp; hypothesis or finding a topic Literature search \u0026amp; paper collection Data extraction \u0026amp; coding Meta-analysis \u0026amp; publication bias tests Reporting \u0026amp; publication  We only consider the step iv in this tutorial. You will need to learn the other steps elsewhere. To get you started, we recently wrote an overview paper which divides the process of meta-analysis into 10 questions (Nakagawa et al. 2017). The 10 questions will guide you through judging the quality of a meta-analysis.\nIs the search systematic and transparently documented? What question and what effect size? Is non-independence taken into account? Which meta-analytic model? Is the level of consistency among studies reported? Are the causes of variation among studies investigated? Are effects interpreted in terms of biological importance? Has publication bias been considered? Are results really robust and unbiased? Is the current state (and lack) of knowledge summarized?   Metafor for meta-analysis I think the R package metafor (Viechtbauer 2010) is the most comprehensive meta-analytic software and the author Wolfgang Viechtbauer, who, I have to say, has the coolest name among my friends, is still actively developing it.\nFirst, install and load the metafor package.\nlibrary(metafor) Have a look at the data set named dat.curtis1998 included in the package. If you have to see the other data sets included in this package, try help(package=\"metafor\").\ndat \u0026lt;- get(data(dat.curtis1998)) str(dat) ## \u0026#39;data.frame\u0026#39;: 102 obs. of 20 variables: ## $ id : int 21 22 27 32 35 38 44 63 86 87 ... ## $ paper : int 44 44 121 121 121 121 159 183 209 209 ... ## $ genus : chr \u0026quot;ALNUS\u0026quot; \u0026quot;ALNUS\u0026quot; \u0026quot;ACER\u0026quot; \u0026quot;QUERCUS\u0026quot; ... ## $ species : chr \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRUM\u0026quot; \u0026quot;PRINUS\u0026quot; ... ## $ fungrp : chr \u0026quot;N2FIX\u0026quot; \u0026quot;N2FIX\u0026quot; \u0026quot;ANGIO\u0026quot; \u0026quot;ANGIO\u0026quot; ... ## $ co2.ambi: num 350 350 350 350 350 350 350 395 350 350 ... ## $ co2.elev: num 650 650 700 700 700 700 700 795 700 700 ... ## $ units : chr \u0026quot;ul/l\u0026quot; \u0026quot;ul/l\u0026quot; \u0026quot;ppm\u0026quot; \u0026quot;ppm\u0026quot; ... ## $ time : int 47 47 59 70 64 50 730 365 365 365 ... ## $ pot : chr \u0026quot;0.5\u0026quot; \u0026quot;0.5\u0026quot; \u0026quot;2.6\u0026quot; \u0026quot;2.6\u0026quot; ... ## $ method : chr \u0026quot;GC\u0026quot; \u0026quot;GC\u0026quot; \u0026quot;GH\u0026quot; \u0026quot;GH\u0026quot; ... ## $ stock : chr \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; ... ## $ xtrt : chr \u0026quot;FERT\u0026quot; \u0026quot;FERT\u0026quot; \u0026quot;NONE\u0026quot; \u0026quot;NONE\u0026quot; ... ## $ level : chr \u0026quot;HIGH\u0026quot; \u0026quot;CONTROL\u0026quot; \u0026quot;.\u0026quot; \u0026quot;.\u0026quot; ... ## $ m1i : num 6.82 2.6 2.99 5.91 4.61 ... ## $ sd1i : num 1.77 0.667 0.856 1.742 1.407 ... ## $ n1i : int 3 5 5 5 4 5 3 3 20 16 ... ## $ m2i : num 3.94 2.25 1.93 6.62 4.1 ... ## $ sd2i : num 1.116 0.328 0.552 1.631 1.257 ... ## $ n2i : int 5 5 5 5 4 3 3 3 20 16 ... This data set is from the paper by Curtis and Wang (1998). They looked at the effect of increased CO\\(_2\\) on plant traits (mainly changes in biomass). So we have information on control group (1) and experimental group (2) (m = mean, sd = standard deviation) along with species information and experimental details. In meta-analysis, these variables are often referred to as ‘moderators’ (we will get to this a bit later).\n Calculating ‘standardized’ effect sizes To compare the effect of increased CO\\(_2\\) across multiple studies, we first need to calculate an effect size for each study - a metric that quantifies the difference between our control and experimental groups.\nThere are several ‘standardized’ effect sizes, which are unit-less. When we have two groups to compare, we use two types of effect size statistics. The first one is standardized mean difference (SMD or also known as Cohen’s \\(d\\) or Hedge’s \\(d\\) or \\(g\\); some subtle differences between them, but we do not worry about them for now):\n\\[\\begin{equation} \\mathrm{SMD}=\\frac{\\bar{x}_{E}-\\bar{x}_{C}}{\\sqrt{\\frac{(n_{C}-1)sd^2_{C}+(n_{E}-1)sd^2_{E}}{n_{C}+n_{E}-2}}} \\end{equation}\\] where \\(\\bar{x}_{C}\\) and \\(\\bar{x}_{E}\\) are the means of the control and experimental group, respectively, \\(sd\\) is sample standard deviation (\\(sd^2\\) is sample variance) and \\(n\\) is sample size.\nAnd its sample error variance is:\n\\[\\begin{equation} se^2_{\\mathrm{SMD}}= \\frac{n_{C}+n_{E}}{n_{C}n_{E}}+\\frac{\\mathrm{SMD}^2}{2(n_{C}+n_{E})} \\end{equation}\\]\nThe square root of this is referred to as ‘standard error’ (or the standard deviation of the estimate – confused?). The inverse of this (\\(1/se^2\\)) is used as ‘weight’, but things are bit more complicated than this as we will find out below.\nAnother common index is called ‘response ratio’, which is usually presented in its natural logarithm form (lnRR):\n\\[\\begin{equation} \\mathrm{lnRR}=\\ln\\left({\\frac{\\bar{x}_{E}}{\\bar{x}_{C}}}\\right) \\end{equation}\\]\nAnd its sampling error variance is:\n\\[\\begin{equation} se^2_\\mathrm{lnRR}=\\frac{sd^2_{C}}{n_{C}\\bar{x}^2_{C}}+\\frac{sd^2_{E}}{n_{E}\\bar{x}^2_{E}} \\end{equation}\\]\nLet’s get these using the function escalc in metafor. To obtain the standardised mean difference, we use:\n# SMD SMD \u0026lt;- escalc(measure = \u0026quot;SMD\u0026quot;, n1i = dat$n1i, n2i = dat$n2i, m1i = dat$m1i, m2i = dat$m2i, sd1i = dat$sd1i, sd2i = dat$sd2i) where n1i and n2i are the sample sizes, m1i and m2i are the means, and sd1i and sd2i the standard deviations from each study.\nThe oject created now has an effect size (yi) and its variance (vi) for each study\n## yi vi ## 1 1.8222 0.7408 ## 2 0.5922 0.4175 ## 3 1.3286 0.4883 ## 4 -0.3798 0.4072 ## 5 0.3321 0.5069 ## 6 2.5137 0.9282 To obtain the response ratio (log transformed ratio of menas), we would use:\nlnRR \u0026lt;- escalc(measure = \u0026quot;ROM\u0026quot;, n1i = dat$n1i, n2i = dat$n2i, m1i = dat$m1i, m2 = dat$m2i, sd1i = dat$sd1i, sd2i = dat$sd2i) The original paper used lnRR so we will use it, but you may want to repeat analysis below using SMD to see whether results are consistent.\nAdd the effect sizes to the original data set with cbind or bind_cols from the package dplyr\nlibrary(dplyr) dat \u0026lt;- bind_cols(dat, lnRR) You should see yi (effec size) and vi (sampling variance) are added.\n## \u0026#39;data.frame\u0026#39;: 102 obs. of 22 variables: ## $ id : int 21 22 27 32 35 38 44 63 86 87 ... ## $ paper : int 44 44 121 121 121 121 159 183 209 209 ... ## $ genus : chr \u0026quot;ALNUS\u0026quot; \u0026quot;ALNUS\u0026quot; \u0026quot;ACER\u0026quot; \u0026quot;QUERCUS\u0026quot; ... ## $ species : chr \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRA\u0026quot; \u0026quot;RUBRUM\u0026quot; \u0026quot;PRINUS\u0026quot; ... ## $ fungrp : chr \u0026quot;N2FIX\u0026quot; \u0026quot;N2FIX\u0026quot; \u0026quot;ANGIO\u0026quot; \u0026quot;ANGIO\u0026quot; ... ## $ co2.ambi: num 350 350 350 350 350 350 350 395 350 350 ... ## $ co2.elev: num 650 650 700 700 700 700 700 795 700 700 ... ## $ units : chr \u0026quot;ul/l\u0026quot; \u0026quot;ul/l\u0026quot; \u0026quot;ppm\u0026quot; \u0026quot;ppm\u0026quot; ... ## $ time : int 47 47 59 70 64 50 730 365 365 365 ... ## $ pot : chr \u0026quot;0.5\u0026quot; \u0026quot;0.5\u0026quot; \u0026quot;2.6\u0026quot; \u0026quot;2.6\u0026quot; ... ## $ method : chr \u0026quot;GC\u0026quot; \u0026quot;GC\u0026quot; \u0026quot;GH\u0026quot; \u0026quot;GH\u0026quot; ... ## $ stock : chr \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; \u0026quot;SEED\u0026quot; ... ## $ xtrt : chr \u0026quot;FERT\u0026quot; \u0026quot;FERT\u0026quot; \u0026quot;NONE\u0026quot; \u0026quot;NONE\u0026quot; ... ## $ level : chr \u0026quot;HIGH\u0026quot; \u0026quot;CONTROL\u0026quot; \u0026quot;.\u0026quot; \u0026quot;.\u0026quot; ... ## $ m1i : num 6.82 2.6 2.99 5.91 4.61 ... ## $ sd1i : num 1.77 0.667 0.856 1.742 1.407 ... ## $ n1i : int 3 5 5 5 4 5 3 3 20 16 ... ## $ m2i : num 3.94 2.25 1.93 6.62 4.1 ... ## $ sd2i : num 1.116 0.328 0.552 1.631 1.257 ... ## $ n2i : int 5 5 5 5 4 3 3 3 20 16 ... ## $ yi : num 0.547 0.143 0.438 -0.113 0.117 ... ## ..- attr(*, \u0026quot;ni\u0026quot;)= int [1:102] 8 10 10 10 8 8 6 6 40 32 ... ## ..- attr(*, \u0026quot;measure\u0026quot;)= chr \u0026quot;ROM\u0026quot; ## $ vi : num 0.0385 0.0175 0.0328 0.0295 0.0468 ... Visualising effect size. We can visualize point estimates (effect size) and their 95% confidence intervals, CIs (based on sampling error variance) by using the forest function, which draws a forest plot for us.\nforest(dat$yi, dat$vi) The problem you see is that when there are many studies, a forest plot does not really work (unless you have very large screen!). Let’s look at just the first 12 studies.\nforest(dat$yi[1:12], dat$vi[1:12]) We can calculate many different kinds of effect sizes with escalc; other common effect size statistics include \\(Zr\\) (Fisher’s z-transformed correlation). By the way, along with my colleagues, I have proposed a new standardized effect size called lnCVR (the log of coefficient of variation ratio – mouthful!), which compares the variability of two groups rather than means. See whether you can calculate it with these data. Actually, the development version of metafor, let you do this with escalc– github page. lnCVR is called “CVR” in escalc. Actually, if you re-analysis this data with lnCVR, you may be able to publish a paper! Nobody has done it yet. Do it tonight!\nOnce you have calculated effect sizes, move on to the next page: Meta-analysis 2: fixed-effect and random-effect models\n Further help (references) Go to the metafor package’s website. There you find many worked examples.\nCurtis, P. S., and X. Z. Wang. 1998. A meta-analysis of elevated CO2 effects on woody plant mass, form, and physiology. Oecologia 113:299-313. Nakagawa, S., R. Poulin, K. Mengersen, K. Reinhold, L. Engqvist, M. Lagisz, and A. M. Senior. 2015. Meta-analysis of variation: ecological and evolutionary applications and beyond. Methods in Ecology and Evolution 6:143-152. Viechtbauer, W. 2010. Conducting meta-analyses in R with the metafor package. Journal of Statistical Software 36:1-48. Authors: Shinichi Nakagawa and Malgorzata (Losia) Lagisz Last updated:\n## [1] \u0026quot;Mon Jan 24 12:57:41 2022\u0026quot;  "
},
{
	"uri": "/statistics/mixed-models/mixed-model-1/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "  Linear mixed models with one random effect\nYou will need to use mixed effect models if you have a random factor in your experimental design. A random factor\n is categorical\n has a large number of levels\n only a random subsample of levels is included in your design\n you want to make inference in general, and not only for the levels you observed.  This is a tough concept to get your head around, and is best explained with an example. The data we will analyse here are counts of invertebrates at 3-4 sites in each of 7 (randomly chosen) estuaries. Here the estuaries are the random effect, as there are a large number of possible estuaries, and we only sample from a random few of them, but we would like to make inference about estuaries in general.\nWe will introduce mixed models in three parts\nMixed models 1 (this page) is an introduction to mixed models for a continuous response with one random effect. You will learn how to check assumptions and do inference, including the parametric bootstrap.\n Mixed models 2 extends this to multiple random effects with a continuous response. We look into how to model nested and crossed random effects.\n Mixed models 3 teaches you how to model discrete data, including counts and binary data, with random effects.\n  All three pages will use the same data for illustration.\n\nProperties of mixed models Assumptions. Mixed models make some important assumptions (we’ll check these later for our examples)\nThe observed \\(y\\) are independent, conditional on some predictors \\(x\\)\n The response \\(y\\) are normally distributed conditional on some predictors \\(x\\)\n The response \\(y\\) has constant variance, conditional on some predictors \\(x\\)\n There is a straight line relationship between \\(y\\) and the predictors \\(x\\) and random effects \\(z\\)\n Random effects \\(z\\) are independent of \\(y\\).\n Random effects \\(z\\) are normally distributed   Running the analysis \nWe will use the package lme4 for all our mixed effect modelling. It will allow us to model both continuous and discrete data with one or more random effects. First, install and load this package:\nlibrary(lme4) We will analyse a data set that aimed to test the effect of water pollution on the abundance of some subtidal marine invertebrates by comparing samples from modified and pristine estuaries. As the total counts are large, we will assume the data is continuous. Later on in Mixed models 3, we’ll model counts as discrete using Generalised linear mixed models (GLMMs).\nDownload the sample data set, Estuaries.csv, and load into R.\nEstuaries = read.csv(\u0026quot;Estuaries.csv\u0026quot;, header = T) Fitting a model with a fixed and random effect\nIn this data set, we have a fixed effect (Modification; modified vs pristine) and a random effect (Estuary). We can use the lmer function to fit a model for any dependent variables with a continuous distribution. To fit a model for total abundance, we would use:\nft.estu = lmer(Total ~ Modification + (1|Estuary),data=Estuaries, REML=T) where Total is the dependent variable (left of the ~), Modification is the fixed effect, and Estuary is the random effect.\nNote the syntax for one random effect is (1|Estuary) - this is fitting a different intercept (hence 1) for each Estuary.\nThis model can be fit by maximum likelihood (REML=F) or restricted maximum likelihood (\u0026gt;REML=T). For fitting models it’s best to use REML, as it is less biased (unbiased for balanced samples), particularly in small samples. However to use the anova function below we need to refit with maximum likelihood.  Assumptions to check \nBefore we look at the results of our analysis, it’s important to check that our data met the assumptions of the model we used. Let’s look at all the assumptions in order.\nAssumption 1: The observed \\(y\\) are independent, conditional on some fixed effects \\(x\\) and random effects \\(z\\)\nWe can’t check this assumption, but you can ensure it’s true by taking a random sample within each level of the random effect in your experimental design.\nAssumption 2: The response \\(y\\) are normally distributed conditional on some predictors \\(x\\) and random effects \\(z\\)\nThis assumption is only critical when we have a small sample size or very skewed data. We can check it with a normal quantile plot of residuals.\nqqnorm(residuals(ft.estu)) We are looking for a straight line relationship. Here, the assumption of normality seems reasonable.\nAssumption 3: The response \\(y\\) has constant variance, conditional on some fixed effects \\(x\\) and random effects \\(z\\)\nLike a linear model, a mixed model assumes constant variance. We can check this by looking for a fan shape in the residual plot (residuals vs fitted values).\nscatter.smooth(residuals(ft.estu)~fitted(ft.estu)) This residual plot seems reasonable, there are differences in variability between estuaries, but variability does not increase with the mean. Note, that the function scatter.smooth is just a scatter plot with a fitted, smoothed curve.\nAssumption 4: There is a straight line relationship between \\(y\\) and the predictors \\(x\\) and random effects \\(z\\)\nTo check this assumption, we check the residual plot again for non-linearity, or a U-shape. In our case there is no evidence of non-linearity. If the residuals seem to go down then up, or up then down, we may need to add a polynomial function of the predictors using the poly function.\nAssumption 5: Random effects \\(z\\) are independent of \\(y\\).\nWe can’t check this assumption, but you can ensure it’s true by taking a random sample of estuaries.\nAssumption 6: Random effects \\(z\\) are normally distributed.\nThis assumption is not crucial (and difficult) to check.  Interpreting the results \nHypothesis test for the fixed effect\nThe package lme4 won’t give you p-values for fixed effects as part of the output in summary. This is because the p-values from Wald tests (using summary) and likelihood ratio tests (using anova) are only approximate in mixed models.\nNevertheless, we will use the anova function to test for an effect of modification on the total abundance of invertebrates, taking into account the random effect of estuary.\nFirst, we fit the full model by maximum likelihood, and a second model that lacks the fixed effect of Modification\nft.estu = lmer(Total ~ Modification + (1|Estuary), data=Estuaries, REML=F) ft.estu.0 = lmer(Total ~ (1|Estuary), data=Estuaries, REML=F) Then, we compare these two models with a likelihood ratio test, using the anova function.\nanova(ft.estu.0,ft.estu) ## Data: Estuaries ## Models: ## ft.estu.0: Total ~ (1 | Estuary) ## ft.estu: Total ~ Modification + (1 | Estuary) ## npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) ## ft.estu.0 3 415.02 420.99 -204.51 409.02 ## ft.estu 4 411.92 419.87 -201.96 403.92 5.1055 1 0.02385 * ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 We find that there is evidence of an effect of Modification (p = 0.02385).\nWe can also calculate confidence intervals for each model parameter using the confint function.\nconfint(ft.estu) ## Computing profile confidence intervals ... ## 2.5 % 97.5 % ## .sig01 2.718166 12.538348 ## .sigma 7.676352 11.522837 ## (Intercept) 31.918235 49.981321 ## ModificationPristine -26.360731 -2.538241 This also provides evidence for an effect of Modification as this parameter (i.e., the difference between the modified and pristine estuaries) has 95% confidence intervals that do not overlap zero.\nHypothesis test for random effects\nYou can use the anova function to test for random effects, but the p-values are very approximate and we do not recommend this procedure. Instead we will use a parametric bootstrap. This is a simulation based method which involves a fair chunk of code, but there’s not much about the code you have to change for different models, it’s mostly just a matter of copy-paste.\nParametric bootstrap\nnBoot=1000 lrStat=rep(NA,nBoot) ft.null = lm(Total~Modification,data=Estuaries)#null model ft.alt = lmer(Total~Modification+(1|Estuary),data=Estuaries,REML=F)#alternate model lrObs = 2*logLik(ft.alt) - 2*logLik(ft.null) #observed test stat for(iBoot in 1:nBoot) { Estuaries$TotalSim=unlist(simulate(ft.null)) #resampled data bNull = lm(TotalSim~Modification,data=Estuaries)#null model bAlt = lmer(TotalSim~Modification+(1|Estuary),data=Estuaries,REML=F)#alternate model lrStat[iBoot] = 2*logLik(bAlt) - 2*logLik(bNull)#resampled test stat } mean(lrStat\u0026gt;lrObs) #P-value for test of Estuary effect ## [1] 0.001 There is strong evidence for including estuary in your model (p = 0.001). You could use similar code to test for the effect of Modification with a parametric bootstrap. ###FAQ for mixed models 1. Do I need balanced samples to fit a mixed model?\nNo, unbalanced designs are fine. Balanced designs will generally give you better power though, so they are good to aim for.\n2. Should I sample many levels of the random effect, or lots of observations within each level?\nThis depends on what you are interested in. In our example, we are interested in the effect of modification. In the study design, estuaries fall directly below modification, so we need a lot of estuaries within each level of Modification to make good inference about the effects of modification. This is true in general, you need lots of samples in the level below the level you are primarily interested in.\n3. Does my random factor have to be a random effect?\nNot necessarily. If you have a random factor (i.e., you have a random sample of categories from a categorical variable) and you want to make inferences about that variable in general, not just at the categories you observed, then include it as a random effect. If you are happy making inference about just the levels you observed, then you can include it as a fixed effect. In our example we wanted to make inference about modification in general, i.e. in every modified and unmodified estuary, so we included estuary as a random effect. If we had treated Estuary as a fixed factor, we would have been restricted to making conclusions about only the estuaries we sample.\n4. What if the levels of my factor aren’t really random?\nThis might be a problem as assumption 4 may not hold. You should always sample the random effect randomly to avoid bias and incorrect conclusions.  Communicating the results \nWritten. Results of linear mixed models are communicated in a similar way to results for linear models. In your results section you should mention that you are using mixed models with R package lme4, and list your random and fixed effects. You should also mention how you carried out inference, i.e. likelihood ratio tests (using the anova function) or parametric bootstrap. In the results section for one predictor, it suffices to write one line, e.g. “There is strong evidence (p\u0026lt;0.001) of negative effect of modification on total abundance. For multiple predictors it’s best to display the results in a table.\nVisual. The best way to visually communicate results will depend on your question, for a simple mixed model with one random effect, a plot of the raw data with the model means superimposed is one possibility. There is a little bit of code that is required for such a plot, and it will be a little different for your data and model.\nModEst=unique(Estuaries[c(\u0026quot;Estuary\u0026quot;, \u0026quot;Modification\u0026quot;)]) #find which Estuaries are modified # Prepare a vector of colors with specific color by modification levels myColors \u0026lt;- ifelse(unique(ModEst$Modification)==\u0026quot;Modified\u0026quot; , rgb(0.1,0.1,0.7,0.5) , ifelse(unique(ModEst$Modification)==\u0026quot;Pristine\u0026quot;, rgb(0.8,0.1,0.3,0.6), \u0026quot;grey90\u0026quot; ) ) boxplot(Total~ Estuary,data=Estuaries,col=myColors,xlab=\u0026quot;Estuary\u0026quot;,ylab=\u0026quot;Total invertebrates\u0026quot;) legend(\u0026quot;bottomleft\u0026quot;, inset=.02, c(\u0026quot; Modified \u0026quot;,\u0026quot; Pristine \u0026quot;), fill=unique(myColors), horiz=TRUE, cex=0.8) #0 if Modified, 1 if Pristine is.mod = ifelse(unique(ModEst$Modification)==\u0026quot;Modified\u0026quot; , 0 , ifelse(unique(ModEst$Modification)==\u0026quot;Pristine\u0026quot;, 1, NA)) Est.means=coef(ft.estu)$Estuary[,1]+coef(ft.estu)$Estuary[,2]*is.mod #Model means ## Warning in coef(ft.estu)$Estuary[, 2] * is.mod: longer object length is not a ## multiple of shorter object length stripchart(Est.means~ sort(unique(Estuary)),data=Estuaries,pch=18,col=\u0026quot;red\u0026quot;,vertical = TRUE,add=TRUE)  Further help \nYou can type ?lmer into R for help with these functions.\nDraft book chapter from the authors of lme4.\nFaraway, JJ. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press, 2005. Zuur, A, EN Ieno and GM Smith. Analysing ecological data. Springer Science \u0026amp; Business Media, 2007. \nAuthor: Gordana Popovic Last updated:\n## [1] \u0026quot;Mon Jan 24 12:21:01 2022\u0026quot;  "
},
{
	"uri": "/statistics/glms/glm-1/",
	"title": "Introduction and Binary Data",
	"tags": [],
	"description": "",
	"content": "  Introduction and binomial data Linear models (e.g., linear regression) are used to model the relationship between a continuous response variable \\(y\\) and one or more explanatory variables \\(x_1, x_2, \\cdots\\). When we have a discrete response we use generalised linear models (GLM’s).\nFor example, if had surveyed a beach and wanted to analyse how the presence of a crab varied with time and distance from the water line, the response variable is discrete: the presence or absence of a crab in a given replicate. The first few rows of the data set would look like this:\n## X Dist Time CrabPres ## 1 1 0 5 0 ## 2 2 0 5 1 ## 3 3 0 5 1 ## 4 4 0 5 0 ## 5 5 0 5 0 ## 6 6 2 5 0 \nProperties of GLM’s. Discrete response data, like counts and presence/absence data, generally exhibit a mean-variance relationship. For example; for counts that are on average 5, we would expect most samples to be between about 1 and 9, but for counts that are on average 500, most of the observations will tend to be between 450 and 550, giving us a much larger variance when the mean is large.\nLinear models assume constant variance. You might have learned to transform count data and then fit a linear model. This can reduce the mean variance relationship, but it won’t get rid of it completely, especially if you have a lot of zeros in your data. To analyse discrete data accurately we need to use GLM’s.\nA GLM makes some important assumptions (we’ll check these later for our examples)\nThe observed \\(y\\) are independent, conditional on some predictors \\(x\\)\n The response \\(y\\) come from a known distribution with a known mean-variance relationship\n There is a straight line relationship between a known function \\(g\\) of the mean of \\(y\\) and the predictors \\(x\\)  \\[ g(\\mu_y) = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots \\]\nNote: link functions g() are an important part of fitting GLM’s, but beyond the scope of this introductory tutorial. All you need to know is that the default link for binomial data is the logit() and for count data it’s log(). For more information see ?family. Running the analysis \nBinomial data\nFirst, we will show you how to fit a model to binomial data, i.e., presence/absence data or data as 0/1. Fitting GLM’s uses very similar syntax to fitting linear models. We use the glm function instead of lm. We also need to add a ?family argument to specify whether your data are counts, binomial etc.\nFor this worked example, download the sample data set on the presence and absence of crabs on the beach, Crabs.csv and import into R.\nCrab_PA = read.csv(\u0026quot;Crabs.csv\u0026quot;, header = T) To test whether the probability of crab presence changes with time (a factor) and distance (a continuous variable), we fit the following model. The response variable (presence/absence of crabs) is binomial, so we use family=binomial.\nft.crab = glm(CrabPres ~ Time*Dist, family=binomial, data=Crab_PA) \n Assumptions to check \nBefore we look at the results of our analysis it’s important to check that our data met the assumptions of the model we used. Let’s look at all the assumptions in order.\nAssumption 1 : The observed \\(y\\) are independent, conditional on some predictors \\(x\\)\nWe can’t check this assumption from the results, but you can ensure it’s true by taking a random sample for your experimental design. If your experimental design involves any pseudo-replication, this assumption will be violated. For certain types of pseudo-replication you can use mixed models instead.\nAssumption 2 : The response \\(y\\) come from a known distribution with a known mean-variance relationship\nThe mean variance relationship is the main reason we use GLM’s instead of linear models. We need to check that the distribution models the mean-variance relationship of our data well. For binomial data this is not a big concern, but later on when we analyse count data it’ll be very important. To check this assumption we look at a plot of residuals, and try to see if there is a fan shape.\nplot(ft.crab,which=1) Unfortunately the glm plot function gives us a very odd looking plot due to the discreteness of the data (i.e., many points on top of each other).\nFor a more useful plot we can instead fit the model using the manyglm function in the mvabund package. We need a slight change to the family argument, for manyglm we write family = \"binomial\".\nlibrary(mvabund) ft.crab.many = manyglm(CrabPres ~ Time*Dist, family=\u0026quot;binomial\u0026quot;, data=Crab_PA) plot(ft.crab.many) Now we can look for a fan shape in the residual plot. For these data, there doesn’t seem to be a fan shape, so we can conclude the mean-variance assumption the model made was reasonable for our data. The residuals in this plot have a random component. If you see a pattern it’s best to repeat the plot a few times to see if the pattern is real.\nAssumption 3 : There is a straight line relationship between a known function \\(g\\) of the mean of \\(y\\) and the predictors \\(x\\)\nTo check this assumption, we check the residual plot above for non-linearity, or a U-shape. In our case there is no evidence of non-linearity. If the residuals seem to go down then up, or up then down, we may need to add a polynomial function of the predictors using the poly function.  Interpreting the results \nIf all the assumption checks are okay, we can have a look at the results the model gave us. The two main functions for inference are the same as for linear models: summary and anova.\nThe p-values these give you if you use glm for fitting the model work well in large samples, although they are still approximate. For binomial models in particular the p-values from the summary function can be funny, and we prefer to use the anova function to see if predictors are significant. The summary() function is still useful to look at the model equation.\nanova(ft.crab,test=\u0026quot;Chisq\u0026quot;) ## Analysis of Deviance Table ## ## Model: binomial, link: logit ## ## Response: CrabPres ## ## Terms added sequentially (first to last) ## ## ## Df Deviance Resid. Df Resid. Dev Pr(\u0026gt;Chi) ## NULL 56 71.097 ## Time 1 6.6701 55 64.427 0.009804 ** ## Dist 1 0.7955 54 63.631 0.372448 ## Time:Dist 1 0.1647 53 63.466 0.684852 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 The p-value for Time is small (P\u0026lt;0.01), so we conclude there is an effect of time on the presence of crabs, but no effect of distance or an interaction between time and distance. This sample is reasonably large, so these p-values should be a good approximation. For a small sample it is often better to use resampling to calculate p-values. When you use manyglm the summary and anova functions use resampling by default.\nanova(ft.crab.many) ## Time elapsed: 0 hr 0 min 0 sec ## Analysis of Deviance Table ## ## Model: CrabPres ~ Time * Dist ## ## Multivariate test: ## Res.Df Df.diff Dev Pr(\u0026gt;Dev) ## (Intercept) 56 ## Time 55 1 6.670 0.011 * ## Dist 54 1 0.795 0.370 ## Time:Dist 53 1 0.165 0.700 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## Arguments: P-value calculated using 999 iterations via PIT-trap resampling. In this case the results are quite similar, but in small samples it can often make a big difference.\nYou can also use summary with either the glm or manyglm function. This is interpreted in a similar manner as for linear regression, but we need to include the link function, g.\nsummary(ft.crab) ## ## Call: ## glm(formula = CrabPres ~ Time * Dist, family = binomial, data = Crab_PA) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.3518 -0.6457 -0.5890 1.0125 1.9390 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) -3.00604 1.47469 -2.038 0.0415 * ## Time 0.25835 0.17439 1.481 0.1385 ## Dist -0.03193 0.23923 -0.133 0.8938 ## Time:Dist 0.01143 0.02830 0.404 0.6863 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 71.097 on 56 degrees of freedom ## Residual deviance: 63.466 on 53 degrees of freedom ## AIC: 71.466 ## ## Number of Fisher Scoring iterations: 4 If \\(p\\) is the probability of crab presence, this output tells us\n\\[ logit(p) = -3.01 + 0.26 \\times \\text{Time} -0.03 \\times \\text{Dist} +0.01 \\times \\text{Time} \\times \\text{Dist}\\]  Communicating the results \nResults of GLM’s are communicated in the same way as results for linear models. For one predictor it suffices to write one line, e.g., “There is strong evidence that the presence of crabs varies with time (p = 0.01). For multiple predictors it’s best to display the results in a table. You should also indicate which distribution was used (e.g. Binomial for presence/absence, Poisson or negative-binomial for counts) and if resampling was used for inference.  Further help \nYou can type ?glm and ?manyglm into R for help with these functions.\nFaraway, JJ. 2005. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press. Zuur, A, EN Ieno and GM Smith. 20074. Analysing ecological data. Springer Science \u0026amp; Business Media, 2007. More advice on interpreting coefficients in glms Author: Gordana Popovic Last updated:\n## [1] \u0026quot;Fri Jan 21 17:06:58 2022\u0026quot;  "
},
{
	"uri": "/statistics/linear-models/linear-regression/",
	"title": "Linear Regression",
	"tags": [],
	"description": "",
	"content": "  Linear regression is the one of the most widely used statistical techniques in the life and earth sciences. It is used to model the relationship between a response (also called dependent) variable \\(y\\) and one or more explanatory (also called independent or predictor) variables \\(x_{1}\\),\\(x_{2}\\)…\\(x_{n}\\). For example, we could use linear regression to test whether temperature (the explanatory variable) is a good predictor of plant height (the response variable).\nIn simple linear regression, with a single explanatory variable, the model takes the form:\n\\[y = \\alpha + \\beta x + \\varepsilon \\]\nwhere \\(\\alpha\\) is the intercept (value of \\(y\\) when \\(x\\) = 0), \\(\\beta\\) is the slope (amount of change in \\(y\\) for each unit of \\(x\\)), and \\(\\varepsilon\\) is the error term. It is inclusion of the error term, also called the stochastic part of the model, that makes the model statistical rather than mathematical. The error term is drawn from a statistical distribution that captures the random variability in the response. In standard linear regression this is assumed to be a normal (Gaussian) distribution.\nNote that the linear in linear model does not imply a straight-line relationship but rather that the response is a linear (additive) combination of the effects of the explanatory variables. However, because we tend to start by fitting the simplest relationship, many linear models are represented by straight lines.\nNote that a linear regression is just a special case of a linear model, where both the response and predictor variables are continuous. Running the analysis \nThe goal in linear regression is obtain the best estimates for the model coefficients (\\(\\alpha\\) and \\(\\beta\\)). In R you can fit linear models using the function lm.\nFor this worked example, download a data set on plant heights around the world, Plant_height.csv, and import into R.\nPlant_height \u0026lt;- read.csv(file = \u0026quot;Plant_height.csv\u0026quot;, header = TRUE) The main argument to lm is the model formula y ~ x, where the response variable is on the left of the tilde (~) and the explanatory variable is on the right. lm also has an optional data argument that lets you specify a data frame from which the variables will be taken.\nTo test whether plant height is associated with temperature, we would model height as the dependent variable (in this case we are using the log of plant height) and temperature as the predictor variable.\nlm(loght ~ temp, data = Plant_height) \n Interpreting the results \nTo obtain detailed output (e.g., coefficient values, R2, test statistics, p-values, confidence intervals etc.), assign the output of the lm function to a new object in R and use the summary function to extract information from that model object.\nmodel \u0026lt;- lm(loght ~ temp, data = Plant_height) summary(model) ## ## Call: ## lm(formula = loght ~ temp, data = Plant_height) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.97903 -0.42804 -0.00918 0.43200 1.79893 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.225665 0.103776 -2.175 0.031 * ## temp 0.042414 0.005593 7.583 1.87e-12 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.6848 on 176 degrees of freedom ## Multiple R-squared: 0.2463, Adjusted R-squared: 0.242 ## F-statistic: 57.5 on 1 and 176 DF, p-value: 1.868e-12 The estimates for the coefficients give you the slope and intercept. In this example, the regression equation for (log) plant height as a function of temperature is:\n\\[log(plant height) = -0.22566 +0.0421.temperature + \\varepsilon \\] Calling summary on a model object produces a lot of useful information but one of the main things to look out for are the t-statistics and p-values for each coefficient. These test the null hypothesis that the true value for the coefficient is 0.\nFor the intercept we usually don’t care if it is zero or not, but for the other coefficient (the slope), a value significantly differing from zero indicates that there is an association between that explanatory variable and the response. In this example, an increase in temperature is associated with an increase in plant height.\nWhilst the t-statistics and p-values indicate a significant association, the strength of the association is captured by the R2 value, the proportion of variance in the response that is explained by the explanatory variable(s).\nThe F-statistic and associated p-value indicates whether the model as a whole is significant. The model will always be significant if any of the coefficients are significant. With only one predictor variable, the probability associated with the t test, that tests whether the slope differs from zero, is identical to the probability associated with the F statistic.\nWe can also obtain 95% confidence intervals for the two parameters. Showing that the intervals for the slope do not include zero is another way of showing that there is an association between the dependent and predictor variable.\nconfint(model) ## 2.5 % 97.5 % ## (Intercept) -0.43047074 -0.02085828 ## temp 0.03137508 0.05345215 \n Assumptions to check \nLinearity. There is no point trying to fit a staight line to data that are curved! Curvilinear relationships produce U-shaped patterns in plots of the residuals vs the fitted values. Using the plot function on a model object provides a series of four graphical model diagnostics, the first of which is a plot of residuals versus fitted values.\nplot(model, which = 1) The absence of strong patterning in the above plot indicates the assumption of linearity is valid. If there is strong patterning, one potential solution is to log-transform the response. Note in the above example plant height had already been log-transformed. An alternative solution is to fit a linear model of the response as a polynomial function (e.g. quadratic) of the response. The simplest way to do this in R is to use the poly function.\nClick here to see a nice interactive app that shows you what patterns of residuals you would expect with curved relationships\nConstant variance. An even spread of data around the regression line is desirable. If the plot of residuals versus fitted values is fan-shaped the assumption of constant variance (aka homogeneity of variance) is violated. A log-transformation of the response variable may fix this problem, but if it doesn’t the best solution is to use a different error distribution in a generalised linear model framework (GLM). See the Generalised linear models 1 for more information.\nNormality. Checks of whether the data are normally distributed are usually performed by either plotting a histogram of the residuals or via a quantile plot where the residuals are plotted against the values expected from a normal distribution (the second of the figures obtained by plot(model). If the points in the quantile plot lie mostly on the line, the residuals are normally distributed. Violations of normality can be fixed via transformations or by using a different error-distribution in a GLM. Note, however, that linear regression is reasonably robust against violations of normality.\npar(mfrow = c(1,2)) # This code put two plots in the same window hist(model$residuals) # Histogram of residuals plot(model, which = 2) # Quantile plot Independence. The observations of the response should be independent of each other. Non-independent observations are those that are in some way associated with each other beyond that which is explained by the predictor variable(s). For instance, samples collected from the same site, or repeatedly from the same object, may be more alike due to some additional factor other than the measured explanatory variable. Ensuring independence is an issue of experimental and sampling design and we usually know if the data are independent or not in advance of our analysis.\nThere are a variety of measures for dealing with non-independence. These include ensuring all important predictors are in the model; averaging across nested observations; or using a mixed-model (see Mixed models 1).  Communicating the results \nWritten The results of linear regression may be presented in the text in a number of different ways, but a short sentence is often adequate, e.g., “plant height exhibited a significant (F = 57.5, p \u0026lt; 0.01) negative relationship with temperature”. However, if you have run several analyses (or if there is more than one predictor), it may be useful to present the results as a table with coefficient values, standard errors and p-values for each explanatory variable.\nVisual For a linear regression with a single explanatory variable, it is useful to present the results as a scatter plot. The line of best fit derived from the model can be added with the abline function.\nplot(loght ~ temp, data = Plant_height, xlab = \u0026quot;Temperature (C)\u0026quot;, ylab = \u0026quot;log(Plant height)\u0026quot;,pch=16) abline(model, col = \u0026quot;red\u0026quot;)  Further help \nType ?lm to get the R help for this function.\nQuinn and Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Ch. 5 Correlation and regression. McKillup (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Ch. 17 Regression. More advice on interpreting coefficients in linear models Author: Andrew Letten Last updated:\n## [1] \u0026quot;Fri Jan 21 16:33:14 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/making-new-variables/",
	"title": "Making New Variables",
	"tags": [],
	"description": "",
	"content": "  Being able to make new variables from those already in your data set is an essential skill for data manipulation prior to making graphs or doing analyses. These new variables could be a transformed variable that you would like to analyse, a new variable that is a function of existing ones, or a new set of labels for your samples.\nTo demonstrate a few of the commonly used functions in R for doing this, let’s consider a data set on the feeding specificity of marine herbivores on five species of macroalgae. Twenty replicate individuals of each of seven species of macroalgae were collected from Sydney Harbour, and the abundance of seven species of herbivorous crustacean recorded from each replicate sample (data from Poore et al. 2000).\nDownload the data set, Herbivore_specialisation.csv, and load into R.\nHerbivores \u0026lt;- read.csv(file = \u0026quot;Herbivore_specialisation.csv\u0026quot;, header = TRUE) The first two columns are categorical variables that label the samples as coming from each of the five habitats or as being collected during the day or the night. The third column is the replicate number per combination of habitat and day/night. The fourth column is the biomass of the habitat sampled and the rest of the columns are the counts of each herbivore species in each sample. Adding a new variable \nAdding a new variable to an existing data frame can be done by assigning the outcome of a given function to a new variable name in the following fashion.\nHerbivores$log_Mass \u0026lt;- log(Herbivores$Mass) Herbivores$Ampithoe \u0026lt;- Herbivores$Ampithoe_caddi + Herbivores$Ampithoe_kava + Herbivores$Ampithoe_ngana The first line creates a new variable called log_Mass which is the log of the variable Mass from the Herbivores data frame.\nThe second line creates a new variable called Ampithoe which is the sum of the abundances for each of the three species of Ampithoe in the data set.\nHaving to reference both the data frame and the variable name in these expressions can get pretty messy, so we recommend using functions from the package dplyr which allow us to just use variable names. First, load the package:\nlibrary(dplyr) The function mutate is then used to create new variables. To achieve the same result as the above code, we would use:\nHerbivores \u0026lt;- mutate(Herbivores, log_Mass = log(Mass)) Herbivores \u0026lt;- mutate(Herbivores, Ampithoe = Ampithoe_caddi + Ampithoe_kava + Ampithoe_ngana) Even neater is to run several things at once. We could create both of those new variables and many others with single block of code. For example:\nHerbivores \u0026lt;- mutate(Herbivores, log_Mass = log(Mass), # log of Mass Ampithoe = Ampithoe_caddi + Ampithoe_kava + Ampithoe_ngana, # sum of three columns Total_abundance = rowSums(Herbivores[,5:12]), # sum of columns 5-12 with all abundance data Total_abundance_perGram = Total_abundance/Mass # abundance as numbers per g of habitat ) The arguments of mutate are simply the name of the data frame followed by any number of expressions that create new variables.\nIn the above examples, note that the new variables have been added to the existing data frame, and all old variables have been kept. You can use transmute if you want to drop the original variables.\nThese functions become especially powerful when combined with some of the others in dplyr. See our pages on subsetting and summarising data.  Renaming a variable \ndplyr offers a straightforward function, rename, to change the name of any variable. For example, to change Mass to Biomass, we simply use:\nHerbivores \u0026lt;- rename(Herbivores, Biomass = Mass) \n Uniting several columns into one \nCombining the content of several columns into a single column can be useful to provide a different set of labels for rows in your data set, or new levels of a categorical variable that you may want to use in graphs. The function unite in the package tidyr allows us to do this very easily. First, install and load this package into R.\nlibrary(tidyr) If we wanted to make a new categorical variable where each level was the unique combination of habitat and day/night, we would use:\nHerbivores \u0026lt;- unite(Herbivores, \u0026quot;Habitat_DayNight\u0026quot;, c(Habitat, DayNight), sep=\u0026quot;_\u0026quot;) The arguments of unite' are: * the data frame to be used (in this case Herbivores) * the name of the new variable (in this case \"Habitat_DayNight\") * the columns to be united, withinc()` * the character used to separate the values in each column being united (in this case “_“)\nView the data frame again and you will notice the new variable, and the fact that the old ones have been removed. It is a better idea to keep them, by adding remove=FALSE\nHerbivores \u0026lt;- unite(Herbivores, \u0026quot;Habitat_DayNight\u0026quot;, c(Habitat, DayNight), sep=\u0026quot;_\u0026quot;, remove=FALSE) \n Separating one column into several \nSeparating content from one column into several separate variables is also very useful if the levels of categorical variables in the original data set are actually combinations of more than one variable. The function separate in tidyr does this.\nFor example, if we wanted to contrast the abundance of herbivores among the genera of algae being used as habitat (rather than individual species), we would need to make a new variable that held only the genus names. We can use separate to make two new columns, one for genus and one for species, from the values in the Habitat variable.\nHerbivores \u0026lt;- separate(Herbivores, Habitat, c(\u0026quot;Genus\u0026quot;,\u0026quot;species\u0026quot;), sep=\u0026quot;_\u0026quot;, remove=FALSE) The arguments of separate' are: * the data frame to be used (in this case Herbivores) * the name of the new variable to be separated (in this case \"Habitat\") * the names of the new variables, withinc()(in this case \"Genus\" and \"species\") * the character used to separate the values in the column being separated (in this case \"_\") * theremove=FALSE` means we keep the variable being separated in the new version of the data frame\nNote that this was only possible because there was a character separating the two variables in the text of the one to be separated (e.g., we couldn’t do this is if the species names in the Habitat variable were originally GenusSpecies, rather than Genus_species).  Further help \nType ?mutate, ?unite, and ?separate for the R help for these functions.\nData wrangling with dplyr and tidyr cheat sheet produced by Rstudio. Some images above were sourced from this document.\nIntroducing tidyr Author: Alistair Poore Last updated:\n## [1] \u0026quot;Wed Jan 19 11:11:12 2022\u0026quot;  "
},
{
	"uri": "/graphics/multivariate-vis/mds/",
	"title": "Multidimensional Scaling",
	"tags": [],
	"description": "",
	"content": "  Multidimensional scaling (MDS) is a popular approach for graphically representing relationships between objects (e.g. plots or samples) in multidimensional space. Dimension reduction via MDS is achieved by taking the original set of samples and calculating a dissimilarity (distance) measure for each pairwise comparison of samples. The samples are then usually represented graphically in two dimensions such that the distance between points on the plot approximates their multivariate dissimilarity as closely as possible.\nOne of the most common applications of MDS in the environmental sciences is to examine the similarity of different ecological communities based on their species composition. In those analyses, the abundance of all species within replicated samples (plots or quadrats in the field, different sites etc.) is recorded and the raw data takes the form of a matrix of species (the variables) by samples.\nConsider an example where researchers wanted to contrast the feeding specificity of marine herbivores on five species of macroalgae. Twenty replicate individuals of each of seven species of macroalgae were collected from Sydney Harbour, and the abundance of seven species of herbivorous crustacean recorded from each replicate (a raw data matrix of 100 samples x 7 variables, data from Poore et al. 2000).\nMultidimensional scaling can create an ordination plot from any measure of similarity or dissimilarity among samples and there are many different measures for calculating the dissimilarity among samples. The most basic of these is the Euclidean distance (i.e., simply the straight-line distance between two points in multivariate space). For contrasts of species composition, however, the most commonly used distance measure is the Bray-Curtis dissimilarity metric. The reason for its popularity is that, compared to other measures, Bray-Curtis is better at handling the large proportion of zeroes (e.g., species absences) commonly found in ecological data sets. This measure won’t consider shared absences as being similar, which makes sense biologically.\nIn addition to the choice of distance measure there are a number of different classes of MDS. Here we focus on what is referred to as non-metric MDS (nMDS), a non-parametric rank-based method that is comparatively robust to non-linear relationships between the calculated dissimilarity measure and the projected distance between objects. Running the analysis \nYour data should be formatted so that each sample is a row and each variable is a column. Download the herbivore specialisation data set, and import into R to see the desired format.\nHerbivores \u0026lt;- read.csv(file = \u0026quot;Herbivore_specialisation.csv\u0026quot;, header = TRUE) The first two columns are categorical variables that label the samples as coming from each of the five habitats or as being collected during the day or the night. The third column is the replicate number per combination of habitat and day/night. The fourth column is the biomass of the habitat sampled and the rest of the columns are the counts of each herbivore species in each sample.\nTo contrast the species composition across habitats or time of sampling, we first need to make a dataframe with only the abundance values for each sample (columns 5 to 11).\nHerb_community \u0026lt;- Herbivores[5:11] Creating a MDS plot involves two steps:\n* creating a dissimilarity matrix with your chosen metric that measures the similarity between every pair of samples\n* creating an ordination plot from that dissimilarity matrix\nThese can be done in the package vegan. First, install and load the package.\nlibrary(vegan) The function metaMDS combines these two steps in a single function.\nHerb_community.mds \u0026lt;- metaMDS(comm = Herb_community, distance = \u0026quot;bray\u0026quot;, trace = FALSE, autotransform = FALSE) where comm = Herb_community specifies the data frame holding the community data, distance = \"bray\" indicates you want to use a Bray-Curtis distance measure and trace = FALSE indicates you wish to ignore in progress output of results. autotransform = FALSE stops vegan from automatically transforming the data (see below for advice on transformation).\nCalling the plot function on the x-y coordinates of the metaMDS output creates an MDS ordination plot.\nplot(Herb_community.mds$points)  This is not informative until we plot samples from each habitat type (macroalgal species) as a different colour.\nTo do this we can extract the x and y coordinates from the MDS plot into a new data frame.\nMDS_xy \u0026lt;- data.frame(Herb_community.mds$points) Then, we can add our habitat and day vs night factors to those coordinates (i.e. the first two columns of the original data set.\nMDS_xy$Habitat \u0026lt;- Herbivores$Habitat MDS_xy$DayNight \u0026lt;- Herbivores$DayNight To plot those points, color coded by Habitat, we can use:\nlibrary(ggplot2) ggplot(MDS_xy, aes(MDS1, MDS2, color = Habitat)) + geom_point() + theme_bw()  Interpreting the results \nInterpreting an MDS plot is reasonably straightforward and the same as for any other ordination plot; objects that are closer together on the plot are more alike than those further apart. MDS arranges the points on the plot so that the distances among each pair of points correlates as best as possible to the dissimilarity between those two samples. The values on the two axes tell you nothing about the variables for a given sample - the plot is just a two dimensional space to arrange the points.\nIf there is any grouping of samples according to categories of samples, then you have interesting patterns in your multivariate data set. In the plot above, samples from each habitat are more likely to be similar to samples from the same habitat, than samples from ther other habitats (visualised as clusters of different colours). This means that the species composition of herbivores differs across their food plants. Remember, that this is not a statistical test, just a visualisation that helps you seek patterns.\nIn contrast, if we colour our samples by time of day, you will see that these two groups of samples are mixed on the plot. This suggests no difference in species composition between the two sampling times.\nggplot(MDS_xy, aes(MDS1, MDS2, color = DayNight)) + geom_point() + theme_bw()  Assumptions to check \nAs a rank-based approach NMDS, is comparatively robust to non-linearity between inter-object distance in space and their multivariate dissimilarity.\nStress. Not an assumption of the process, but the most important factor to consider after generating an MDS plot is the ‘stress’. The stress provides a measure of the degree to which the distance between samples in reduced dimensional space (usually 2-dimensions) corresponds with the actual multivariate distance between the samples. Lower stress values indicate greater conformity and therefore are desirable. High stress values indicate that there was no 2-dimensional arrangement of your points that reflect their similarities. A rule of thumb is that stress values should ideally be less than 0.2 or even 0.1.\nYou can obtain the stress value from your plot with:\nHerb_community.mds$stress ## [1] 0.1485345 If the stress value is greater than 0.2, it is advisable to include an additional dimension, but remember that human brains are not very well equipped to visualise objects in more than 2-dimensions.\nTransformation and standardisation. Transforming data sets prior to creating a MDS plot is often desirable, not to meet assumptions of normality, but to reduce the influence of extreme values. For example,\nHerb_community.sq \u0026lt;- sqrt(Herb_community) Herb_community.sq.mds \u0026lt;- metaMDS(comm = Herb_community.sq, distance = \u0026quot;bray\u0026quot;, trace = FALSE) Standardising samples or variables (by their mean or totals) may also be done, to create plots where all variables have equal influence, or plots where the differences among samples is purely based on relative values not their magnitude. Several common methods of standardisation used for community data sets are provided in the vegan function decostand.\nRemember that any of these modifications do actually change your question. If the example above was done with samples standardised by total abundance, then the plot would represent a contrast of species composition with no influence of the different abundances found on the different habitats.\nPlease also note that ordination based on distances has been criticised for failing to account for the mean-variance relationships that are commonplace in abundance data sets like the one used here, and for lacking an underlying statistical model - see Hui et al. (2014) Model-based approaches to unconstrained ordination. Methods in Ecology and Evolution 6:399-411. link. Communicating the results \nVisual. The results from a MDS are best presented visually as a 2-dimensional ordination plot (as above). Rarely, a 3-dimensional plot may be used.\nWritten. The written description of the MDS analyses (often in the figure legend) should mention what dissimilarity metric was used, whether data were transformed or standardised, and present the stress value. In a formal analysis, MDS plots are usually accompanied by some multivariate statistical test of dissimilarity between treatment/observational groups, e.g., via the adonis function in vegan.  Further help \nType ?metaMDS for the R help for this function.\nQuinn, GP and MJ Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Ch. 18. Multidimensional scaling and cluster analysis. McKillup, S (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Ch. 22. Introductory concepts of multivariate analysis. \nAuthor: Andrew Letten Last updated:\n## [1] \u0026quot;Thu Jan 20 14:38:14 2022\u0026quot;   "
},
{
	"uri": "/graphics/basic-plotting/one-continuous/",
	"title": "One Continuous Variable",
	"tags": [],
	"description": "",
	"content": "  Being able to visualise the properties of data is a critical step in data exploration, and needed for effective communication of results. This page details two common ways that you can display data from a single, continuous variable in R: frequency histograms and box-and-whisker plots.\nThe sample data used below are the lengths (cm) of 80 fish caught in an estuary at sites with different management zones (protected versus unprotected) and shores (urbanised versus healthy).\nFrequency histograms \nFrequency histograms plot how often the values of a continuous variable fall into certain ranges. They are an effective way to visualise the range of values obtained and the distribution of your data (i.e. is it symmetrical or skewed?).\nFirstly, download the sample data set, Estuary_fish.csv, and import into R.\nFish \u0026lt;- read.csv(file = \u0026quot;Estuary_fish.csv\u0026quot;) A frequency histogram of the variable Length from the data frame Fish is easily produced with the hist function.\nhist(Fish$Length) You can see straight away that all the fish were less than 30 cm long and that these length data are positively skewed - small fish are more frequent and large fish are rare.\nYou can alter the number of bins or the range of each bin with breaks argument. This will change the width and shape of the histogram. For example, if you wanted 15 bins, you would use:\nhist(Fish$Length,breaks=15) If you wanted each bin to be have a range of 2 cm, you would use breaks=seq(0,30,by=2) where the numbers in the brackets are the minimum, maximum and range for each bin.  Box and whisker plots \nA box and whisker plot, or boxplot, is another useful way to visualise the distribution of a single, continuous variable. They are easily made with the boxplot function. The horizontal=TRUE argument makes the single axis horizontal.\nboxplot(Fish$Length, horizontal=TRUE) The plot shows the distribution of a variable by indicating the median, quartiles, maximum and minimum of a variable. The top and bottom whiskers are the maximum and minimum values (excluding any outliers that are indicated by a circle). The thick black line is the median, with the boxes either side of the median line the lower and upper quartiles.\nRemember that the median is the value that has 50% of values larger and 50% of values smaller. Similarly, the quartiles represent the values with 25% of the values lower (the lower quartile) or 25% of values higher (the upper quartile).\nThe boxplot will indicate skewness in your data if the median is not equally distant from the quartiles or maximum and minimum values. In this example, you can see that the median is closer to the minimum value that the maximum (indicating that low values are more common).  Formatting plots \nThese simple plots can be formatted using the basic R formatting in the graphics package. The code below gives you some of the more commonly used formatting commands to give you higher control over your plots.\nAdd axis labels or titles Axis labels are produced with the xlab and ylab arguments. Titles are provided with the main argument.\nhist(Fish$Length, xlab = \u0026#39;Fish length (cm)\u0026#39;,main=\u0026#39;Frequency histogram of fish length\u0026#39;) boxplot(Fish$Length, xlab=\u0026#39;Fish length (cm)\u0026#39;, main=\u0026#39;Box plot of fish length\u0026#39;, horizontal = TRUE) Using the main=NULL argument removes the title, which is often unecessary as details of what a plot illustrates are usually written in a figure legend below the plot.\nEdit axis limits Axis limits are set by the xlim and ylim arguments, where a vector of the minimum and maximum limits is required. For example, to have each of these plot the data between 0 and 40, you would use:\nhist(Fish$Length, xlab = \u0026#39;Fish length (cm)\u0026#39;,main=\u0026#39;Frequency histogram of fish length\u0026#39;, xlim=c(0,40)) boxplot(Fish$Length, xlab=\u0026#39;Fish length (cm)\u0026#39;, main=\u0026#39;Box plot of fish length\u0026#39;, ylim=c(0,40), horizontal = TRUE) Note that ylim' is needed there to set the range for the single response variable (Fish length) even though it ends up on the horizontal axis after we use thehorizontal=TRUE` argument. Plot alignment Use the horizontal=TRUE argument to align the box plot horizontally - leave this out if you want a vertical alignment. Adding colour Colour can be added to any part of the plots (axis, fonts etc.) using the col argument. There are over 600 colours that can be plotted, type colors() for the names of the whole range.\nHere we will simply change the colour of the histogram.\nhist(Fish$Length, xlab = \u0026#39;Fish length (cm)\u0026#39;,main=\u0026#39;Frequency histogram of fish length\u0026#39;, col=\u0026quot;red\u0026quot;)  Further help \nType ?hist and ?boxplot to get the R help for these functions. Author: Stephanie Brodie Last updated:\n## [1] \u0026quot;Thu Jan 20 13:13:26 2022\u0026quot;  "
},
{
	"uri": "/statistics/t-tests/one-sample/",
	"title": "One Sample T-test",
	"tags": [],
	"description": "",
	"content": "  One of the simplest hypothesis tests in statistics is to test whether a single parameter from a sample of measurements differs from a hypothesised population parameter. The test is asking what is the likelihood of obtaining that sample from a population with certain properties.\nFor this, we use a one sample t-test. The test statistic, t, has the general form of:\n\\[t = \\frac{St-\\theta}{S_{St}}\\]\nwhere St is the value of the statistic from your sample, \\(\\theta\\) is the population value against which you are comparing your sample, and \\(S_{St}\\) is the standard error of your sample statistic.\nSuch tests can be used for a variety of parameters sampled from populations (e.g., means, slopes and intercepts in linear regression etc.). Here, lets look at a simple example where we test whether the mean of a set of replicated measures differs from a hypothesised value.\nImagine that a forensic scientist was trying to track the origin of some soil samples taken from footprints at a crime scene. She collected 10 samples and analysed the concentration of pollen from a species of pine tree found in a local forest. It was known that soil from that local forest had an average concentration of 125 grains per gram of soil. The one sample t-test will test the likelihood of the ten samples coming from that forest by contrasting the mean concentration in the ten new samples to the value expected if they came from that forest.\nThe test statistic, t is:\n\\[t = \\frac{\\bar{x}-\\mu}{SE}\\]\nwhere \\(\\bar{x}\\) is the sample mean, \\(\\mu\\) is the population mean and SE is the standard error of the sample.\nNote that the size of test statistic depends on two things: 1) how different the sample mean is to the population mean (the numerator) and 2) how much variation is present within the sample (the denominator). The null hypothesis is that the population mean from which the sample was taken is the known value, i.e., \\(H_o: \\mu=125\\). Running the analysis \nThe test statistic t is relatively straightforward to manually calculate. The test statistic can then checked against a t distribution in order to determine the probability of obtaining that value of the test statistic if the null hypothesis is true.\nTo calculate the probability associated with a given value of t in R, use\npt(q, df = your.df, lower.tail = FALSE)*2 where q is your value of t, your.df is the degrees of freedom (n-1). The lower.tail = FALSE ensures that you are calculating the probability of getting a t value larger than yours (i.e., the upper tail, P[X \u0026gt; x]). Note that the critical value for \\(t_{\\alpha = 0.05}\\) varies depending on the number of degrees of freedom - larger degrees of freedom = smaller critical value of t.\nMuch easier is to use the t.test function in R to give you the test statistic and its associated probability in one output. For a one sample t-test, we would use:\nt.test(y,mu=your.mu) where y is a vector with your sample data and your.mu is the population parameter you are comparing the sample to.\nFor our crime scene example, we could assign our ten measurements to an object called pollen and run the t-test on that object.\npollen \u0026lt;- c(94,135,78,98,137,114,114,101,112,121) t.test(pollen, mu = 125) \n Interpreting the results \n## ## One Sample t-test ## ## data: pollen ## t = -3.0691, df = 9, p-value = 0.01337 ## alternative hypothesis: true mean is not equal to 125 ## 95 percent confidence interval: ## 97.20685 120.79315 ## sample estimates: ## mean of x ## 109 The output of a one sample t-test is straight-forward to interpret. In the above output, the test statistic t = -3.0691 with 9 degrees of freedom, and a low p value (p = 0.013). We can therefore reject the null hypothesis and conclude that it was unlikely that the soil samples from the crime scene came from the nearby pine forest.\nYou also get the mean of your sample (109) and the 95% confidence interval for population mean estimated from that sample (this will not overlap your hypothesised mean when the test is significant).  Assumptions to check \nt-tests are parametric tests, which implies we can specify a probability distribution for the population of the variable from which samples were taken. Parametric (and non-parametric) tests have a number of assumptions. If these assumptions are violated we can no longer be sure that the test statistic follows a t distribution, in which case p-values may be inaccurate.\nNormality. The t distribution describes paramaters sampled from a normal population, so assumes that the data are normally distributed. Note however that t tests are reasonably robust to violations of normality (although watch out for the influence of outliers).\nIndependence. The observations should have been sampled randomly from a defined population so that sample mean is an unbiased estimate of the population mean. If individual replicates are linked in any way, then the assumption of independence will be violated.  Communicating the results \nWritten. As a minimum, the observed t statistic, the p value and the number of degrees of freedom should be reported. For example, you could write “The mean pollen count from the footprints (109 ) was significantly lower than expected if it was derived from the nearby forest with an average count of 125 (t = 3.07, df = 9, P = 0.01)”.\nVisual. Box plots or frequency histograms can be used to visualise the variation in a single variable. In this example, you might use a line or arrow to indicate the single value (125) that you were comparing the sample to.\nhist(pollen, xlab = \u0026quot;Pollen count\u0026quot;, main=NULL) abline(v=125,col=\u0026quot;red\u0026quot;) boxplot(pollen,xlab = \u0026quot;Pollen count\u0026quot;,horizontal =TRUE) abline(v=125,col=\u0026quot;red\u0026quot;)  Further help \nType ?t.test to get the R help for this function.\nQuinn and Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Chapter 3: Hypothesis testing. McKillup (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Chapter 9: Comparing the means of one and two samples of normally distributed data. \nAuthor: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 15:47:40 2022\u0026quot;  "
},
{
	"uri": "/graphics/ggplot/",
	"title": "Plotting in R with ggplot2",
	"tags": [],
	"description": "",
	"content": "  ggplot2 is a powerful graphing package in R that can be used to create professional looking plot for reports, essays or papers. It can create a variety of plots including boxplots, scatterpots and histograms and they can be highly customised to suit your data.\nThe package is named after a book called The Grammar of Graphics about how to effectively communicate data graphically. Start with the basics to learn the basic syntax of making a graph\nThen, visit our other pages to further customise the aesthetics of the graph, including colour and formatting:\n* altering the overall appearance\n* adding titles and axis names\n* colours and symbols.\nHelp on all the ggplot functions can be found at the The master ggplot help site.\nA useful cheat sheet on commonly used functions can be downloaded here.\nChang, W (2012) R Graphics cookbook. O’Reilly Media. - a guide to ggplot with quite a bit of help online here \nLast updated:\n## [1] \u0026quot;Thu Jan 20 14:33:18 2022\u0026quot; "
},
{
	"uri": "/statistics/linear-models/anova/anova-single/",
	"title": "Single Factor ANOVA",
	"tags": [],
	"description": "",
	"content": "  Analysis of variance (ANOVA) is one of the most frequently used techniques in the biological and environmental sciences. ANOVA is used to contrast a continuous dependent variable y across levels of one or more categorical independent variables x. The independent variables are termed the factor or treatment, and the various categories within that treatment are termed the levels. In this module, we will start with the simplest design - those with a single factor.\nWhere an independent samples t-test would be used for comparison of group means across two levels, ANOVA is used for the comparison of \u0026gt;2 group means, or when there are more than two or more predictor variables (see ANOVA: factorial). The logic of this test is essentially the same as the t-test - it compares variation between groups to variation within groups to determine whether the observed differences are due to chance or not.\nFor example, to contrast the the hatching times of turtle eggs incubated at four different temperatures (15°C, 20°C, 25°C and 30°C), hatching time is the continuous response variable and temperature is the categorical predictor variable with with four levels. The null hypothesis would be that mean hatching time is equal for all temperatures (Ho: \\(\\mu_{15} = \\mu_{20} = \\mu_{25} = \\mu_{30}\\)).\nNote that an ANOVA is a linear model, just like linear regression except that the predictor variables are categorical rather than continuous.\n\\[y_{ij} = \\mu + \\alpha_i + \\varepsilon_{ij}\\]\nwhere \\(\\mu\\) is the overall mean and \\(\\alpha_i\\) is the effect of the ith group.\nIt is the same as a multiple linear regression with a predictor variable for each level of the categorical variable (each coded as a dummy variable). For the question of whether hatching time of turtles differs between four incubation tempeatures, we must fit four parameters to describe the mean response of each temperature (rather than just a single intercept and single slope in a simple linear regression). For this example, our linear model equation will have this form:\n\\[HatchingTime = \\mu + \\beta_1.Temp_{15} + \\beta_2.Temp_{20} + \\beta_3.Temp_{25} + \\beta_4.Temp_{30} + \\varepsilon\\]\nANOVA partitions the total variance into a component that can be explained by the predictor variable (among levels of the treatment), and a component that cannot be explained (within levels, the residual variance). The test statistic, F, is the ratio of these two sources of variation.\n\\[F = \\frac{MS_{among}}{MS_{within}}\\]\nwhere MS are the mean squares, a measure of variation. The probability of obtaining the observed value of F is calculated from the known probability distribution of F, with two degrees of freedom (one for the numerator = the number of levels -1) and one for the denominator (number of replicates per level - 1 x number of levels). Running the analysis \nThe data should be formatted such that the individual replicates are rows and the variables are separate columns. Include a column for the dependent variable, y, and a corresponding column for the categorical variable, x. Download the sample data set for the turtle hatching example, Turtles.csv, import into R and check that temperature variable is a factor with the str function.\nTurtles = read.csv(file = \u0026quot;Turtles.csv\u0026quot;,header=TRUE) str(Turtles) In this case, because we have numbers for the four levels of the Temperature treatment, we need to change that variable to become a factor rather than an integer.\nTurtles$Temperature = factor(Turtles$Temperature) Now, we can run the analysis of variance contrasting hatching time (days) across temperatures using the function aov. The arguments of the function are simply a formula statement, y~x, with the response variable to the left of the ~, the predictor variable to the right, and some code to specify which data frame holds those variables.\nTurtles.aov = aov(Days ~ Temperature, data = Turtles) The output from this analysis can be seen by using the summary function on the object created.\nsummary(Turtles.aov) Exactly the same analysis can be reproduced using the linear model function lm.\nTurtles.lm = lm(Days ~ Temperature,data=Turtles) summary(Turtles.lm) \n Interpreting the results \n## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Temperature 3 8025 2675.2 15.98 9.08e-07 *** ## Residuals 36 6027 167.4 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 The summary output of an ANOVA object is a table with the degrees of freedom (Df), sums of squares (Sum Sq), mean squares (Mean Sq) for the predictor variable (i.e., variation among levels of your treatment) and for the Residuals (i.e., varation within the levels). The test statistic, F value and its associated p-value (Pr(\u0026gt;F)) are also presented.\nFirst check the degrees of freedom. The factor Df = the number of levels of your factor - 1. The residual Df = a(n-1), where a = the number of levels of your factor and n = sample size (replicates per level).\nThe sums of squares and mean squares are measures of variation. The F statistic is the ratio of MSamong and MSwithin and the p-value is the probability of the observed F value from the F distribution (with the given degrees of freedom).\nThe main thing to look at in the ANOVA table is whether your predictor variable had a significant effect on your response variable. In this example, the probability that all four incubation temperatures are equal is \u0026lt;0.001. This is very unlikely and much less than 0.05. We would conclude that there is a difference in hatching times between the temperatures. We are also interested in the R^2 value which tells us how much variation was explained by the model.\nIf you use the lm function, you get a bit more information from the summary of the linear model output.\n## ## Call: ## lm(formula = Days ~ Temperature, data = Turtles) ## ## Residuals: ## Min 1Q Median 3Q Max ## -28.200 -9.225 1.650 9.025 19.400 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 58.400 4.092 14.273 \u0026lt; 2e-16 *** ## Temperature20 -13.800 5.787 -2.385 0.0225 * ## Temperature25 -9.200 5.787 -1.590 0.1206 ## Temperature30 -38.300 5.787 -6.619 1.04e-07 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 12.94 on 36 degrees of freedom ## Multiple R-squared: 0.5711, Adjusted R-squared: 0.5354 ## F-statistic: 15.98 on 3 and 36 DF, p-value: 9.082e-07 The output for the standard ANOVA table is down the bottom and above it you get the actual parameter estimates from the linear model (the \\(\\beta_1\\), \\(\\beta_2\\) etc from above). In this example, turtles at 15°C hatched after 58.4 days, on average (the intercept in the model). The other parameter estimates are differences between each level of temperature and the intercept. For example, at 20°C they were 13.8 days faster (i.e., the mean for 20°C = 58.4-13.8 = 44.6 days).\nIf you detect any significant differences in the ANOVA, we are then interested in knowing exactly which groups differ from one another, and which do not. Remember that a significant p value in the test you just ran would reject the null hypothesis the means of the dependent variable were the same across all groups, but not identify which were different from each other. To see a comparison between each mean and each other mean, we can use a Tukey’s post-hoc test.\nTukeyHSD(Turtles.aov) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = Days ~ Temperature, data = Turtles) ## ## $Temperature ## diff lwr upr p adj ## 20-15 -13.8 -29.38469 1.784689 0.0982694 ## 25-15 -9.2 -24.78469 6.384689 0.3969971 ## 30-15 -38.3 -53.88469 -22.715311 0.0000006 ## 25-20 4.6 -10.98469 20.184689 0.8562615 ## 30-20 -24.5 -40.08469 -8.915311 0.0008384 ## 30-25 -29.1 -44.68469 -13.515311 0.0000785 \n Assumptions to check \nThe important assumptions of ANOVA are independence, homegeneity of variance and normality. We advocate a qualitative evalutation of the normality and homogeneity of variance assumptions, by examining the patterns of variation in the residuals, rather than a formal test such has Cochran’s test. Linear models in general are quite ‘robust’ for violating these assumptions (heterogeneity and normality), within reason.\nNormality. The assumption of normality can be checked by a frequency histogram of the residuals or by using a quantile plot where the residuals are plotted against the values expected from a normal distribution. The histogram of residuals should follow a normal distribution. If the points in the quantile plot lie mostly on the line, the residuals are normally distributed. Both of these plots can be obtained from the model object created by the aov function.\npar(mfrow = c(1,2)) # This code put two plots in the same window hist(Turtles.aov$residuals) plot(Turtles.aov,which=2) Violations of normality can be fixed via transformations or by using a different error-distribution in a generalised linear model (GLM).\nHomogeneity of variance. The assumption of homgeneity of variance, namely that the variation in the residuals is approximately equal across the range of the predictor variable, can be checked by plotting the residuals against the fitted values from the aov model object.\nplot(Turtles.aov,which=1) Heterogenous variances are indicated by non-random pattern in the residuals vs. fitted plot. Look for an even spread of the residuals on the y axis for each of the levels on the x axis. A fan-shaped distribution with more variance at higher values on the x axis is a common problem when data are skewed. See the testing assumptions of linear models module for more information. If there are strong patterns, one potential solution is to transform the response variable y. If this doesn’t fix the problem the best solution is to use a different error distribution in a generalised linear model (GLM).\nIndependence. ANOVA assumes that all replicate measures are independent of each other (i.e., equally likely to be sampled from the population of possible values for each level). This issue needs to be considered at the design stage. If data are grouped in any way (e.g., half the turtle eggs measured at one time, then the other half measured later), then more complex designs are needed to account for additional factors (e.g., a design with both temperature and time as factors).\nThere are a variety of measures for dealing with non-independence. These include ensuring all important predictors are in the model; averaging across nested observations; or using a mixed-model.  Communicating the results \nWritten. The results of a one-way ANOVA are usually expressed in text as a short sentence, e.g., “Turtle hatching time differed among the four incubation temperatures (F = 15.98, df = 3,36, p \u0026lt; 0.001)”. A significant effect would be followed by a written description of the post-hoc test results (i.e., exactly which temperatures differed from which). The results from post-hoc tests can also be added to the figure (e.g, by labelling which levels differed).\nVisual. A boxplot or column graph with error bars are suitable for contrasting a continuous variable across levels of categorical variable. See the graphics help for making publication ready versions of these figures.\nboxplot(Days~Temperature, data=Turtles, ylab = \u0026quot;Hatching time (days)\u0026quot;, xlab = \u0026quot;Temperature (°C)\u0026quot;)  Further help \nType ?aov or ?lm to get the R help for these functions.\nQuinn and Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Ch. 8 Comparing groups or treatments - analysis of variance. McKillup (2012) Statistics explained. An introductory guide for life scientists Cambridge University Press. Ch. 11. Single-factor analysis of variance. Underood, AJ (1997) Experiments in ecology: Their logical design and interpretation using analysis of variance. Cambridge University Press. \nAuthor: James Lavender Last updated:\n## [1] \u0026quot;Fri Jan 21 16:12:04 2022\u0026quot;  "
},
{
	"uri": "/statistics/t-tests/",
	"title": "T-tests",
	"tags": [],
	"description": "",
	"content": "  Some simple hypothesis tests with the t statistic:\n One sample t tests to contrasting a single sample parameter to a population parameter\n Independent samples t tests to contrast the means of two samples Paired t-tests to contrast two groups of values where each pair is measured from the same object.  "
},
{
	"uri": "/graphics/ggplot/ggplot-basics/",
	"title": "The Basics of ggplot2",
	"tags": [],
	"description": "",
	"content": "  Creating a ggplot \nFirst, you will need to install the package ggplot2 on your machine, then load the package with the usual library function.\nlibrary(ggplot2) The starting point for creating a plot is to use the ggplot function with the following basic structure:\nplot1 \u0026lt;- ggplot(data, aes(x variable, y variable)) + geom_graph.type() print(plot1) data is a data frame that holds the variables that you would like to plot.\naes specifies which variables to plot. This code commonly causes confusion when creating ggplots. While aes stands for aesthetics, in ggplot it does not relate to the visual look of the graph but rather what data you want to see in the graph. It specifies what the graph presents rather than how it is presented.\n+ geom_graph.type specifies what sort of plot you want to make. ggplot will not work unless you have this added on. You don’t actually type ‘graph.type()’, but choose one of the types of graph.\nCommonly used examples include:\n* scatterplot - + geom_point()\n* boxplot - + geom_boxplot()\n* histogram - + geom_histogram()\n* bar plot - + geom_bar()\nEnsure there is a open and closed bracket after the geom code. This tells R to make the graph with the basic standard formatting for this graph type.\nThe type of graph you want to make has to match the classes of the inputs. For example, a scatterplot would require both variables to be numeric. Or a boxplot would require the x variable to be a factor and the y variable to be numeric. You can check the class of any variable with the class function, or all variables in a data frame with the str function.\nA helpful practise when making ggplots is to assign the plot you’ve made to an object (e.g., plot1 in the code above) and then ‘print’ it separately. As your ggplot becomes more complicated this will make it much easier.  Example plots \nIn these examples, let’s use a data set that is already in R with the length and width of floral parts for three species of iris. First, load the data set:\ndata(iris) To contrast petal length across the three species of iris with a box plot, we would use:\nplot1 \u0026lt;- ggplot(iris, aes(Species, Petal.Length)) + geom_boxplot() print(plot1) Note how aes included the x then the y variables which you wanted to plot, and that + geom_boxplot() specified a boxplot.\nTo plot a frequency histogram of petal length, we would use:\nplot2 \u0026lt;- ggplot(iris, aes(Petal.Length)) + geom_histogram() print(plot2) To use a scatter plot the visualise the relationship between petal length and sepal length, we would use:\nplot3 \u0026lt;- ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() print(plot3) These points could then be coloured according to the levels of a categorical variable. To do this, add colour=\"categorical.variable\" in the aes brackets. To colour by species, we would use:\nplot4 \u0026lt;- ggplot(iris, aes(Sepal.Length, Petal.Length, colour=Species)) + geom_point() print(plot4)  Adding a basic theme \nThe overall look of the ggplot can be altered with different set themes. This can be done by adding + theme_bw() or + theme_classic() to the end of your line of code. Like geom(), ensure there is open and closed brackets after the theme name.\nplot5 \u0026lt;- ggplot(iris, aes(Sepal.Length, Petal.Length, colour=Species)) + geom_point() + theme_bw() print(plot5) plot6\u0026lt;-ggplot(iris, aes(Sepal.Length, Petal.Length, colour=Species)) + geom_point() + theme_classic() print(plot6) ###Further help To further customise the aesthetics of the graph, including colour and formatting, see our other ggplot help pages:\n* altering the overall appearance\n* adding titles and axis names\n* colours and symbols.\nHelp on all the ggplot functions can be found at the The master ggplot help site.\nA useful cheat sheet on commonly used functions can be downloaded here.\nChang, W (2012) R Graphics cookbook. O’Reilly Media. - a guide to ggplot with quite a bit of help online here \nAuthor: Fiona Robinson Last updated:\n## [1] \u0026quot;Thu Jan 20 14:34:18 2022\u0026quot;  "
},
{
	"uri": "/statistics/catagorical/contingency-tabs/",
	"title": "Contingency Tables",
	"tags": [],
	"description": "",
	"content": "  Contingency tables are used to test for associations between two or more categorical variables. The data take the form of counts of observations that have been classified by these categorical variables.\nFor example, consider the bill and face colours of the endangered Gouldian Finch (Erythrura gouldiae) living in the savannahs of northern Australia. They are polymorphic, having either red, yellow or black faces. Their bills are also either red, yellow or black, but bill colour is not always the same as face colour. All birds in a sample could be classified into all nine combinations of face and bill colour and the counts of each held in a two-way table:\n## Black face Red face Yellow face ## Black bill 16 5 6 ## Red bill 19 20 6 ## Yellow bill 18 22 22 To test whether one variable is associated with the other we contrast the observed counts to the expected counts if there was no association (in other words if the two variables were entirely independent of each other). In this example, we would be testing whether bill colour varied independently from face colour.\nThe counts expected under this null model are calculated from the row and column totals of the table holding the observed data. For each cell in the table, the expected count is:\n(row total x column total)/grand total\nWhen we do this for each cell, we obtain a new table with all expected values:\n## Black face Red face Yellow face ## Black bill 10.67910 9.470149 6.850746 ## Red bill 17.79851 15.783582 11.417910 ## Yellow bill 24.52239 21.746269 15.731343 These are the expected counts if the null hypothesis is true. In this example, if the numbers of black, red and yellow faced birds are in the same proportions for each of the bill colours.\nThe observed counts are then contrasted to the expected counts with the \\(\\chi^2\\) test statistic,\n\\(\\chi^{2} = \\sum_{i=1}^{k} \\frac{(O_{i}-E_{i})^2}{E_{i}}\\)\nwhere O and E are the observed and expected numbers in each of the cells of the table. Running the analysis \nWith a calculator, you could calculate \\(\\chi^2\\) and then determine the probability of obtaining that \\(\\chi^2\\) value from a table of the known probability distribution of \\(\\chi^2\\). In R, we can obtain that probability by:\npchisq(x, df,lower.tail = FALSE) with x = your value of \\(\\chi^2\\), and degrees of freedom (df) = (number of row-1) x (number of columns-1). The lower.tail = FALSE bit gives you the probability that \\(\\chi^2\\) is greater than your value.\nEasier, is to run the whole analysis in R. Firstly, you would need to enter the observed counts as a matrix.\nGfinch \u0026lt;- matrix(c(16,19,18,5,20,22,6,6,22), nrow=3, dimnames = list(c(\u0026quot;Black bill\u0026quot;, \u0026quot;Red bill\u0026quot;, \u0026quot;Yellow bill\u0026quot;), c(\u0026quot;Black face\u0026quot;, \u0026quot;Red face\u0026quot;, \u0026quot;Yellow face\u0026quot;))) nrow tells R how many rows you have. dimnames labels the rows and columns.\nCheck that you have entered the data correctly by simply entering the name of the matrix you just made.\nGfinch Run the contingency analysis with the chisq.test function.\nchisq.test(x, correct = F) where x is the name of the matrix holding the observed data (for this example use the object Gfinch)  Interpreting the results \nThe output from a contingency table is very simple: the value of \\(\\chi^2\\), the degrees of freedom and the p-value. The p-value gives the likelihood of your observed counts coming from a population where the null hypothesis was true.\n## ## Pearson\u0026#39;s Chi-squared test ## ## data: Gfinch ## X-squared = 12.881, df = 4, p-value = 0.01187 In this example, the probability that the observed counts are derived from a population where the null hypothesis was true is 0.01187. We would then reject the null hypothesis and conclude that there was an association between bill and face colour.\nIt is important to remember that this is not testing either of the variables in isolation (e.g., whether black faced birds are more commonly encountered that red or yellow faced birds), but an association between both variables (i.e., whether bill colour is independent of face colour).\nTo explore which of the cells is the table had more observations than expected, or had fewer observations than expected, look at the standardised residuals. These are the differences between the observed and expected, standardised by the square root of the expected. These are standardised because contrast of the absolute differences (observed - expected) can be misleading when the size of the expected values vary. For example, a difference of 5 from an expectation of 10 is an increase of 50%, but a difference of 5 from an expectation of 100 is only a 5% change).\nchisq.test(Gfinch)$residuals ## Black face Red face Yellow face ## Black bill 1.628236 -1.45259188 -0.3250357 ## Red bill 0.284793 1.06130659 -1.6033875 ## Yellow bill -1.317120 0.05441038 1.5804894 In this example, you can see that birds with a black face are more likely to have a black bill than expected by chance, and less likely to have a yellow bill.  Assumptions to check \nIndependence. The \\(\\chi^2\\) test assumes that the observations are classfied into each category independently of each other. This is a sampling design issue and is usually avoided by random sampling. In this example, there would be problems is you deliberately chose birds with a combination of bill and face colour if you were missing that combination in the birds already sampled.\nSample size. The \\(\\chi^2\\) statistic can only be reliably compared to the \\(\\chi^2\\) distribution if sample sizes are sufficiently large. You should check that at least 20% of the expected frequencies are larger than 5. You can see the expected counts for each category by adding $expected to the end of your \\(\\chi^2\\) test. For example,\nchisq.test(Gfinch)$expected If this assumption has not been met, you could combine categories (if you have more than two and makes sense to do so), run a randomisation test or consider log-linear modelling.  Communicating the results \nWritten. The results of analysing a contingency table can be easily presented in the text of a results section. For example, “There was a significant association between the bill colour and the face colour of Gouldian finches (\\(\\chi^2\\) = 12.88, df = 2, P = 0.01).”\nVisual. Count data are best presented as a bar plot with the counts on the Y axis and the categories on the X axis.\nbarplot(Gfinch,beside=T,ylab=\u0026quot;Count\u0026quot;,xlab=\u0026quot;Face colour\u0026quot;,col=c(\u0026quot;black\u0026quot;,\u0026quot;red\u0026quot;,\u0026quot;yellow\u0026quot;)) legend(\u0026quot;topright\u0026quot;,inset=0.15,c(\u0026quot;Black bill\u0026quot;, \u0026quot;Red bill\u0026quot;, \u0026quot;Yellow bill\u0026quot;),pch=15,col=c(\u0026quot;black\u0026quot;,\u0026quot;red\u0026quot;,\u0026quot;yellow\u0026quot;)) See the graphing modules for making better versions of these figures that are suitable for reports or publications.  Further help \nType chisq.test to get the R help for this function.\nQuinn and Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Chapter 14. Analyzing frequencies.\nMcKillup (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Chapter 20.3 Comparing proportions among two or more independent samples. Author: Alistair Poore Last updated:\n## [1] \u0026quot;Mon Jan 24 12:26:31 2022\u0026quot;  "
},
{
	"uri": "/statistics/glms/glm-2/",
	"title": "Count Data",
	"tags": [],
	"description": "",
	"content": "  Count data\nThis is a continuation of Generalised linear models 1 which introduced GLMs and gave instructions for binary data. Read that first to understand when GLMs are used. On this page, we will cover the use of GLM’s for count data and briefly introduce how they can be used for other data types you may have. Running the analysis \nFor this worked example, we have counts of different animal groups at control sites and sites where bush regeneration has been carried out (treatment). We want to know if the the bush regeneration activities have affected the count of slugs.\nDownload the sample data set, Revegetation.csv, and import into R to see how the data are arranged:\nReveg = read.csv(\u0026quot;Revegetation.csv\u0026quot;, header = T) If you view the frequency histogram of the slug counts, you will see that it is very skewed, with many small values and few large counts (the variable name, Soleolifera, is the order name of terrestrial slugs).\nhist(Reveg$Soleolifera) The default distribution for count data is the Poisson. The Poisson distribution assumes the variance equals the mean. This is quite a restrictive assumption which ecological count data often violate. We may need to use the more flexible negative-binomial distribution instead.\nWe can use a GLM to test whether the counts of slugs (from the order Soleolifera) differ between control and regenerated sites. To fit the GLM, we will use the manyglm function instead of glm so we have access to more useful residual plots.\nTo fit the GLM, load the mvabund package then fit the following model:\nlibrary(mvabund) ft.sol.pois = manyglm(Soleolifera~Treatment, family=\u0026quot;poisson\u0026quot;, data=Reveg) where Soleolifera is the response variable, and Treatment is the predictor variable (with two levels, control and revegetated).  Assumptions to check \nBefore we look at the results, we need to look at the residual plot to check the assumptions.\nplot(ft.sol.pois) ## Warning in default.plot.manyglm(x, res.type = res.type, which = which, caption = ## caption, : Only the first 1 colors will be used for plotting. It’s hard to say whether there is any non-linearity in this plot, this is because the predictor is binary (treatment vs revegetated). Looking at the variance assumption, it does appear as though there is a fan shape. The residuals are more spread out on the right than the left - we call this overdispersion.\nThis tells us the variance assumption of the Poisson may be too restrictive and we should try a different distribution. We can instead fit a negative-binomial distribution in manyglm by changing the family argument to family=\"negative binomial\".\nft.sol.nb = manyglm(Soleolifera~Treatment,family=\u0026quot;negative binomial\u0026quot;,data=Reveg) Look again at the residual plot:\nplot(ft.sol.nb) ## Warning in default.plot.manyglm(x, res.type = res.type, which = which, caption = ## caption, : Only the first 1 colors will be used for plotting. This seems to have improved the residual plot. There is no longer a strong fan shape, so we can go ahead and look at the results.  Interpreting the results \nIf all the assumption checks are okay, we can have a look at the results the model gave us with the same two functions for inference as used for linear models: summary and anova.\nanova(ft.sol.nb) ## Time elapsed: 0 hr 0 min 0 sec ## Analysis of Deviance Table ## ## Model: Soleolifera ~ Treatment ## ## Multivariate test: ## Res.Df Df.diff Dev Pr(\u0026gt;Dev) ## (Intercept) 48 ## Treatment 47 1 10.52 0.002 ** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## Arguments: P-value calculated using 999 iterations via PIT-trap resampling. summary(ft.sol.nb) ## ## Test statistics: ## wald value Pr(\u0026gt;wald) ## (Intercept) 1.502 0.023 * ## TreatmentRevegetated 3.307 0.001 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Test statistic: 3.307, p-value: 0.001 ## Arguments: P-value calculated using 999 resampling iterations via pit.trap resampling. Both tests indicate strong evidence of a treatment effect (p\u0026lt;0.01). To extract the model equation we can look at the coefficients from the fit.\nft.sol.nb$coefficients ## Soleolifera ## (Intercept) -0.9162907 ## TreatmentRevegetated 2.1202635 The default link function for Poisson and negative binomial models is \\(log()\\). If we write the mean count as \\(\\lambda\\)\n\\[ \\log(\\lambda) = -0.92 + 2.12 \\times \\text{Treatment}\\]  Communicating the results \nWritten. Results of GLM’s are communicated in the same way as results for linear models. For one predictor it suffices to write one line, e.g. “There is strong evidence of positive effect of bush regeneration on the abundance of slugs from the order Soleolifera (p \u0026lt; 0.001)”. For multiple predictors it’s best to display the results in a table. You should also indicate which distribution was used (e.g. negative-binomial) and if resampling was used for inference. ” We used a negative-binomial generalised linear model due to overdispersion evident in the data. Inference was carried out using bootstrap resampling with 1000 resamples (default when using manyglm).”\nVisual. In this example, a boxplot would be an effective way to visualse the differences in slug counts between control and revegetated sites.\nboxplot(Soleolifera~Treatment,ylab = \u0026quot;Count\u0026quot;, xlab = \u0026quot;Treatment\u0026quot;, data=Reveg)  Other types of data \nIf you have continuous positive data with zeros, like biomass data, the tweedie distribution might be able to model this, although it does have some quite restrictive assumptions. You can use family=\"tweedie\" with the manyglm function. Be sure to look at residual plots for violations of assumptions.\nFor strictly positive continuous data a gamma distribution can be used. This is available in the glm function using family=gamma.  Further help \nYou can type ?glm and ?manyglm into R for help with these functions.\nFaraway, JJ. 2005. Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC press. Zuur, A, EN Ieno and GM Smith. 20074. Analysing ecological data. Springer Science \u0026amp; Business Media, 2007. More advice on interpreting coefficients in glms Author: Gordana Popovic Last updated:\n## [1] \u0026quot;Fri Jan 21 17:06:48 2022\u0026quot;  "
},
{
	"uri": "/statistics/mixed-models/mixed-model-2/",
	"title": "Crossed and Nested Factors",
	"tags": [],
	"description": "",
	"content": "  Mixed models 1 is an introduction to mixed models with one random factor. After reading that, if you think you have more than one random factor, then read on. For example, you might have crossed or nested factors.\nMany experimental designs in ecology and environmental sciences require mixed models with several random effects (factors). You might have heard of nested and crossed factors. We often define these as quite distinct designs (e.g., from www.theanalysisfactor.com)\nTwo factors are crossed when every category (level) of one factor co-occurs in the design with every category of the other factor. In other words, there is at least one observation in every combination of categories for the two factors.\nA factor is nested within another factor when each category of the first factor co-occurs with only one category of the other. In other words, an observation has to be within one category of Factor 2 in order to have a specific category of Factor 1. All combinations of categories are not represented.\nThere are also intermediate designs that are partially crossed, where some levels of one factor occur in several (but not all) levels of the second factor. These designs have often been taught as separate problems with different ways to carry out analyses of variance (ANOVAs) depending on if you have crossed or nested factors. Using mixed models with the package lme4, we can think if all of these in one framework, where nested and crossed designs are modelled in the same way. Thinking about factors as crossed or nested is simplified to careful labelling of factor levels - more on this later. Running the analysis \nWe will use the package lme4 for all our mixed effect modelling. It will allow us to model both continuous and discrete data with one or more random effects. First, load the package:\nlibrary(lme4) We will analyse a data set that aimed to test the effect of water pollution on the abundance of some subtidal marine invertebrates by comparing samples from modified and pristine estuaries. As the total counts are large, we will assume the data are continuous. Later on, in Mixed models 3, we’ll model counts as discrete using Generalised linear mixed models (GLMMs).\nDownload the sample data set, Estuaries.csv, and load into R.\nEstuaries \u0026lt;- read.csv(\u0026quot;Estuaries.csv\u0026quot;, header = T) Fitting a model with a fixed effect and several random effects\nIn this data set, we have a fixed effect (Modification; modified vs pristine) and two random effects (Estuary and Site). Site is nested within Estuary as each site can only belong in one estuary. When entering the data, however, we’ve been careless and numbered sites within each estuary as 1, 2, 3 etc.\nWe can see this by looking at the data, and a cross tabulation.\nEstuaries[1:10,] ## X Modification Estuary Site Hydroid Total Schizoporella.errata ## 1 1 Modified JAK 1 0 44 15 ## 2 2 Modified JAK 1 0 42 8 ## 3 3 Modified JAK 2 0 32 9 ## 4 4 Modified JAK 2 0 44 14 ## 5 5 Modified JAK 3 1 42 6 ## 6 6 Modified JAK 3 1 48 12 ## 7 7 Modified JAK 4 0 45 28 ## 8 8 Modified JAK 4 0 34 1 ## 9 9 Pristine JER 1 7 29 0 ## 10 10 Pristine JER 1 5 51 0 xtabs(~ Estuary + Site, Estuaries, sparse = TRUE) ## 7 x 4 sparse Matrix of class \u0026quot;dgCMatrix\u0026quot; ## Site ## Estuary 1 2 3 4 ## BOT 2 2 2 2 ## CLY 2 2 2 2 ## HAK 2 2 2 2 ## JAK 2 2 2 2 ## JER 2 2 2 2 ## KEM 2 2 . 2 ## WAG 2 2 2 2 Estuary JAK and estuary JER each have sites numbered 1, even though these sites are not connected in any way. We can also see this in the cross tabulation xtabs. This site labelling looks crossed, where each site occurs in each estuary, rather than nested.\nWe can fix this by simply telling R that Site is nested in Estuary. It is best practice, however, to do this at the data entry stage. If things are the same, then they should be labelled the same, and if they are not they should be labelled differently.\nTo create a unique label for each site in this data set, we convert Site to a factor (it was an integer), and create a new variable (SiteWithin) that is the combination of Estuary and Site\nEstuaries$Site \u0026lt;- as.factor(Estuaries$Site) Estuaries$SiteWithin \u0026lt;- paste0(Estuaries$Estuary, \u0026quot;_\u0026quot;, Estuaries$Site) Now, check the structure to see that each site is nested in only one Estuary, consistent with the experimental design.\nxtabs(~ Estuary + SiteWithin, Estuaries, sparse = TRUE) ## 7 x 27 sparse Matrix of class \u0026quot;dgCMatrix\u0026quot; ## [[ suppressing 27 column names \u0026#39;BOT_1\u0026#39;, \u0026#39;BOT_2\u0026#39;, \u0026#39;BOT_3\u0026#39; ... ]] ## ## BOT 2 2 2 2 . . . . . . . . . . . . . . . . . . . . . . . ## CLY . . . . 2 2 2 2 . . . . . . . . . . . . . . . . . . . ## HAK . . . . . . . . 2 2 2 2 . . . . . . . . . . . . . . . ## JAK . . . . . . . . . . . . 2 2 2 2 . . . . . . . . . . . ## JER . . . . . . . . . . . . . . . . 2 2 2 2 . . . . . . . ## KEM . . . . . . . . . . . . . . . . . . . . 2 2 2 . . . . ## WAG . . . . . . . . . . . . . . . . . . . . . . . 2 2 2 2 To fit a model for total abundance, we would use:\nfit.mod \u0026lt;- lmer(Total ~ Modification + (1|Estuary) + (1|SiteWithin), data = Estuaries) summary(fit.mod) ## Linear mixed model fit by REML [\u0026#39;lmerMod\u0026#39;] ## Formula: Total ~ Modification + (1 | Estuary) + (1 | SiteWithin) ## Data: Estuaries ## ## REML criterion at convergence: 386.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -1.8686 -0.6687 0.1504 0.6505 1.9816 ## ## Random effects: ## Groups Name Variance Std.Dev. ## SiteWithin (Intercept) 49.85 7.061 ## Estuary (Intercept) 47.59 6.899 ## Residual 43.65 6.607 ## Number of obs: 54, groups: SiteWithin, 27; Estuary, 7 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 41.053 4.739 8.662 ## ModificationPristine -14.553 6.232 -2.335 ## ## Correlation of Fixed Effects: ## (Intr) ## MdfctnPrstn -0.760 where Total is the dependent variable (left of the ~), Modification is the fixed effect, and Estuary and SiteWithin are the random effects.\nWe’ll also fit the wrong model, to see the difference if we had used the old labels for each site.\nfit.wrong \u0026lt;- lmer(Total ~ Modification + (1|Estuary) + (1|Site), data = Estuaries) summary(fit.wrong ) ## Linear mixed model fit by REML [\u0026#39;lmerMod\u0026#39;] ## Formula: Total ~ Modification + (1 | Estuary) + (1 | Site) ## Data: Estuaries ## ## REML criterion at convergence: 393.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.3312 -0.7631 0.1040 0.5766 1.8202 ## ## Random effects: ## Groups Name Variance Std.Dev. ## Estuary (Intercept) 53.613 7.322 ## Site (Intercept) 7.686 2.772 ## Residual 80.045 8.947 ## Number of obs: 54, groups: Estuary, 7; Site, 4 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 41.257 4.849 8.508 ## ModificationPristine -14.757 6.124 -2.410 ## ## Correlation of Fixed Effects: ## (Intr) ## MdfctnPrstn -0.727 The only place we can see an obvious difference is under the Random effects table. For the correct model we have Number of obs: 52, groups: SiteWithin, 26; Estuary, 7 while the wrong model tells us we have only 4 sites, which we know is incorrect.\nNote: fit.wrong would be correct if we had crossed factors  Checking assumptions \nThe assumptions are the same as for one random factor, but it doesn’t hurt to list them again\nThe observed \\(y\\) are independent, conditional on some predictors \\(x\\)\n The response \\(y\\) are normally distributed conditional on some predictors \\(x\\)\n The response \\(y\\) has constant variance, conditional on some predictors \\(x\\)\n There is a straight line relationship between \\(y\\) and the predictors \\(x\\) and random effects \\(z\\)\n Random effects \\(z\\) are independent of \\(y\\).\n Random effects \\(z\\) are normally distributed\n  See Mixed models 1 for detailed guidance about assumptions in linear mixed models. Briefly, assumptions 1 and 5 cannot be checked, but can be ensured by taking random samples, and assumption 6 is not crucial and difficult to check. To check assumption 2 we look for a straight line relationship on the normal quantile plot. To check assumptions 3, and 4 we look for a fan shape and U shape on the residual vs. fitted plot.\npar(mfrow=c(1,2)) qqnorm(residuals(fit.mod)) scatter.smooth(residuals(fit.mod)~fitted(fit.mod)) #residual plot The normal quantile plot looks reasonable, however we see here a definite fan shape in the residual vs. fit plot. Let’s try transforming the response and see if we do better.\nfit.mod \u0026lt;- lmer(log(Total) ~ Modification + (1|Estuary) + (1|SiteWithin), data = Estuaries) par(mfrow=c(1,2)) qqnorm(residuals(fit.mod)) scatter.smooth(residuals(fit.mod)~fitted(fit.mod)) #residual plot This scatterplot is much better, the fan shape is all but gone. The smooth line is below zero on the left, but there are relatively few points there, so it’s not of great concern.  Interpreting the results \nHypothesis test for the fixed effect\nWe can use the anova as before to obtain approximate p-values for fixed effects.\nft.mod \u0026lt;- lmer(log(Total)~Modification + (1|Estuary) + (1|SiteWithin), data=Estuaries, REML=F) ft.mod.0 \u0026lt;- lmer(log(Total)~(1|Estuary) + (1|SiteWithin), data=Estuaries, REML=F) anova(ft.mod.0,ft.mod) ## Data: Estuaries ## Models: ## ft.mod.0: log(Total) ~ (1 | Estuary) + (1 | SiteWithin) ## ft.mod: log(Total) ~ Modification + (1 | Estuary) + (1 | SiteWithin) ## npar AIC BIC logLik deviance Chisq Df Pr(\u0026gt;Chisq) ## ft.mod.0 4 79.223 87.179 -35.611 71.223 ## ft.mod 5 77.397 87.342 -33.698 67.397 3.8258 1 0.05047 . ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 We find weak evidence of an effect of Modification (p=0.05047).\nHypothesis test for random effects\nAs in Mixed models 1 we will use a parametric bootstrap. We will test if we need to have a random effect for Site given we have a random effect for Estuary in the model. I’ve taken the code from Mixed models 1 and changed the relevant parts, you can compare the two to get an idea of how to write your own parametric bootstrap code.\nnBoot=1000 lrStat \u0026lt;- rep(NA,nBoot) ft.null \u0026lt;- lmer(log(Total) ~ Modification + (1|Estuary) , Estuaries, REML=F)#null model ft.alt \u0026lt;- lmer(log(Total) ~ Modification + (1|Estuary) + (1|SiteWithin), Estuaries, REML=F)#alternate model lrObs \u0026lt;- 2*logLik(ft.alt) - 2*logLik(ft.null) #observed test stat for(iBoot in 1:nBoot) { Estuaries$logTotalSim \u0026lt;- unlist(simulate(ft.null)) #resampled data bNull \u0026lt;- lmer(logTotalSim~Modification + (1|Estuary) , Estuaries, REML=F)#null model bAlt \u0026lt;- lmer(logTotalSim~Modification+(1|Estuary)+ (1|SiteWithin), Estuaries, REML=F)#alternate model lrStat[iBoot] \u0026lt;- 2*logLik(bAlt) - 2*logLik(bNull)#resampled test stat } mean(lrStat\u0026gt;lrObs) #P-value for test of Estuary effect ## [1] 0 The p-value is 0, so very small. We have strong evidence of an effect of Site and should keep it in the model.  Communicating results \nWritten. Results of linear mixed models are communicated in a similar way to results for linear models. In your results section you should mention that you are using mixed models with R package lme4, and list your random and fixed effects. You should also mention how you carried out inference, i.e. likelihood ratio tests (using the anova function) or parametric bootstrap. In the results section for one predictor, it suffices to write one line, e.g., “There is strong evidence (p\u0026lt;0.001) of negative effect of modification on total abundance”. For multiple predictors it’s best to display the results in a table.\nVisual. The best way to visually communicate results will depend on your question, for a simple mixed model with one random effect, a plot of the raw data with the model means superimposed is one possibility. There is a little bit of code that is required for such a plot, and it will be a little different for your data and model.\nYou can plot within each site, but this is a bit odd for a boxplot as there are only two observations per site, you might want to do this for your data if you have more observations within each Site.\nlibrary(Hmisc) ## Loading required package: lattice ## Loading required package: survival ## Loading required package: Formula ## Loading required package: ggplot2 ## ## Attaching package: \u0026#39;Hmisc\u0026#39; ## The following objects are masked from \u0026#39;package:base\u0026#39;: ## ## format.pval, units ModEst \u0026lt;- unique(Estuaries[c(\u0026quot;SiteWithin\u0026quot;, \u0026quot;Modification\u0026quot;)])#find which Estuaries are modified cols \u0026lt;- as.numeric(ModEst[order(ModEst[,1]),2])+3 #Assign colour by modification boxplot(log(Total)~ SiteWithin,data=Estuaries,col=cols,xlab=\u0026quot;Estuary\u0026quot;,ylab=\u0026quot;Total invertebrates\u0026quot;) legend(\u0026quot;bottomleft\u0026quot;, inset=.02, c(\u0026quot; Modified \u0026quot;,\u0026quot; Pristine \u0026quot;), fill=unique(cols), horiz=TRUE, cex=0.8) means=fitted(fit.mod) #this will give the estimate at each data point Est.means=summarize(means, Estuaries$SiteWithin, mean)$means #extract means by site stripchart(Est.means~ sort(unique(SiteWithin)),data=Estuaries,pch=18,col=\u0026quot;red\u0026quot;,vertical = TRUE,add=TRUE)#plot means by site Alternatively, you can plot by Estuary as before (see Mixed models 1). Further help \nYou can type ?lmer into R for help with these functions.\nDraft book chapter from the authors of lme4.\nFaraway, JJ (2005) Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC Press. Zuur, A, EN Ieno and GM Smith (2007) Analysing ecological data. Springer Science \u0026amp; Business Media. \nAuthor: Gordana Popovic Last updated:\n## [1] \u0026quot;Mon Jan 24 12:21:35 2022\u0026quot;   "
},
{
	"uri": "/graphics/ggplot/ggplot-appearance/",
	"title": "Customising your ggplot",
	"tags": [],
	"description": "",
	"content": "  ggplots are almost entirely customisable. This gives you the freedom to create a plot design that perfectly matches your report, essay or paper.\nThe overall appearance can be edited by changing the style or prescence of grid lines, axis notches, panel colour, legend colour or outlines.\nBefore you get started, read the page on the basics of plotting with ggplot and install the package ggplot2.\nlibrary(ggplot2) \nCreating a customised theme \nOne of the most effective ways to customise your plot is to create a customised theme and separate this from your basic ggplot code. By separating and saving your theme, it will be much easier to edit, alter and reuse for other projects.\nIn these examples, let’s use a data set that is already in R with the length and width of floral parts for three species of iris. First, load the data set:\ndata(iris) The following code for a scatter plot of petal length vs sepal length with the three species colour-coded is the base that we will use throughout this tutorial.\nIrisPlot\u0026lt;-ggplot(iris, aes(Sepal.Length, Petal.Length, colour=Species)) + geom_point()  To change the design of an element of your plot, you create a theme then print the plot with the theme applied. For example, some code to change the colour and size of the legend in the above plot would look like this.\nmytheme \u0026lt;- theme(legend.title = element_text(colour = \u0026quot;steelblue\u0026quot;, size = rel(2))) We would then reprint the base plot with this theme added:\nprint(IrisPlot + mytheme) Themes can have many different elements, that relate to legends, axes, titles etc. Separate each within the theme code with a comma.  Formatting the plot and legend background \nThe plot and legend background can be changed to any colour listed here using the following code:\n panel.background = element_rect(your format) will alter the panel behind the graph.\n legend.key = element_rect(your format) alters the boxes next to each category name.\n legend.background = element_rect(your format) will alter the box around the legend names and boxes.  For each of these, the formats you can alter are:\n fill = \"colour\" to colour the panel behind the plot.\n colour = \"colour\" will alter the axis outline of the graph.\n size = (number) will alter the thickness of this outline.  To demonstrate how this works, here is a ugly theme with obvious colours chosen to demonstrate the differences:\nmytheme \u0026lt;- theme(panel.background = element_rect(fill = \u0026quot;black\u0026quot;, colour = \u0026quot;yellow\u0026quot;, size = 4), legend.key = element_rect(fill = \u0026quot;darkgrey\u0026quot;, colour = \u0026quot;yellow\u0026quot;), legend.background = (element_rect(colour= \u0026quot;yellow\u0026quot;, fill = \u0026quot;blue\u0026quot;))) print(IrisPlot + mytheme)  Altering the size, colour or presence of grid lines \nThe grid lines are divided into two sets of grid lines; major and minor. This allows you to accentuate or remove half the grid lines.\n* panel.grid.major = element_line(your format) - alters the format of major grid lines.\n* panel.grid.minor = element_line(your format) - alters the format of minor grid lines.\nwhere (your format) specifies the colour and thickness of the lines.\nFormats include:\n* Colour. For example, colour = \"steelblue2\" - remember to include “” before and after the colour name.\n* Size. Specified by entering a number, for example, size = (3).\nPutting these together in a theme would look like this:\nmytheme \u0026lt;- theme(panel.grid.major = element_line(colour=\u0026quot;black\u0026quot;, size = (1.5)), panel.grid.minor = element_line(size = (0.2), colour=\u0026quot;grey\u0026quot;)) print(IrisPlot + mytheme) To remove the grid lines, use the element_blank().\nmytheme \u0026lt;- theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank()) print(IrisPlot + mytheme)  Altering the x and y axis lines \nThe size and colour of axis lines themselves can be customised in the same way as the grid lines (above), using axis.line=element_line(your format). For example:\nmytheme \u0026lt;- theme(axis.line = element_line(size = 1.5, colour = \u0026quot;red\u0026quot;), panel.background = element_rect(fill = \u0026quot;white\u0026quot;)) print(IrisPlot + mytheme)  Altering the axis ticks/notches \nThe size and colour of the ticks can be altered using axis.ticks = element_line(your format). For example:\nmytheme \u0026lt;- theme(axis.ticks = element_line(colour = \u0026quot;red\u0026quot;, size=(2))) print(IrisPlot +mytheme)  Removing any element of a theme \n= element_blank() is used if you wish to entirely remove an element of the formatting. For example, to get rid of ticks, grid lines and the background, you would use:\nmytheme \u0026lt;- theme(axis.ticks = element_blank(), panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background= element_blank()) print(IrisPlot +mytheme)  Example of a fully customised ggplot \nHere is an example of a ggplot with many of the elements customised. This is obviously a lot of code, but remember that you can save and reuse your favorite theme as often as you like. See the page on adding titles and axis names for help with those parts of the print() code.\nIrisPlot \u0026lt;- ggplot(iris, aes(Sepal.Length,Petal.Length,colour=Species,shape=Species))+geom_point() mytheme3 \u0026lt;- theme(legend.text = element_text(face = \u0026quot;italic\u0026quot;,colour=\u0026quot;steelblue4\u0026quot;, family = \u0026quot;Helvetica\u0026quot;, size = rel(1)), axis.title = element_text(colour=\u0026quot;steelblue4\u0026quot;,family = \u0026quot;Helvetica\u0026quot;, size = rel(1.5)), axis.text = element_text(family = \u0026quot;Helvetica\u0026quot;,colour = \u0026quot;steelblue1\u0026quot;, size = rel(1.5)), axis.line = element_line(size = 1,colour = \u0026quot;black\u0026quot;), axis.ticks = element_line(colour=\u0026quot;grey\u0026quot;,size = rel(1.4)), panel.grid.major = element_line(colour=\u0026quot;grey\u0026quot;,size = rel(0.5)), panel.grid.minor = element_blank(), panel.background = element_rect(fill = \u0026quot;whitesmoke\u0026quot;), legend.key = element_rect(fill = \u0026quot;whitesmoke\u0026quot;), legend.title = element_text(colour = \u0026quot;steelblue\u0026quot;,size = rel(1.5), family = \u0026quot;Helvetica\u0026quot;), plot.title = element_text(colour = \u0026quot;steelblue4\u0026quot;, face = \u0026quot;bold\u0026quot;, size = rel(1.7),family = \u0026quot;Helvetica\u0026quot;)) print(IrisPlot + mytheme3+ ggtitle(\u0026quot;Iris species petal and sepal length\u0026quot;) + labs(y=\u0026quot;Petal length (cm)\u0026quot;, x = \u0026quot;Sepal length (cm)\u0026quot;, colour = \u0026quot;Species\u0026quot;) + scale_colour_manual(values = c(\u0026quot;slateblue\u0026quot;, \u0026quot;slateblue2\u0026quot;, \u0026quot;slateblue4\u0026quot;))) ###Further help To further customise the aesthetics of the graph, including colour and formatting, see our other ggplot help pages:\n* adding titles and axis names\n* colours and symbols.\nHelp on all the ggplot functions can be found at the The master ggplot help site.\nA useful cheat sheet on commonly used functions can be downloaded here.\nChang, W (2012) R Graphics cookbook. O’Reilly Media. - a guide to ggplot with quite a bit of help online here \nAuthor: Fiona Robinson Last updated:\n## [1] \u0026quot;Thu Jan 20 13:34:15 2022\u0026quot;  "
},
{
	"uri": "/statistics/linear-models/anova/anova-factorial/",
	"title": "Factorial ANOVA",
	"tags": [],
	"description": "",
	"content": "  Analysis of variance (ANOVA) is one of the most frequently used techniques in the biological and environmental sciences. ANOVA is used to contrast a continuous dependent variable y across levels of one or more categorical independent variables x. The independent variables are termed the factor or treatment, and the various categories within that treatment are termed the levels. Here, we will consider designs with two or more factors that are both applied to the experimental units (read the single factor ANOVA page first if you are unfamiliar with ANOVA).\nFrequently, we want to test for differences in a response variable due to two or more factors. These experimental or sampling designs allow us to test for the effects of each of these factors separately (termed main effects), and to test whether the two factors interact. For these designs, we use more complex versions of ANOVA than the most simple design that tests the effects of only one factor.\nConsider an example where a researcher is testing the effects of metal contamination on the number of species found in sessile marine invertebrates (sponges, bryozoans and sea squirts etc.). They would like to know whether copper reduces species richness, but also know that the richness of invertebrates can depend on whether the substrate is vertical or horizontal. Consequently, they ran an experiment where species richness was recorded in replicate samples in each of the six combinations of copper enrichment (“None”,“Low”,“High”) and orientation (“Vertical”,“Horizontal”). The experimental design in termed factorial because all levels of one treatment are represented in all levels of the other treatment (also termed orthogonal).\nThe factorial ANOVA will test:\n* whether there are any differences in richness among the three levels of copper enrichment\n* whether there are any differences in richness among the two levels of substrate orientation\n* whether there is any interaction between copper and orientation\nYou have three null hypotheses:\n* there is no difference between the means for each level of copper, Ho: \\(\\mu_{None} = \\mu_{Low} = \\mu_{High}\\)\n* there is no difference between the means for each level of orientation, $Ho: \\(\\mu_{Vertical} = \\mu_{Horizontal}\\)\n* there is no interaction between the factors\nThis is far better than running two separate single factor ANOVAs that contrast copper effects for each level of orientation because you have more statistical power (higher degrees of freedom) for the tests of interest, and you get a formal test of the interaction between factors which is often scientifically interesting.\nNote that an ANOVA is a linear model, just like linear regression except that the predictor variables are categorical rather than continuous. With two predictor variables, the linear model is:\n\\[y_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\varepsilon_{ijk}\\]\nwhere \\(\\mu\\) is the overall mean, \\(\\alpha_i\\) is the effect of the ith group of the first factor, and \\(\\beta_i\\) is the effect of the jth group of the second factor and \\((\\alpha\\beta)\\) is the interaction.\nAthough we have two factors, and an interaction effect, this requires fitting more than 3 parameters in our model because we have 3 levels of Factor A (Copper) and 2 levels of Factor B (Orientation) (if you can figure out how many parameters must be fit in this model, you are officially a stats geek! This is tricky even for those ‘in the know’).\nWith two factors, ANOVA partitions the total variance into a component that can be explained by the first predictor variable (among levels of the treatment A), a component that can be explained by the second predictor variable (among levels of the treatment B), a component that can be explained by the interaction, and a component that cannot be explained (within levels, the residual variance). The test statistic, F, is calculated three times to test each of the null hypotheses. For two fixed factors, the F ratios are:\n\\[F = \\frac{MS_{A}}{MS_{within}}\\] \\[F = \\frac{MS_{B}}{MS_{within}}\\] \\[F = \\frac{MS_{AB}}{MS_{within}}\\]\nwhere MS are the mean squares, a measure of variation. The probability of obtaining the observed value of F is calculated from the known probability distribution of F, with two degrees of freedom (one for the numerator = the number of levels -1) and one for the denominator. Note that these F ratios will change if any factors are random (see below for the distinction between fixed and random factors), Running the analysis \nYour data should be formatted with the measurements from each replicate as a row and each of the variables as columns, corresponding to the dependent variable y, Factor A and Factor B.\nDownload the sample data set for the sessile invertebrates, Sessile.csv, and import into R to to see the desired format. Check that your predictor variables are factors with the function str\nSessile = read.csv(file = \u0026quot;Sessile.csv\u0026quot;, header = TRUE) str(Sessile) With our predictor variable correctly assigned as factors, we can now run the analysis. As with other forms of linear models we have a model formula with the dependent variable, y, to the left of the ~ and the predictor variables to the right. For this two factor design, we use:\nSessile.aov = aov(Richness ~ Copper * Orientation, data = Sessile) Note that when you specify a model with * between the two predictors, R automatically includes both variables and their interaction. This same model could also be written as:\nSessile.aov = aov(Richness ~ Copper + Orientation + Copper:Orientation, data = Sessile) The output from this analysis can be seen by using the summary function on the object created.\nsummary(Sessile.aov) Exactly the same model can also be run using the linear model function, lm.\nSessile.lm = lm(Richness ~ Copper * Orientation, data = Sessile) anova(Sessile.lm) \n Interpreting the results \n## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Copper 2 3330 1665.0 192.53 \u0026lt; 2e-16 *** ## Orientation 1 240 240.0 27.75 2.46e-06 *** ## Copper:Orientation 2 571 285.4 33.00 4.34e-10 *** ## Residuals 54 467 8.6 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 The summary output of an ANOVA object is a table with the degrees of freedom (Df), sums of squares (Sum Sq), mean squares (Mean Sq) for the each of predictor variable (i.e., variation among levels of your treatments), their interaction and for the Residuals (i.e., varation within the levels). The test statistic, F value and its associated p-value (Pr(\u0026gt;F)) are also presented.\nCheck that you have the correct degrees of freedom. For a two factor design with fixed factors they are:\n* Factor A: a - 1 (where a = number of levels of Factor A)\n* Factor B: b - 1 (where b = number of levels of Factor B)\n* Interaction (AB): (a-1)(b-1)\n* Residual: ab(n -1) (where n = sample size)\nThe sums of squares and mean squares are measures of variation. There are three F statistics, corresponding to a test of each of the main effects and one for the interaction. The p-values are the probabilities of the observed F values from the F distribution (with the given degrees of freedom).\nIn this example, there is strong evidence to reject all three null hypotheses:\n* that all levels of the copper treatment are equal (P \u0026lt; 0.001),\n* that the vertical and horizontal orientations are equal (P \u0026lt; 0.001)\n* that there is no interaction between copper and orientation (P \u0026lt; 0.001)\nA significant interaction means that the effect of one factor depends upon the other. In this example, it would mean that the effect of copper was not consistent between the vertical and horizontal habitats. Consequently, the interpretation of the main effects becomes more complex. See Understanding interactions for more help on interpreting interactions in linear models. A quick way to help you understand an interaction if you get one is to examine an interactions plot.\ninteraction.plot(Sessile$Copper, Sessile$Orientation, Sessile$Richness) Here you can see that the effect of copper (a decline in species richness) is more pronounced in the habitats with a vertical orientation, and that the difference between the two habitats changes with exposure to copper. Multiple comparisons. If you detect any significant differences in the ANOVA, we are then interested in knowing exactly which levels differ from one another, and which do not. Remember that a significant p value in the test you just ran would reject the null hypothesis the means were the same across all groups, but not identify which were different from each other. If there is no interaction, you can run a post-hoc test on each of the main effects (only needed if there are more than two levels for an effect). If there is an interaction, you will need to consider post-hoc tests that contrast the means from all combinations of both factors.  Assumptions to check \nThe assumptions of factorial ANOVA’s are the same as for all linear models including the simpler one-way ANOVA’s (see ANOVA: single factor), being independence, normality and homogeneity of variances. We also need to consider two new issues: 1) whether your factors are fixed or random, and 2) whether your sampling or experimental design is balanced (i.e., has the same number of replicates in each combination of treatments).\nFixed and random factors. There is an important distinction between factors whose levels are the only ones of interest (termed fixed), and factors whose levels are a sampled from a larger collection of possible levels (termed random). For example, if we repeated the experiment above at three different sites in Sydney Harbour, chosen from many possible sites, we would consider site a random factor. We are not interested in those sites in particular, but would like to know if our experimental treatments were consistent across sites. On the other hand, if you were only interested in Darling Harbour and Circular Quay, then these two could be considered two levels of a fixed factor. Treating sites as a fixed factor in that case means that you conclusions should not be extrapolated to other possible sites, but restricted to those particular sites.\nStatistically, there is a big difference between a fixed factors were you have measured all possible levels of interest (e.g, control vs a single treatment) and random factors where the levels are sampled from all possible levels. In analysis of variance, all this matters because the F tests that are being used to test your hypotheses are constructed differently depending on which factors are fixed and random. In the example above, all factors were fixed and the denominator of all F tests was \\(MS_{within}\\). In models with all factors random, and models with a mix of fixed and random factors (termed mixed effects models), other components of the variation are used as the denominators in the F tests.\nIf you have random factors, you will need to read more than this help page to establish the correct F ratios for your design, and you may need to calculate them manually. Note that the code presented will give correct F tests only for designs with all factors fixed. You should also strongly consider analysing your data as a mixed model\nBalanced and unbalanced designs. Ideally, factorial ANOVA should be conducted with a balanced design - one with the same number of replicates in each combination of factors. Balanced designs are less likely to be affected by minor deviations from the assumptions of normality and homogeneity of variance. Unfortunately, unbalanced designs where you have unequal numbers of replicates for each level are common in practice (e.g. bad weather prevented sampling the second site as intensively, volunteer lost the data sheet etc!).\nUnbalanced designs are more susceptible to violating the assumptions of ANOVA and there is no single way to partitioning the \\(SS_{total}\\) into the main effect and interaction components. The aov and lm functions in R use what are called Type I sums of squares where the terms in the model are fitted sequentially (i.e., how much variation is explained by factor A, then how much additional variation is explained by adding factor B). This means that the order of the terms in model matters: the model formulae Y ~ A + B + A:B and Y ~ B + A + B:A will give you different results.\nThere is a fair bit of debate on this in the statistical literature, but many advise using what are called Type II or Type III sums of squares for unbalanced designs. Other software packages like SPSS, SYSTAT and Minitab will automatically use Type III sums of squares where the order of terms in the model doesn’t matter. To access these in R, we can use the Anova function in the car package.\nNormality. The assumption of normality can be checked by a frequency histogram of the residuals or by using a quantile plot where the residuals are plotted against the values expected from a normal distribution. The histogram of residuals should follow a normal distribution. If the points in the quantile plot lie mostly on the line, the residuals are normally distributed. Both of these plots can be obtained from the model object created by the aov function.\npar(mfrow = c(1,2)) # This code put two plots in the same window hist(Sessile.aov$residuals) plot(Sessile.aov,which=2) Violations of normality can be fixed via transformations or by using a different error-distribution in a generalised linear model (GLM).\nHomogeneity of variance. The assumption of homgeneity of variance, namely that the variation in the residuals is approximately equal across the range of the predictor variable, can be checked by plotting the residuals against the fitted values from the aov model object.\nplot(Sessile.aov,which=1) Heterogeneous variances are indicated by non-random pattern in the residuals vs. fitted plot. Look for an even spread of the residuals on the y axis for each of the levels on the x axis. A fan-shaped distribution with more variance at higher values on the x axis is a common problem when data are skewed. See the testing assumptions of linear models module for more information. If there are strong patterns, one potential solution is to transform the response variable y. If this doesn’t fix the problem the best solution is to use a different error distribution in a generalised linear model (GLM).\nIndependence. ANOVA assumes that all replicate measures are independent of each other (i.e., equally likely to be sampled from the population of possible values for each level). This issue needs to be considered at the design stage. If data are grouped in any way (e.g., half the invertebrate samples measured at one time, then the other half measured later), then more complex designs are needed to account for additional factors (e.g., a design with an additional factor of sampling time).\nThere are a variety of measures for dealing with non-independence. These include ensuring all important predictors are in the model; averaging across nested observations; or using a mixed model  Communicating the results \nWritten. The results of the main effects and any interaction should be described in the text of a results section. Each F test can be described in the text, e.g., “The copper treatment and substrate orientation interacted to affect the species of sessile invertebrates (F = 19.33, df = 2,54, p \u0026lt; 0.001)”. Alternatively, all tests could be put into a Table like the one given in the output following summary(Sessile.aov) above. Description of the main tests would be followed by a description of the post-hoc results if used.\nRemember that the interpretation of the main effects is complicated when there is a significant interaction (see above). In this example, while copper reduced species richness, that effect was not consistent between the two habitats. In other scenarios with an interaction, you might have copper affecting richness in one habitat but not another, preventing you making a simple statement like “copper reduced species richness” because it wouldn’t always be true.\nVisual. A boxplot or column graph with error bars are suitable for contrasting a continuous variable across levels of categorical variable. See the graphing modules for making publication ready versions of these figures.\nboxplot(Richness ~ Copper*Orientation,data = Sessile, names = c(\u0026quot;High.H\u0026quot;,\u0026quot;Low.H\u0026quot;,\u0026quot;None.H\u0026quot;,\u0026quot;High.V\u0026quot;,\u0026quot;Low.V\u0026quot;,\u0026quot;None.V\u0026quot;),ylab=\u0026quot;Species richness\u0026quot;,xlab=\u0026quot;Copper/Orientation\u0026quot;,ylim=c(0,80))  Further help \nType ?aov or ?lm to get the R help for these functions.\nQuinn and Keough (2002) Experimental design and data analysis for biologist. Cambridge University Press. Ch. 9 Multifactor analysis of variance. McKillup (2012) Statistics explained. An introductory guide for life scientists Cambridge University Press. Ch. 13 two-factor analysis of variance. Underwood (1997) Experiments in ecology: Their logical design and interpretation using analysis of variance.\u0026gt; Cambridge University Press. \nAuthors: James Lavender \u0026amp; Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 16:14:58 2022\u0026quot;  "
},
{
	"uri": "/getting-started-with-r/",
	"title": "Getting Started with R",
	"tags": [],
	"description": "",
	"content": "  Throughout this site, instructions for statistical analyses, data management and graphical techniques are provided in the software language R. R is a free, open source language that has rapidly become standard usage in the biological and environmental sciences. Apart from the cost, the language has the benefits of being able to explicitly share methods with colleague, and a very active community of people who are developing packages that will run very many types of analyses and graphics.\nBefore you get started with making graphics and doing analyses, you will need to:\n Install R and learn the basics of using R\n Think about project management to plan how you are going to organise your files   Data entry After collecting data, being able to enter those data and import into various software packages are obviously essential skills for students and researchers in the environmental sciences. You might think that you just write the numbers in a spreadsheet package and open that file in another piece of software, but there is actually quite a bit to be learnt about tidy ways to enter the data and import that data without errors.\nOn these pages, we give some guidance for data entry that will save a lot of time when it comes to analysing data and making effective figures. We also describe the types and structure of data objects in R that you will see once you have imported your data.\n Data entry - organising data when first entering it into a spreadsheet.\n Importing data into R\n Data types and structure - better understanding data objects in R   Further help \nThe British Ecological Society’s Guide to Data Management in Ecology and Evolution Author: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 15:51:49 2022\u0026quot;  "
},
{
	"uri": "/statistics/linear-models/",
	"title": "Linear Models",
	"tags": [],
	"description": "",
	"content": "  These pages have some introductions to commonly used linear models that test the response of a continuous dependent variable against one or more predictor variables that may be continuous or categorical. Note that these are only named as different techniques (e.g., regression vs ANOVA) due to common usage in the literature that you will encounter - they all involve the same linear modelling framework.\n Linear regression Analysis of variance: single factor Analysis of variance: factorial\n Understanding interactions Interpreting coefficients in linear models  \nAuthor: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 16:02:11 2022\u0026quot; "
},
{
	"uri": "/graphics/multivariate-vis/pca/",
	"title": "Principal Component Analysis",
	"tags": [],
	"description": "",
	"content": "  Principal Components Analysis (PCA) is the one of the most widely used multivariate statistical techniques. The primary motivation behind PCA is to reduce, or summarize, a large number of variables into a smaller number of derived variables that may be readily visualised in 2- or 3-dimensional space. For example, PCA might be used to compare the chemistry of different watersheds based on multiple variables or to quantify phenotypic variation amongst species based on multiple morphological measurements.\nThe new set of variables created by PCA can be used in other analyses, but most commonly as a new set of axes on which to plot your multivariate data.\nThe first principal component (PC) is fitted such that it explains the maximum amount of variation in the data. Think of this as a line of best fit in multivariate space, as close as possible to all the points with the variation maximised along the line and minimised on the perpindicular away from the line. The second PC is fitted at right angles to the first (i.e., orthogonally, with with no correlation) such that it explains as much of the remaining variation as possible. Additional PCs, which must be orthogonal to existing PCs, can then be fitted by the same iterative process.\nVisualising this in two dimensions helps to understand the approach. The data points will be plotted on the new blue axes (the principal components) rather than the original black axes. Now imagine fitting those lines in more than three dimensions!\nConsider a plant physiologist attempting to quantify differences in leaf shape between two species of tree. She recorded total length (leaf + petiole), leaf length, width at the widest point, width half way along the leaf and petiole length from ten leaves of each species. These data are five dimensional (i.e., five measured variables) and we can use PCA to extract two new variables that will allow us to visualise the data in fewer dimensions.\nIt is highly likely that there are strong relationships between variables in our example data set (e.g., leaf length vs total length). This means that the principal components are likely to explain a fair bit of the variation (imagine fitting a straight line along a sausage-shaped collection of points in multivariate space). If all variables were completely uncorrelated with each other, then PCA is not going to work very well (imagine trying to fit a line of best best fit a ball-shaped collection of points in multivariate space). Running the analysis \nYour data should be formatted with variables as columns and observations as rows. Download the sample leaf shape data set, Leafshape.csv., and import into R to see the required format.\nLeaf_shape \u0026lt;- read.csv(file = \u0026quot;Leafshape.csv\u0026quot;, header = TRUE) The first column is a categorical variable that labels the leaves by species (A or B). We need to extract that to a new object (Species) that we can use later for plotting, and make a new data frame (Leaf_data) with just the variables to be analysed by PCA (columns 2-6).\nSpecies \u0026lt;- Leaf_shape$Species Leaf_data \u0026lt;- Leaf_shape[,2:6] There are a number of function and packages in R available for conducting PCA, one of the simplest of which is the princomp function in base stats. To run a PCA, we simply use:\nLeaf_PCA \u0026lt;- princomp(Leaf_data, cor = FALSE) Calling the plot function on the scores of the princomp output produces a score plot. This is the ordination of all 20 leaf samples in the new two-dimensional space defined by PC1 and PC2. Here, we can also label the samples by species with the colour argument, and add a legend.\nplot(Leaf_PCA$scores, pch = 16, col = as.factor(Species)) legend(0,0.4,c(\u0026quot;Species A\u0026quot;,\u0026quot;Species B\u0026quot;),pch=16,col=c(\u0026quot;black\u0026quot;,\u0026quot;red\u0026quot;))  Interpreting the results \nThe interpretation of the score plot is the same as for any ordination plot: points that are close together have similar values of the original variables (in this case, would have been close together in five dimensional space if you can imagine that).\nPrincipal components analysis produces a lot of graphical and numerical output. To fully interpret the results you need to understand several things:\n1) How much variance is explained by each component? This can be found by using the summary object produced by the PCA.\nsummary(Leaf_PCA) ## Importance of components: ## Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 ## Standard deviation 0.8302248 0.22418865 0.11987329 0.1035367 0.0089705579 ## Proportion of Variance 0.9013599 0.06572552 0.01879107 0.0140183 0.0001052315 ## Cumulative Proportion 0.9013599 0.96708539 0.98587647 0.9998948 1.0000000000 The proportion explained independently by each component is provided in the second row of the output from summary. In this example, PC1 explains 90% of the variation between the two species with PC2 2 explaining a further 6.6%. Together, those two axes (the ones you are now plotting on) explain 96.7% of the variance (the cumulative proportion row in the output). This means that those original data in five dimensions can be placed almost perfectly on this new two-dimensional plane.\nThe relative contribution of each component can also also visualised by a scree plot. Note that the Y-axis presented is not the % of variation explained. The contributions always decline with the number of the component, and ideally we would want as much variation as possible explained by the first two, as these are the ones we are using to visualise the data.\nscreeplot(Leaf_PCA, type = \u0026#39;lines\u0026#39;) 2 How are the original variables related to the principal components?\nThese relationships can obtained numerically by extracting the loadings from the object produced by the PCA.\nloadings(Leaf_PCA) ## ## Loadings: ## Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 ## Total_length 0.772 0.244 0.582 ## Petiole_length 0.458 -0.169 0.647 -0.586 ## Leaf_length 0.320 0.428 -0.627 -0.564 ## Width1 -0.949 0.160 -0.215 -0.163 ## Width2 -0.300 -0.259 0.826 0.400 ## ## Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 ## SS loadings 1.0 1.0 1.0 1.0 1.0 ## Proportion Var 0.2 0.2 0.2 0.2 0.2 ## Cumulative Var 0.2 0.4 0.6 0.8 1.0 The loadings are simple correlations between the principal components and the original variables (Pearson’s r). Values closest to 1 (positive) or -1 (negative) will represent the strongest relationships, with zero being uncorrelated.\nIn this example, you can see that PC1 is positively correlated with the two width variables. R doesn’t bother printing very low correlations, so you can also see that PC1 is uncorrelated with the three length variables. Given the the two species are split along the x-axis in the score plot (PC1), we now know that species A with high values of PC1 has wider leaves than species B with low values of PC1. We also know that leaves toward the top of the plot are the longest due to the positive correlations between PC2 and the three length variables (but this does not separate the two species on the plot).\nYou can also produce a biplot with the relationships between the original variables and the principal components overlaid on the score plot. The original variables (in red) will have a strong relationship with one of the principal components if they are parallel to that component (eg Width 1 and PC1) and longer arrows represent stronger correlations.\nbiplot(Leaf_PCA)  Assumptions to check \nLinearity. PCA works best when the relationship between variables are approximately linear. In the absence of linearity it is best to transform variables (e.g., log transform) prior to the analysis.\nCorrelation vs covariance matrices. You can run PCA using a covariance matrix, which is appropriate when all variables are measured on the same scale, or a correlation matrix, which is appropriate if variables are measured on very different scales. These will produce different output because using a covariance matrix is affected by differences in the size of variances among the variables. Researchers also commonly standardise variables prior to the analysis if they would like variables that were measured on different scales to have an equal influence on the output.\nChange between these two options with the cor argument in the princomp function.\nLeaf_PCA = princomp(Leaf_data, cor = FALSE) # uses a covariance matrix Leaf_PCA2 = princomp(Leaf_data, cor = TRUE) # uses a correlation matrix Outliers. Outliers can have big influence on the results of PCA, especially when using a covariance matrix.\nRotating axes. The princomp function produces an unrotated principal components analysis. There are options in other R packages for rotating the principal components after they have been derived with the aim of an output that is easier to interpret (e.g., where the loadings within a component are close to one or zero). There are several methods for doing this, and you would need to read more than this help module before attempting such methods.\n Communicating the results \nWritten. In the results section, it would be typical to state the amount of variation explained by the first two (or three) PCs and the contribution of different variables to those PCs. In this example, you would state that the first principal component explained 90% of the variation in leaf morphology and was most strongly related to leaf width at the widest point.\nVisual. PCA results are best presented visually as a 2-dimensional or, rarely, a 3-dimensional ordination plot (see above) where the position of each observation represents is position in relation to the first two (or three) principal components. It is common to label the points in some way to seek patterns on the plot (like how we labelled leaves by species above).  Further help \nType ?princomp to get the R help for this function.\nAn nice interactive page to help you understand what PCA is doing can be found here.\nQuinn, GP and MJ Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Ch. 17. Principal Components and Correspondence Analysis. McKillup, S (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Ch. 22. Introductory concepts of multivariate analysis. \nAuthor: Andrew Letten Last updated:\n## [1] \u0026quot;Thu Jan 20 14:38:50 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/subsetting-data/",
	"title": "Subsetting data",
	"tags": [],
	"description": "",
	"content": "  We often want to subset our data, whether it’s to examine particular rows or columns of our dataset, or to pull out observations with particular properties. We may conduct subsetting at the data exploration stage to investigate whether our response variable differs in its relationship to a particular predictor variable across categories (e.g., to look for an interaction). We may also like to pull out elements of our dataset for separate analyses.\nIn this exercise, we will load a dataset where bats were sampled across regrowth forest in south-eastern Australia which has been thinned to reduce the density of trees.\nThe dataset includes measurements of total number of bat calls (“Activity”) and number of bat calls that indicate foraging behaviour (“Foraging”) recorded over one night for 47 sites and 173 sampling nights in total. Variables relating to forest thinning have been collected and are listed as columns ending in “thinned”. As the forest studied was in a floodplain, covariates relating to water availability were also collected and are listed in columns ending “water”.\nFirst, download the data set, Bats_data.csv, and load into R.\nBats \u0026lt;- read.csv(file=\u0026quot;Bats_data.csv\u0026quot;, header=T, stringsAsFactors=F) Basics of subsetting in R Check the structure after you have loaded the data with the str function.\nNow that we have some idea of the dataset we are working with, we can use the [] and $ operators to select rows and columns in a dataframe. It’s quite simple: we place the name of the dataframe we want to select from before the square brackets and inside the square brackets we place a comma. Numbers to the left of the comma represent rows we’d like to select and numbers to the left of the comma represent columns we’d like to select.\nFor example, if we wanted to select only data from the first three rows and all columns, we would use:\nBats[1:3,] If we wanted only the last four columns and all rows, we would use:\nBats[,7:10] In combination, this would select data from only the first three rows from the last four columns:\nBats[1:3, 7:10] If the row and column numbers that you want do not form a sequence, we can use the \u0026gt;c() function to concatenate row or column indices. For example, let’s add the sixth row and the 2nd column to our selection from above:\nBats[c(6,1:3), c(2,7:10)] Rather than working out which variable is in which numbered column, it is often easier to use the variable names in a data frame and select the variable using $ operator. For example, to choose only the Site variable:\nBats$Site  Subsetting rows in dplyr The package dplyr has many convenient functions for subsetting that can be more intuitive and quick for you. First, install then load the package:\nlibrary(dplyr) Subsetting by row numbers\nIf you know the row numbers that you are interested in subsetting, you can easily select these rows either using square brackets as discussed above or the slice function in dplyr.\nFor example, to select just rows 10-12 in the dataframe, you would use:\nBats.slice \u0026lt;- slice(Bats, 10:12) Selecting rows that meet certain criteria\nWe can subset these rows using the filter function. For example, if wanted only the rows where foraging activity was recorded, we could select for rows where the count of foraging calls was greater than zero.\nBats.foraging \u0026lt;- filter(Bats, Foraging \u0026gt; 0) You can experiment with a range of logical operators when using the filter function\n\u0026lt; less than\n\u0026gt;greater than\n==equal to\n\u0026lt;=less than or equal to\n\u0026gt;=greater than or equal to\n!=not equal to\nin.NA=is NA\n!is.na=is not NA\nand more.\nYou can use the commands ?base::Logic and ?Comparison to learn more about these operators.\nYou will notice that while using the above functions, we have mostly assigned them to new objects, e.g., Bats.foraging \u0026lt;-... . This gives us the option to use the newly subsetted data for further computations.\nTaking a random selection of rows\nWe may want to randomly select a number or fraction of rows in our dataset to validate our models. For example, we could take 50% of the data to build the model and then 50% of the model to test it against observed data. Random selection of rows is important if we are going to split the data up this way, because we don’t want to bias our data to any particular properties or categories. Here we make a new dataframe “Bats.50p” which has half the number of rows of the initial dataset:\nBats.50p \u0026lt;- sample_frac(Bats, size = 0.5, replace=FALSE) Similarly, we could ask for a certain number of rows to be randomly sampled from the data set. For example, to randomly sample 100 rows, we would use:\nBats.100r \u0026lt;- sample_n(Bats, 100, replace=FALSE) Selecting rows with the highest values\ndplyr has a neat function for selecting n rows with the highest values of any given column: top_n. Below, we identify the three rows of data which contain the greatest total bat activity per night:\nBats.top \u0026lt;- top_n(Bats, 3, Activity) print(Bats.top) ## Site Activity Foraging Date Treatment.thinned Area.thinned ## 1 CC04A1 802 9 7/01/2013 short-term 0 ## 2 PC32A2 1070 66 7/01/2013 medium-term 0 ## 3 PC32A2 944 52 8/01/2013 medium-term 0 ## Time.since.thinned Exclusion.thinned Distance.murray.water ## 1 0 11.932831 143.9868 ## 2 8 7.150972 429.2099 ## 3 8 7.150972 429.2099 ## Distance.creek.water ## 1 102.5009 ## 2 694.7085 ## 3 694.7085 Wow, over 1000 bat calls in one night!\nRemoving duplicate rows\nAnother useful function is to remove duplicate rows, for example if we have accidentally entered data twice.\nBats.distinct \u0026lt;- distinct(Bats) We can compare the number of rows between our original dataset and our new dataset with duplicates removed and our old dataset using \u0026lt;nrow:\nnrow(Bats) ## [1] 173 nrow(Bats.distinct) ## [1] 173 In this case, the dataframes are identical because our data doesn’t have any duplicate rows.\n Subsetting columns in dplyr As discussed above, you can select one column $ or one or more by indexing with []. dplyr has the function select which allows you to select columns by name or by using useful helper functions.\nSelecting columns by name\nFor example, to select just the Site column from the data frame, or both the Site and Date columns:\nBats_subset1 \u0026lt;- select(Bats, Site) Bats_subset2 \u0026lt;- select(Bats, Site, Date) Selecting several columns by their position\nTo select a group of columns adjacent to each other use the first and last names separated by :. For example, this selects all columnns between Site and Date.\nBats_subset3 \u0026lt;- select(Bats, Site:Date) Selecting columns by their properties\nThe in-built helper functions within select allow you to select particular columns according to their properties.\nFor example, we could select the two columns (Distance.murray.water \u0026amp; Distance.creek.water) by the start of the column names, or the end of the column names:\nBats_subset4 \u0026lt;- select(Bats, starts_with(\u0026quot;Distance\u0026quot;)) Bats_subset4 \u0026lt;- select(Bats, ends_with(\u0026quot;water\u0026quot;)) If you are familiar with regular expressions, you can use the match helper function. For example, to select those same two columns, we could use ^ to indicate the column name starts with the following characters and $ to indicate the column name ends with the preceding characters.\nBats_subset4 \u0026lt;- select(bats, matches(\u0026quot;^Distance\u0026quot;)) Bats_subset4 \u0026lt;- select(bats, matches(\u0026quot;water$\u0026quot;)) We can use contains when we want to select columns that contain certain characters or words in their name.\nBats_subset4 \u0026lt;- select(Bats, contains(\u0026quot;water\u0026quot;)) The helper function one_of will select columns that belong to a list of column names, remembering to use c() to concatenate the list of names.\nBats_subset4 \u0026lt;- select(bats, one_of(c(\u0026quot;Distance.murray.water\u0026quot;, \u0026quot;Distance.creek.water\u0026quot;))) Note that all the last 6 uses of select did exactly the same thing - pulled out the two columns, Distance.murray.water and Distance.creek.water.\nYou can also name particular columns that you want to exclude from the selection using a minus in fron of the column name to be excluded. For example, to make a data frame that no longer has the Foraging variable:\nBats_subset5 \u0026lt;- select(Bats, -Foragaing) Finally, if you have numbered columns, we can use the numrange helper function to select particular columns. For example, this code would select for columns named var1, var2, \u0026amp; var3.\nselect(data, num_range(\u0026quot;var\u0026quot;, 1:3)) \n Further help This tutorial was based on the excellent Data wrangling with dplyr and tidyr cheat sheet produced by Rstudio. Images were sourced from the same document.\nYou can type ?dplyr to get help with this package.\nIntroduction to dplyr\nAuthor: Rachel V. Blakey\nLast updated:\n## [1] \u0026quot;Thu Jan 20 14:28:50 2022\u0026quot;  "
},
{
	"uri": "/graphics/basic-plotting/two-continuous/",
	"title": "Two Continuous Variable",
	"tags": [],
	"description": "",
	"content": "  Visualising the relationship between two continuous variables is one of the most commonly used graphical techniques in the sciences. This page details how to produce simple scatterplots to display how one continuous variable is related to another.\nFor this worked example, download a data set on plant heights around the world, Plant_height.csv, and import into R.\nPlant_height \u0026lt;- read.csv(file = \u0026quot;Plant_height.csv\u0026quot;, header = TRUE) \n###Scatterplots### To visualise how plant height varies with temperature, we can use a simple scatterplot, using the plot function. Place the Y variable on the left of the tilde (~) and the X variable on the right. The data=Plant_height argument tells R to look in the data frame Plant_height for those two variables.\nplot(height ~ temp, data = Plant_height) If the two variables you would like to plot are in different objects in R, you would simply use:\nplot(y ~ x) where y and X are two vectors of equal length. Formatting plots \nScatterplots can be formatted using the basic R formatting in the graphics package. The code below details some of the more commonly used formatting commands for simple scatterplots. These commands can be used for any plotting function in the graphics package.\nAdd axis labels or titles Axis labels are produced with the xlab and ylab arguments. Titles are provided with the main argument. Note that figures in scientific publications rarely have a title, but include information about the plot in a figure legend presented below the plot.\nplot(height ~ temp, data = Plant_height, xlab=\u0026#39;Temperature (°C)\u0026#39;, ylab = \u0026#39;Plant height (m)\u0026#39;,main=\u0026#39;Plant height vs temperature\u0026#39;) Edit axis limits Axis limits are set by the xlim and ylim arguments, where a vector of the minimum and maximum limits is required. For example to set the Y axis to have a minimum of zero and a maximum of 80 m, and the x axis to range between -20 and 30, use:\nplot(height ~ temp, data = Plant_height, xlab=\u0026#39;Temperature (°C)\u0026#39;, ylab = \u0026#39;Plant height (m)\u0026#39;, ylim = c(0,80),xlim = c(-20,30)) Symbol style The choice of symbols to use in plotting is extensive and choices are accessed using the pch argument in the graphical parameters. Type ?pch to see all the choices.\nA solid circles pch=16 or pch=19 are often the neatest way to display data on a scatterplot.\nplot(height~temp,data=Plant_height, xlab=\u0026#39;Temperature (°C)\u0026#39;, ylab = \u0026#39;Plant height (m)\u0026#39;, ylim = c(0,80),pch=16) Adding colour Colour can be added to any part of the plots (axis, fonts etc.) using col argument. There are over 600 colours that can be plotted, type colours() for the whole range.\nHere we will simply change the colour of the symbols to blue.\nplot(height~temp,data=Plant_height, xlab=\u0026#39;Temperature (°C)\u0026#39;, ylab = \u0026#39;Plant height (m)\u0026#39;, pch=16, col=\u0026quot;blue\u0026quot;) Adding a line of best fit To further explore the relationship between two variables you can add a line of best fit. For example, to add the line of best fit from a simple linear regression, we would use the linear modelling function, lm, to obtain the slope and intercept, and add this line to the scatterplot via the graphical parameter abline.\nSee the page on linear regression for the analysis of tree height versus temperature for this data set. The dependent variable analysed was the log transformed data for tree height (loght). To plot this against temperature with the line of best fit from the linear model, we would use:\nplot(loght ~ temp, data = Plant_height, xlab=\u0026#39;Temperature (°C)\u0026#39;, ylab = \u0026#39;log(Plant height)\u0026#39;,pch=16) abline(lm(loght ~ temp, data = Plant_height))  Further help \nType ?plot and ?abline to get the R help for these functions.\n\nAuthors: Stephanie Brodie \u0026amp; Alistair Poore Last updated:\n## [1] \u0026quot;Thu Jan 20 13:19:54 2022\u0026quot;  "
},
{
	"uri": "/statistics/t-tests/two-sample/",
	"title": "Two Sample T-test",
	"tags": [],
	"description": "",
	"content": "  An independent samples t-test aka a two sample t-test is one of the most commonly used statistical tests. It is used for comparing whether the means of two samples are statistically different from each other (e.g., control vs. treatment, site A vs site B etc). For example, consider the simple case of whether a sample of pH measurements from one river differs from a sample of pH measurements from a second river.\nThe null hypothesis is that the population means from which the two samples are taken are equal \\[H_o: \\mu_1=\\mu_2\\].\nThe test statistic, t, is:\n\\[t = \\frac{\\bar{x_{1}}-\\bar{x_{2}}}{s_{\\bar{y_{1}}-\\bar{y_{2}}}}\\]\nwhere the denominator is the standard error of the difference between the two means.\n\\[\\sqrt{\\frac{(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}{(\\frac{1}{n_{1}}}+\\frac{1}{n_{2}})}\\]\nNote that the size of test statistic depends on two things: 1) how different the two means are (the numerator) and 2) how much variation is present within each sample (the denominator).\nThis equation is for the pooled variance t-test. For a separate variances t-test (also known as Welch’s t test), which does not assume equal variances, the denominator is:\n\\[\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}\\]\nNote that a t test is a special case of a linear model with a single continuous response variable and a single categorical predictor variable that has two levels. Running the analysis \nAn independent samples t-test can be run with the same t.test function as used for one sample or paired t-tests. For an independent samples t-test assuming equal variances, we would use:\nt.test(x \u0026lt;- my_sample1, y = my_sample2, var.equal = TRUE) where my_sample1 and my_sample2 are vectors containing the measurements from each sample.\nMore commonly, we would use a data frame with the response and predictor variables as separate columns. You can then use a formula statement, y ~ x, to specify the response and predictor variables rather than the code above. Consider the simple example where you wanted to compare the pH of two rivers. Ten replicate pH measures were taken from each river.\nDownload the sample data set, River_pH.csv, and import into R.\nRiver_pH = read.csv(file = \u0026quot;River_pH.csv\u0026quot;, header = TRUE) The t-test is run with the t.test function, with the arguments specifying the response variable (pH) to the left of the ~, the predictor variable (River_name) to the right of the ~, and the data frame to be used.\nt.test(pH ~ River_name, data = River_pH, var.equal = TRUE) The argument var.equal = TRUE specifies that we are assuming equal variances. Note the default t-test argument for the alternative hypothesis is a two-tailed test. If you want to conduct a one-tailed test you must add an argument to the function specifying alternative = \"greater\" or alternative = \"less\".\n Interpreting the results \n## ## Two Sample t-test ## ## data: River_pH$pH by River_pH$River_name ## t = 6.9788, df = 18, p-value = 1.618e-06 ## alternative hypothesis: true difference in means between group A and group B is not equal to 0 ## 95 percent confidence interval: ## 1.574706 2.931168 ## sample estimates: ## mean in group A mean in group B ## 8.661497 6.408560 The output of a t-test is straight-forward to interpret. In the above output, the test statistic t = 6.9788 with 18 degrees of freedom, and a very low p value (p \u0026lt; 0.001). We can therefore reject the null hypothesis that the two rivers have the same pH.\nYou also get the means from the two samples (needed to know which one is larger if the test is significant), and the 95% confidence interval for the difference between the two means (this will not overlap zero when the test is signficant).  Assumptions to check \nt-tests are parametric tests, which implies we can specify a probability distribution for the population of the variable from which samples were taken. Parametric (and non-parametric) tests have a number of assumptions. If these assumptions are violated we can no longer be sure that the test statistic follows a t distribution, in which case p-values may be inaccurate.\nNormality. The data are normally distributed. Note however that t tests are reasonably robust to violations of normality (although watch out for the influence of outliers).\nEqual variance. The variances of each sample are assumed to be approximately equal. t tests are also reasonably robust to violations of equal variance if sample sizes are the same but can be problematic when sample sizes are very different.\nIn the event of unequal variances, it may be better to perform a Welch’s t test which does not assume equal variances. To conduct a Welch test in R, the var.equal argument in t.test function should be changed to var.equal=FALSE. This is in fact the default argument for t.test if not specified.\nIndependence. The observations should have been sampled randomly from the population so that the two sample means are unbiased estimates of the population means. If individual replicates are linked in any way, then the assumption of independence will be violated.  Communicating the results \nWritten. As a minimum, the observed t statistic, the P-value and the number of degrees of freedom should be reported. For example, you could write “the pH was significantly higher in River A than River B (independent samples t-test: t = 6.98, df = 18, P \u0026lt; 0.001)”.\nVisual. Box plots or column graphs with error bars are effective ways of communicating the variation in a single continuous response variable versus a single categorical predictor variable.\nboxplot(pH~River_name, data = River_pH, xlab = \u0026quot;River name\u0026quot;, ylab = \u0026quot;pH\u0026quot;)  Further help \nType ?t.test to get the R help for this function.\nQuinn and Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Chapter 3: Hypothesis testing. McKillup (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Chapter 9: Comparing the means of one and two samples of normally distributed data. \nAuthor: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 15:58:29 2022\u0026quot;  "
},
{
	"uri": "/getting-started-with-r/rstudio-notebooks/",
	"title": "Using R Notebooks",
	"tags": [],
	"description": "",
	"content": "  If you are working in the laboratory or in the field, it is essential to keep good notes on what you are doing so that you can remember your methods and ensure that your work is reproducible.\nSimilarly, once you are dealing with the data you have collected, good notes on how you have processed that data are essential. They help you in understanding exactly what you are doing and are needed to write methods sections, and to communicate both methods and results to collaborators or supervisors.\nIn a traditional R script, all the text is code and comments are separated from executable code by starting a line with #. For example,\nplot(y ~ x) # code to make a plot of y vs x This can get messy if you have lots of comments, so we recommend looking at RStudio notebooks as a very clean way of writing your code with associated comments.\nRStudio notebooks are a form of markdown document, a widely used format for exporting text and code to various report formats. All web pages on this site start their life as markdown files with all the text, code needed to make the html file. Rstudio notebooks have the added benefits of displaying the output from your code directly in the document. Creating a new notebook \nCreating a new notebook is as simple as clicking File, New File, R Notebook from the RStudio menu. You will need a recent version of RStudio (1.0 or higher), so update that if necessary.\nSave the file in a folder on your computer. This folder will become the working directory for any code in your notebook and there is no need to set the working directory.\nEdit the title at the top, have a quick read of the notes then delete the template provided (from “This is an [R Markdown]…”” onwards). Make sure you leave the first few lines in between the — marks.\nYour notebook is now just a big blank page for you to start writing down all the steps involved in your work. For example, you might want to start with a brief description of the project.  Adding code to your notebook Executable code is added to your notebook in what are called chunks. To do this, click on Insert, R from the top right of your notebook (or use Ctrl + Alt + I on the keyboard). This will add an empty chunk that looks like this:\nAny code that you want to run then be added inside the chunk. I like to use the first chunk in the notebook to load any R packages that might be required for the upcoming work. E.g.,\nBe careful not to delete the ``` marks as the text will no longer be recognised as code.  Running the code \nRunning all the code in your chunk is done by clicking the little green arrow at the top right of your chunk. Just like in a script you can still run individual lines of code by entering Ctrl+Enter with your cursor on that line.\nUse the chunks to organise your workflow, grouping code that does a particular task within a chunk and preceding these by plain text comments that explain what each chunk will do. Avoid putting every single line of code in a separate chunk and avoid having very many lines of code that do different things within the same chunk.\nOutput from your code will appear directly below the code chunk rather than in the console below or the plots pane to the right. For example, a plot of plant height vs temperature from the data set used in our linear regression tutorial.\nYou can hide or show any output within your notebook by clicking on the little upward arrows (top right of output).\nTo expand or collapse all output click on the cog symbol next to Preview at the top of the notebook. The settings in there can also be used to send all output to the console (Chunk output in Console) or keep in the notebook (Chunk Output Inline).\nIf you save the notebook and leave RStudio, the output is saved and you will see plots etc when you reopen the file. If you have made any changes to code or data files, however, you will need to run the code again.\nThis is easily done by clicking Run, Run all. Also very useful when you are part way through a document is Run All Chunks Above to ensure everything is refreshed and running correctly.  Exporting your notebook to other formats \nIn addition to being a visually appealing way to combine code and comments, notebooks can also be used to create reports in various formats (html, pdf and word).\nClicking on Preview will give you a sneak preview of what this might look like. To make the documents, you would then choose Knit to HTML for example to make an html file.\nThe html files created are an excellent way to share your work with collaborators and supervisors. The single document can be opened in any browser on any device and has all comments, code, statistical output and figures. Your reader doesn’t need to run any code (or even be an R user) to see what you have done. The html files even have neat little buttons where you can hide and show the code, and the ability to reverse the whole process and download a markdown file from the html.\nWhen you knit to HTML for the first time, you may be prompted for some packages that are not on your machine (e.g., knitr, rmarkdown). If this happens, install those and do it again.\nWhen you first look at your html file, you may also realise that there are some unwanted parts (e.g., warning messages) and that the formatting could improved. To fix these, you need to learn a bit more about controlling the behaviour of code chunks, and some basic formatting.\nThese are nicely detailed on RStudio’s R Markdown cheatsheet. Here are a just few of the more useful options: .\n Some basic markdown formatting \n    Markdown Output    Header 1 # Header 1  Header 2 ## Header 2  Header 3 ## Header 2  italics italics  bold bold  Inserting an image:   Inserting a link: More help at Environmental Computing-http://environmentalcomputing.net More help at Environmental Computing     Controlling chunk behaviour \nYou can control how the code and its output is displayed in the exported document with a series of options for each chunk. There are lots of these (detailed here), but a few useful ones are:\nIf you want to show the code but not run it, use eval=F within the {r} at the top of your chunk Choose to run code in the output or not\n#```{r, eval=F} 2+2 To run the code, but hide the code in the output:\n#```{r, echo=F} 2+2 To hide all messages and warnings:\n#```{r, warning=F, message=F} 2+2 ## [1] 4 To change the size of any plots:\n#```{r, fig.height=3, fig.width=10} ggplot(Plant_height, aes(temp, loght)) + geom_point() These can also be set once at the top of the document rather than individually for each chunk (termed Global options). For example, to set the size of all figures, we would use:\n\nFurther help \nRStudio’s introduction to notebooks\nRStudio’s R Markdown cheatsheet\nNathan Stephen’s Why I love R notebooks\nJonathan McPherson’s R Notebooks Author: Alistair Poore Last updated:\n## [1] \u0026quot;Wed Jan 19 11:00:35 2022\u0026quot;   "
},
{
	"uri": "/coding-skills/writing-functions/",
	"title": "Writing Functions",
	"tags": [],
	"description": "",
	"content": "  A function is a self contained chunk of code which performs a specified task. Think of them as “mini-scripts” that are written separately from your main script.\nWell-written code uses lots of functions. This likely includes:\n functions from base R, functions from packages you have installed, and functions you have written yourself.  It’s hard to do anything in R without using some of the built-in functions, but have you written you’re own functions? If not, it’s time to start.\nBelow we spend some time outlining the two main types of function, why use functions, and then how they are constructed.\nTo illustrate our examples, we will use a sample data set containing a series of different measurements from replicated algal samples. You can read the data into R directly from the web:\nlibrary(tidyverse) algae \u0026lt;- read_csv(\u0026quot;Algal_traits.csv\u0026quot;) (or if you like download the data set, Algal_traits.csv). Taking a look we see a bunch of variables like height, weight etc\n## # A tibble: 60 × 8 ## Location Type Species height length dryweight wetwet strength ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 w1 red.algae a 0.395 2.16 0.956 2.46 2.993355157 ## 2 w1 red.algae a 0.0189 1.98 0.0655 1.96 2.756726384 ## 3 w1 red.algae a 0.698 4.72 0.200 2.24 2.252360245 ## 4 w1 red.algae a 0.139 2.00 0.467 1.53 2.310011661 ## 5 w1 red.algae a 0.377 4.41 0.978 2.10 2.334597887 ## 6 w2 red.algae a 0.0767 0.572 0.100 1.61 \u0026lt;NA\u0026gt; ## 7 w2 red.algae a 0.933 0.839 0.564 1.75 2.472866529 ## 8 w2 red.algae a 0.0617 4.62 0.252 1.72 2.635546813 ## 9 w2 red.algae a 0.991 4.08 0.254 1.71 2.521458416 ## 10 w2 red.algae a 0.314 2.13 0.125 2.14 2.580392619 ## # … with 50 more rows Types of function  Broadly, there are two main types of function:\nFirst are functions that do something and return an object. These functions take some specified inputs, do some manipulations / operations, then return an object back to you. Examples include mean() (takes mean of a vector), lm() (fits a linear model), or read.csv (loads a table of data).\nSecond are functions that have some external effect on your computer or working environment. These functions do something but don’t return any objects. Examples include things like write.csv() (writes a file to disk), plot() (makes a plot), library() (loads a package).\nFor the first type, you’ll often save the output in a variable and manipulate it further. For example, let’s say we want to calculate the average of the variable height of the samples in the algae data. We can use the function mean:\nmean_height \u0026lt;- mean(algae$height) This code takes the mean of algae$height and stores it in the variable mean_height. We can query the answer by running the variable name:\nmean_height ## [1] 0.4590399 We can also run the function without assigning the output to a variable. The output is still returned, this time to the console - after which it is printed and lost.\nmean(algae$height) ## [1] 0.4590399 By contrast, output from the second type of function does not need to be assigned to a variable. Moreover, the function doesn’t print anything to screen either. E.g.\nwrite.csv(Algae, \u0026quot;data.csv\u0026quot;)  Why use functions?  So why is it so useful to divide your script into many separate, but cooperating, functions? Why not write one big, long script? There are multiple ways in which writing functions can improve your coding.\nCode with functions is easier to read Writing functions is a good way of organising your analytical methods into self contained chunks. Generally, code written in this way is much easier to read.\nConsider some of the functions that you have already used within R. For example, mean().\nThis function is already predefined within the R base package, meaning that you didn’t have to tell the computer how to compute the mean, and because that programming job has already been done, you can simply use the function in your own script. Imagine if every time you needed a mean you had to write the following:\n sum(x) / length(x) Even this line of script uses two functions: the sum function and length function. If these weren’t available, you would need to write out the full method every time you needed a mean.\n (x[1] + x[2] + x[3] + x[4] + x[5]) / 5  Instead, we simply use mean without giving it two thoughts.\nImportantly, it is much easier to tell what mean(x) is doing than the line above. Reading the code you know exactly what is happening. Using the full formula, it would be less obvious what was happening every time you wanted to calculate the mean of a different variable.\nWhich raises an important point: functions should have a clear and informative name, that tells you what the function does.\nFunctions quickly increase the ease of which you can read and interpret the code.\nIt is not obvious what the code sqrt(var(algae$height)/length(algae$height)) what this is doing, whereas it is immediately obvious what the code standard_error(x) is doing.\n Organise your workflow Building on the idea of making code easier to read, functions can help organise your whole workflow and make it easier to follow. Often people have a big long analysis script, which is difficult to interpret. When you use functions, your analysis script might end up looking much simpler:\ndata \u0026lt;- read_csv(\u0026quot;Algal_traits.csv\u0026quot;) stats_species \u0026lt;- fit_model_species(data) stats_spatial \u0026lt;- fit_model_spatial(data) make_plot_species(stats_species) make_plot_spatial(stats_spatial) save_output(stats_species) Here all the functions like fit_model_species are ones that you’ve written yourself.\nWow, how much easier is that to engage with, than some long script with 100’s of lines?\n Reuse code (a.k.a. “Don’t repeat yourself”) Not only is using the mean function more informative (its easier to tell what your line of code is doing) it’s also reusable. Once a function is defined it can be used over and over again, not only within the same script but within other scripts too.\nTo further highlight this, we will go through an example of writing our own function to calculate the standard error of a bunch of variables. R has built in functions for the mean of a vector (mean(x)) and standard deviation (sd(x)) but not the standard error. To calculate standard error,\n\\[SE_\\bar{x}= \\sqrt{\\frac{var}{n}}\\]\nwe need the variance and sample size, n. These are relatively easy to calculate using other base functions in R. var will calculate the variance and length gives the length of the vector and thus the sample size (n).\nLet’s say we first wanted the mean and standard error of height. This is given by\nsqrt(var(algae$height) / length(algae$height)) ## [1] 0.04067788 Imagine now that you wanted to calculate these same statistics on a different variable (e.g., dry weight). When faced with wanting to use this piece of code twice, we may be tempted to just copy-and-paste it to a new place, thus having two copies of the above snippet in our code. However, a much more elegant (and benifitial in the long-term) approach is to make it into a function and call that function twice.\nIf we first define a function for standard error:\nstandard_error \u0026lt;- function (x){ sqrt(var(x) / length(x)) } we simply use standard_error like we would any other function.\nstandard_error(algae$height) ## [1] 0.04067788 standard_error(algae$dryweight) ## [1] 0.02190001  Reduce chance of errors Wrapping code into functions reduces the chance of making inadvertent errors. Such errors may not cause your code to crash, but may cause the results to be wrong. These types of mistakes are the hardest to find and can render our results meaningless.\nThere are at least two ways functions reduce the chance of errors.\nFirst, copy and paste leads to errors. Without a function, you may copy and past code all over the place. For example, if I wanted to calcualte the standard error of a bunch of variables (without using our new standard_error function)\nsqrt(var(algae$height) / length(algae$height)) ## [1] 0.04067788 sqrt(var(algae$dryweight) / length(algae$dryweight)) ## [1] 0.02190001 sqrt(var(algae$length) / length(algae$dryweight)) ## [1] 0.1824489 Did you notice the mistake? I forgot to change the second variable on the third line!!!!! The code will run but give the wrong results. This is less likely if we write:\nstandard_error(algae$height) ## [1] 0.04067788 standard_error(algae$dryweight) ## [1] 0.02190001 standard_error(algae$length) ## [1] 0.1824489 Second, functions limit the scope of variables and enforce cleanup. When calculating something, it’s common to create new variables. As an example, Let’s say we calculated standard error as follows\nvar_x \u0026lt;- var(algae$height) n \u0026lt;- length(algae$height) sqrt( var_x / n ) ## [1] 0.04067788 Note you now have two new objects in your environment: var_x and n:\nvar_x ## [1] 0.0992814 n ## [1] 60 You can get rid of them by running:\nrm(var_x, n) (the function rm() “removes”, i.e. deletes, objects from the environment).\nBut what if you forget? There’s a real danger that later you accidentally reuse the variable n or var_x, thinking they’re something that they’re not. And if they have non-specific names like n the risk of this happening is high.\nIf instead you put the code above into a function, as follows, this danger disappears.\nstandard_error \u0026lt;- function (x){ var_x \u0026lt;- var(algae$height) n \u0026lt;- length(algae$height) sqrt( var_x / n ) } When you run:\nstandard_error(algae$height) ## [1] 0.04067788 The result is returned but variables var_x and n are nowhere to be seen. That’s because they were automatically cleaned up when the function exited.\nAny variables created within a function get automatically cleaned up at the end of the function. So using functions leaves us with a nice clean workspace. Moreover, the environment within the function is much safer than the global env, because we’re less likely to grab random variables from elsewhere.\n Help your brain to solve big problems The best way to solve big complex problems is to divide it into a series of smaller problems. It’s well known that our brains cannot cope with more than about 5-10 bits of information at any one time.\nWriting functions allows us to identify a series of smaller problems and solve these one by one, using all of our cognitive power.\nWhen I look at the function standard_error as defined above, I can think about the operations being performed (addition, division, square root)in isolation from the broader problem I’m solving (studying algae).\nAs a general rule, a good function does one thing well. If that one thing is complicated, it be made up a bunch smaller functions (i.e. steps), each doing one thing well.\n  Writing your own functions  Now let’s look more closely at the mechanics of writing a function.\nThe syntax of a function A function definition has the following form:\nfunction_name \u0026lt;- function (arg1, arg2, ...){ statements # do useful stuff object # return something } function_name: The function’s name. Can be any valid text without a space, but you should avoid using names that are used elsewhere in R. Check to see if your name is already used as a keyword by asking for the help page ?function_name (no 100% guarantee, but a good check). Also, aim for names that describe what the function does. A long name like calculate_standard_error is much better than something short and unintuitive like f.\narg1, arg2, …: The arguments of the function. You can write a function with any number of arguments, with those being any R objects (numeric, strings, characters, data.frames, matrices, other functions).\nfunction body: The code between the {} is the function body and run every time the function is called. This is the code that is doing all the useful stuff and is called the function body.\nreturn value: The last line of code is the object to be returned. Some times you’ll see people write return(object), though it’s enough to write object.\nUsing this format, a function to calculate the standard error of the values in the object x would be:\nstandard_error \u0026lt;- function (x) { sqrt(var(x) / length(x)) } To be able to use the function, you need to run that code into your console. Once defined we can call the function like we would any other function.\nstandard_error(algae$height) ## [1] 0.04067788  Default arguments Let’s take a closer look at the function mean. Typing ?mean into the console brings up the relevant “help” details. Note the structure\nmean(x, trim = 0, na.rm = FALSE, ...) The first argument x is our vector of numbers. To use the function we need to specify something for x, e.g.\nmean(x=algae$height) or just\nmean(algae$height) The first version makes it explicit that the values in algae$height outside of the function are passed to the variable x within the function. The second version does the same thing, but less explictly. It works because R takes the values of height and maps it onto the first unnamed argument in our function call onto the first unnamed argument in the function definition. So the following will also work:\nmean(na.rm=TRUE, x=algae$height) mean(na.rm=TRUE, algae$height) But what are those are other arguments in the function definition: trim and na.rm? These are optional arguments, with default values set as specified. The function needs a value to run but unless you specify it, it will use the default.\nTry running the mean() function on the strength variable.\nmean(algae$strength) ## Warning in mean.default(algae$strength): argument is not numeric or logical: ## returning NA ## [1] NA Notice we get NA, this is because by default the function doesn’t know how to deal with missing values (NA is a missing value) and there is one in that column of the data. How you deal with missing values is highly dependent on what you are trying to calculate (see the help module on importing data), but in this case, we’re happy remove NAs before calculating the mean. This can be achieved by setting the argument for na.rm to TRUE:\nmean(algae$strength, na.rm=TRUE) ## Warning in mean.default(algae$strength, na.rm = TRUE): argument is not numeric ## or logical: returning NA ## [1] NA The functions mean, var, sd, sum all behave similarly. Without specifying the argument, the functions all use their default value, which in this case is na.rm=FALSE. So these give the same result\nmean(algae$strength) ## Warning in mean.default(algae$strength): argument is not numeric or logical: ## returning NA ## [1] NA mean(algae$strength, na.rm=FALSE) ## Warning in mean.default(algae$strength, na.rm = FALSE): argument is not numeric ## or logical: returning NA ## [1] NA But, we can override this if that’s what we want:\nmean(algae$strength, na.rm=TRUE) ## Warning in mean.default(algae$strength, na.rm = TRUE): argument is not numeric ## or logical: returning NA ## [1] NA You’ll notice that many functions have arguments with default values set.\nGoing back to our new function standard_error, let’s add a new argument na.rm so that it behaves like mean and the other function listed above:\nstandard_error \u0026lt;- function (x, na.rm=FALSE){ sqrt(var(x, na.rm = na.rm) / sum(!is.na(x))) } Like the other functions, we’ve set the default behaviour of na.rm to FALSE.\nNow, let’s try out our new function on the strength variable with missing data, alternating na.rm = TRUE and na.rm = FALSE.\nstandard_error(algae$strength) ## Warning in var(x, na.rm = na.rm): NAs introduced by coercion ## [1] NA standard_error(algae$strength, na.rm = FALSE) ## Warning in var(x, na.rm = na.rm): NAs introduced by coercion ## [1] NA standard_error(algae$strength, na.rm = TRUE) ## Warning in var(x, na.rm = na.rm): NAs introduced by coercion ## [1] 0.03870419 Within the function the value for na.rm that is received by the function is passed into the var function. The var function already has a na.rm argument already built within it (see help file ?var), but length does not. We can use the code function sum(!is.na(x) to calculate n. The function is.na will test each value of the vector, x, to see if it is missing. If it not missing (the ! means NOT), then it returns a TRUE for that position, and by counting the values returned as TRUE with sum, we are effectively counting only values that are not missing.\n Functions that extend functions Let’s say you have a script where you continually want to set na.rm=TRUE and get sick of typing this everywhere:\nstandard_error(algae$height, na.rm = TRUE) standard_error(algae$strength, na.rm = TRUE) ... (Besides, we’re also repeating ourselves a lot and so increasing the risk of errors – what if we forget?)\nOne approach here is to define a new function that builds of our previous function but with the desired behaviour. E.g.\nstandard_error_narm \u0026lt;- function (x){ standard_error(x, na.rm=TRUE) } We can now call the new function and the the same result as the above specifying na.rm=TRUE\nstandard_error_narm(algae$strength) ## Warning in var(x, na.rm = na.rm): NAs introduced by coercion ## [1] 0.03870419 While the example with standard_error is perhaps a bit trivial, you can take this approach all over the place. For example, a function that makes a style of plot with defaults set just the way you like them.\n What’s the ... argument for? Notice the argument ... in the definition of the mean function above? What’s that about? The ..., or ellipsis, element in the function definition allows for other arguments to be passed into the function, and passed onto to another function within the function being called, without having to write them all out by name. For example, in the definition of the function standard_error_narm we could instead write\nstandard_error_narm \u0026lt;- function (...){ standard_error(..., na.rm=TRUE) } When you call standard_error_narm defined like this, anything other than na.rm will be passed directly into the next function. This avoids repeating the arguments of one function when defining another.\nA less trivial example is using plot. I could write a function setting changing some of defaults for plot, so that I don’t have to keep repeating these.\nmy_plot \u0026lt;- function (...){ plot(..., pch=16, las=1, log=\u0026quot;xy\u0026quot;) }  Adding comments to your function Before you are finished, there is one last thing to do. It is a good idea to add comments your function, as this will save you from a world of pain when you go back to fix something later on. Function comments should contain, a brief description of the function (one sentence), a list of function arguments with a description of each (including data type) and a description of the return value. Function comments should be written immediately above or below the function definition line.\nstandard_error \u0026lt;- function (x, na.rm){ # Computes the sample standard error # # Args: # x: Vector whose standard error is to be calculated. x must have length greater than one. # y: na.rm can either be T or F. T removes missing values before calculating standard error. # # Return: # The standard error of x sqrt(var(x, na.rm = na.rm) / sum(!is.na(x))) } Another common way to annotate functions is using the roxygen2 syntax.\n Storing and using functions Once you get into the habit of writing functions it’s a good idea to keep them in a separate file containing your functions together. Why? Because otherwise you have these big clunky files clogging up your script. If you’ve solved the problem of how to do something, why not stuff it away somewhere you can go, but only if needed.\nTo get get your functions out of the way, we recommend keeping all the functions for each project together in a folder called R within your project directory. (For more on project set up see our post on project management.)\nTo make these functions accessible within your workflow, you then use the function source to read the function files into memory, e.g.\nsource(\u0026quot;R/stats.R\u0026quot;) Often, you may have a series of files\nsource(\u0026quot;R/data_cleaning.R\u0026quot;) source(\u0026quot;R/stats.R\u0026quot;) source(\u0026quot;R/plots.R\u0026quot;) It’s a matter of preference whether you use a single or multiple files.\n Writing functions to work with pipes %\u0026gt;% For many of us, pipes have become an essential part of our workflow. (If this is foreign to you, see our post using pipes under data manipulation).\nImportantly, you can write functions that work with the pipe operator. All you need to do is setup your so that the first argument is the object being piped into the function. In fact, our standard_error already works with pipes, assuming you are passing in x:\nalgae$height %\u0026gt;% standard_error() ## [1] 0.04067788  Returning multiple arguments The examples above all return a single item. What if I want to return multiple items from a function? The answer is to return a list object. Lists are helpful because you can bundle together many different items.\nFor example, we could write a function that returns several statistics of a variable:\nsummary_stats \u0026lt;- function(x, na.rm = TRUE) { list(mean = mean(x, na.rm=na.rm), var = var(x, na.rm=na.rm), n = sum(!is.na(x)) ) } If we run this function, we receive an object that has named elements:\nheight_stats \u0026lt;- summary_stats(algae$height) names(height_stats) ## [1] \u0026quot;mean\u0026quot; \u0026quot;var\u0026quot; \u0026quot;n\u0026quot; height_stats$mean ## [1] 0.4590399 height_stats$var ## [1] 0.0992814 height_stats$n ## [1] 60 In fact many functions do this, e.g. lm() (for fitting a linear model). Fitting a model we can check it’s a list, then ask for a name of the returned elements, and start calling them by name:\nfit \u0026lt;- lm(algae$height ~ algae$dryweight) is.list(fit) ## [1] TRUE names(fit) ## [1] \u0026quot;coefficients\u0026quot; \u0026quot;residuals\u0026quot; \u0026quot;effects\u0026quot; \u0026quot;rank\u0026quot; ## [5] \u0026quot;fitted.values\u0026quot; \u0026quot;assign\u0026quot; \u0026quot;qr\u0026quot; \u0026quot;df.residual\u0026quot; ## [9] \u0026quot;xlevels\u0026quot; \u0026quot;call\u0026quot; \u0026quot;terms\u0026quot; \u0026quot;model\u0026quot; fit$coefficients ## (Intercept) algae$dryweight ## 0.4054402 0.1276447   What makes a good function Finally, let’s recap a few pointers on what makes a good function.\nIt’s short If you've written a function whose body is 2,996 lines of code, you're doing it wrong.\n\u0026mdash; M Butcher (@technosophos) April 11, 2013  --\nIdeally each function does one thing well. Often this means lots of short functions. Short functions are extremely useful. Even if the code in the function body is more complex, ideally it still does one thing well.\nIt does one thing well The reason for writing a function is not to reuse its code, but to name the operation it performs.\n\u0026mdash; Tim Ottinger (@tottinge) January 22, 2013  -- It has an intuitive name \"The name of a variable, function, or class, should answer all the big questions.\" - Uncle Bob Martin, Clean Code\n\u0026mdash; Gustavo Rod. Baldera (@gbaldera) April 24, 2013  --\n Further help You can find more help on functions at\n DataCamp’s tutorial on functions Hadley Wickam’s information on functions for intermediate and advanced users. The official R intro material on writing your own functions  Author: Original by Keryn F Bain; revised and substantially expanded by Daniel S Falster\n\nLast updated:\n## [1] \u0026quot;Wed Jan 19 15:09:45 2022\u0026quot;  "
},
{
	"uri": "/statistics/linear-models/anova/",
	"title": "ANOVA",
	"tags": [],
	"description": "",
	"content": "  Analysis of variance (ANOVA) is one of the most frequently used techniques in the biological and environmental sciences. ANOVA is used to contrast a continuous dependent variable y across levels of one or more categorical independent variables x. The independent variables are termed the factor or treatment, and the various categories within that treatment are termed the levels. In this module, we will start with the simplest design - those with a single factor.\nWhere an independent samples t-test would be used for comparison of group means across two levels, ANOVA is used for the comparison of \u0026gt;2 group means, or when there are more than two or more predictor variables (see ANOVA: factorial). The logic of this test is essentially the same as the t-test - it compares variation between groups to variation within groups to determine whether the observed differences are due to chance or not.\n"
},
{
	"uri": "/getting-started-with-r/project-managment/",
	"title": "Basic Project Management",
	"tags": [],
	"description": "",
	"content": "  Having your data files, R scripts and outputs organised is very helpful for keeping track of what you are working on and for sharing data or scripts with colleagues or supervisors. Try and avoid a folder on your computer that is a big mix of spreadsheets, images, word processing documents etc. How you organise your files is your choice, but a little bit of planning and project organization at the beginning will pay lots of dividends down the road. Here are our suggestions for keeping your projects neatly organised.\nSetting up an organised project folder \nCreate a folder on your computer for each project. This could be a course you are currently doing, a chapter of your thesis or a research project of any kind. Within that folder, include the following things:\n A data folder (including meta-data) An outputs folder (with subfolders “Figures” and “Tables” and possibly “Supplementary Material”) An R script that will run the data manipulation, analyses and create figures required for the project (try to keep this R script short and readable) A folder for R functions (if used) usually called “R” A folder for writing and references called “Manuscripts”  The data folder should hold the raw data (usually entered in a spreadsheet program). After you finish entering your data, you should aim to keep these data untouched; all the things you want to do with the data, such as data cleaning and subsetting, summarising data into table, running statistical analyses or creating figures, can be done via R scripts. This keeps a record of everything you do. Think of this script(s) as the lab notebook for a data scientist. Intermediate outputs are good–separate these from the raw data and save them in the outputs folder.\nOne goal of this project organization is that your data processing and analysis is entirely reproducible, and as such both the data and exact methods can be shared with colleagues and supervisors, who can then repeat and hopefully build on your analyses. Also, although you might know all the files and steps at the moment, think of yourself in a year once you’ve moved on to other jobs or projects; try to be nice to your future self and keep good notes. In contrast, if you used a point–and–click or spreadsheet program to do important steps in your analysis, you’ll need to remember all the steps taken to recreate the analyses or figures. Most analyses at some point get too complicated for this to be tractable.\n Using R Studio’s project files \nAn easy way to access all these files is to use a project file. In R Studio, you can create a new project file with File, New Project. You will then be asked if you want a new directory or to associate it with an existing directory.\nChoose this second option to have a project file associated with the folder that you created above.\nOnce created, you can open your project by directly clicking on that file or from File, Open if you have R Studio open already. Once open, you will see your directory structure in the files panel on the bottom right of R Studio and all your scripts and data are easily accessible.\nA big benefit of using a project file is that when you import data, you do not need to specify the working directory with setwd. R Studio will look within the folder that contains the project file. When using read.csv(\"\"), press tab repeatedly when you are within the \"\" to choose the local folders and files:\nread.csv(\u0026quot;/Data/Survey_data.csv\u0026quot;) The data file is found with a relative file path, rather than the alternatives of a full path in the read.csv function or setting the working directory then using read.csv\nread.csv(\u0026quot;C:/Work/Data/Survey_data.csv\u0026quot;) setwd(\u0026quot;C:/Work/Data\u0026quot;) read.csv(file=\u0026quot;Survey_data.csv\u0026quot;) Similarly, when you output a file (e.g., figures or tables), you can store than in your outputs folder (away from the raw data)\nwrite.csv(\u0026quot;/Outputs/Survey_summary_table.csv\u0026quot;) You can now simply copy your whole project folder to any other computer (desktop to laptop, student to supervisor etc.) and your code will always work without having to change the working directory for every machine.\nIf you have mutiple R project files, you can easily swap between them by clicking on the project name on the top right of R Studio.  Further help \nR Studio’s help with using projects Our introduction to version control for keeping track of revisions to project files. Author: Alistair Poore \u0026amp; Will Cornwell Last updated:\n## [1] \u0026quot;Tue Jan 18 18:23:37 2022\u0026quot;  "
},
{
	"uri": "/graphics/multivariate-vis/cluster-analysis/",
	"title": "Cluster Analysis",
	"tags": [],
	"description": "",
	"content": "  Cluster analysis is a method of classification, aimed at grouping objects based on the similarity of their attributes. It is commonly used to group a series of samples based on multiple variables that have been measured from each sample. The procedure produces a tree-like diagram (a dendrogram) that illustrates the relationships between all the samples based on a defined measure of similarity.\nThere are many methods available for clustering (agglomerative, divisive, non hierarchical etc.). Here are some instructions for one of the more commonly used methods, agglomerative hierarchical clustering. This procedure involves a series of steps:\n calculate a matrix that holds all pair-wise similarities among all objects\n join together the pair of objects that are most similar\n recalculate the similarity matrix for that cluster vs all remaining objects\n repeat last two steps until all objects are joined\n  Running the analysis \nIn this example, we will use cluster analysis to visualise differences in the composition of metal contaminants in the seaweeds of Sydney Harbour (data from (Roberts et al. 2008).). Download the data set, Harbour_metals.csv, and load into R.\nHarbour_metals \u0026lt;- read.csv(file=\u0026quot;Harbour_metals.csv\u0026quot;, header=TRUE) These data have the concentrations of seven metals measured from 60 samples, half from the seaweed Padina crassa and half from the Sargassum linearifolium\nThe first two columns are categorical variables that group samples by site and seaweed species. The third column has unique labels for each replicate sample and the remaining columns are the metal concentrations.\nThe cluster analysis runs on the response variables only so we need to make a data frame with just the metal concentrations (columns 4-8).\nHarbour_metals2 \u0026lt;- Harbour_metals[,4:8] To help interpret the graph, we can add the sample labels as row names in this data frame\nrownames(Harbour_metals2) \u0026lt;- Harbour_metals$Rep To perform the cluster analysis, we need to make a matrix that quantifies the similarity between each pair of samples. Here we will use the Euclidean distance as our similarity coefficient, but there are others to choose from (see below).\nH_metals.sim \u0026lt;- dist(Harbour_metals2, method = \u0026quot;euclidean\u0026quot;) We then use hclust function with an argument that specifies the linkage method (here we will use the single linkage method).\nH_metals.cluster \u0026lt;- hclust(H_metals.sim, method = \u0026quot;single\u0026quot;) Finally, plot the object that was created by the hclust function.\nplot(H_metals.cluster) We can make this a bit neater with all the samples lined up along the bottom by converting it to a dendrogram object (the as.dendrogram function) and plotting that (although this default plot is still a bit ugly and would need work with labels and axes before being ready for publication).\nplot(as.dendrogram(H_metals.cluster),ylab = \u0026quot;Euclidean distance\u0026quot;)  Interpreting the results \nA dendrogram has a branch for each sample joined at nodes that relate to the value of the similarity coefficient that joined the two objects. Interpretation of all the relationships comes from examination of the branching structure (which objects join most closely with each other) and from the similarities at which they join. Objects that join together close the tips of the branches are more similar to each other than those that join further toward the base of the tree (note that the default dendogram in R is like an upside down tree with the branches at the bottom and trunk at the top).\nStrong evidence for distinct groups would be evident if there were clusters where the samples within a cluster are much more similar to each other than samples in other clusters.  Assumptions to check \nBefore running a cluster analysis to create a dendrogram, you need to consider:\nWhat measure of similarity to use. Dendograms can be created from any similarity matrix. There are many distance measures that can be used to describe the similarity between samples. The dist fuction in R has \"euclidean\", \"maximum\", \"manhattan\", \"canberra\", \"binary\" or \"minkowski\" (specified in the method argument of dist). Other measures are available in other packages (e.g., the Bray-Curtis measure which is recommended for analyses of species composition data is available in the package vegan).\nWhether the data need transforming or standardising. If the variables are measured on very different scales, or if there are outliers, then the structure of the dendrogram will be strongly influenced by the values of the largest values in the data set. Variables can be transformed or standardised to lessen the influence of large values (i.e., treat all variables on a more equal footing).\nWhat method will be used to create the dendrogram. The structure of dendrograms can also be sensitive to algorithm used to construct the tree (the linkage method). In the previous example, you used the single linkage method. The hclust function in R has several available: \"ward\", \"single\", \"complete\", \"average\", \"mcquitty\", \"median\" and \"centroid\".  Communicating the results \nWritten. The interpretation of the dendrogram would be described in the text of a Results section (i.e, were there any obvious clusters of samples? were there any samples that were very different from the rest?). There are no numerical results to report.\nVisual. Results from cluster analyses are communicated visually with the dendrogram. It is important to label the axis to show what measure of similarity was used in the analysis.\nIf there are pre-determined groups of samples (e.g., samples grouped by species in the example above) samples are usually labelled or provided with colour-coded symbols to allow patterns in the dendrogram to be more easily seen. With large data sets individual labels for each sample (as we did here) make for very plots.\nWith many samples in your dendrogram it is often necessary to label them in some way (e.g., by colour) to help see patterns. The package dendextend allows you to do this. Here is some code to produce the same dendrogram with the samples colour coded by location.\nlibrary(dendextend) dend \u0026lt;- as.dendrogram(H_metals.cluster) sample_colours \u0026lt;- as.numeric(Harbour_metals$Location) sample_colours \u0026lt;- sample_colours[order.dendrogram(dend)] labels_colors(dend) \u0026lt;- sample_colours plot(dend,ylab = \u0026quot;Euclidean distance\u0026quot;)  Further help \nYou can access R help for the main functions used here by typing ?hclust, ?dist or ?as.dendrogram. There are many R packages associated with the many different types of cluster analysis. See a long list of possibly useful packages here.\nQuinn, GP and MJ Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Ch. 18. Multidimensional scaling and cluster analysis. McKillup, S (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Ch. 22. Introductory concepts of multivariate analysis. Visualizing dendrograms in R Author: Alistair Poore Last updated:\n## [1] \u0026quot;Thu Jan 20 14:37:59 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/",
	"title": "Data Manipulation",
	"tags": [],
	"description": "",
	"content": "  Having skills in organising and summarising data is crucial for students and researchers in all sciences. On these pages, we give some guidance for manipulating data in ways that can save a lot of time when it comes to analysing data and making effective figures.\nData manipulation using the packages dplyr, tidyr and reshape2.\n Making new variables Subsetting data - selecting rows and columns\n Summarising data - extracting summary statistics\n Combining data sets - joining entire data sets, or parts by matching rows Reshaping data between wide and long formats\n  ###Further help The British Ecological Society’s Guide to Data Management in Ecology and Evolution Author: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 15:51:46 2022\u0026quot; "
},
{
	"uri": "/statistics/catagorical/fishers-exact/",
	"title": "Fisher&#39;s Exact Test",
	"tags": [],
	"description": "",
	"content": "  Some people notice a distinctive smell from their urine after eating asparagus, while others never notice the smell. These differences could arise from variation among people in the chemical profile of the urine (i.e., how compounds from asparagus are metabolised), or from variation in the ability of different people to detect the smell.\nA paper (Pelchat et al. 2010 Chemical Senses) reviewed these studies and presented the following data that described variation among four study populations:\nIsrael (Lison et al. 1980), 328, 0 China (Hoffenberg 1983), 96, 2 USA (Sugarman and Neelon 1985), 10, 5 USA (Lison et al. 1980), 11, 10\nasparagus = matrix(c(328,96,10,11,0,2,5,10), nrow=4, dimnames = list(c(\u0026quot;Israel\u0026quot;, \u0026quot;China\u0026quot;, \u0026quot;USA.1\u0026quot;, \u0026quot;USA.2\u0026quot;), c(\u0026quot;Can detect odour\u0026quot;,\u0026quot;Cannot detect odour\u0026quot;))) asparagus ## Can detect odour Cannot detect odour ## Israel 328 0 ## China 96 2 ## USA.1 10 5 ## USA.2 11 10 Q1 What numbers of people would be expected to smell the odour in each population if all study populations had the same proportion of people able to detect the odour?\nchisq.test(asparagus, correct=F)$expected ## Warning in chisq.test(asparagus, correct = F): Chi-squared approximation may be ## incorrect ## Can detect odour Cannot detect odour ## Israel 315.93074 12.0692641 ## China 94.39394 3.6060606 ## USA.1 14.44805 0.5519481 ## USA.2 20.22727 0.7727273 Q2 What statistical test could you use to detect differences among populations in the perception of the odour? Ensure you check that the assumptions of the test are met.\nQ3 Run your chosen test. What is your P value?\nfisher.test(asparagus) ## ## Fisher\u0026#39;s Exact Test for Count Data ## ## data: asparagus ## p-value \u0026lt; 2.2e-16 ## alternative hypothesis: two.sided You are a behavioural ecologist studying the diet of common ringtail possums (Pseudocheirus peregrinus) at two sites (sites A and B) dominated by two species of Eucalyptus, (E. ovata and E. sideroxylon).\nYou notice that possums at site A tend to eat E. ovata and that at location B they mostly eat E. sideroxylon. To test whether the populations at each site differ in the feeding preferences, you attach radio collars to seven possums at location A and eight possums at location B. You track each possum and note the species of the first tree that you observe it eating leaves from.\nAt location A you see six possums eat E. ovata and one (1) eat E. sideroxylon. At location B, none eat E. ovata and you see all eight eat E. sideroxylon.\nQ1 What is the exact probability of observing this or a more extreme pattern by chance alone?\nQ2 Is there evidence to suggest that the possums at site A and B differ in their use of food trees?\nAuthor: Alistair Poore Last updated:\n"
},
{
	"uri": "/statistics/glms/",
	"title": "Generalised Linear Models (GLMs)",
	"tags": [],
	"description": "",
	"content": "  Generalised linear models (GLMs) are used when the distribution of data do not conform to the assumptions of linear models, specifically the assumptions of normally distributed residuals and no relationship between the variance and the mean (e.g., presence/absence, count or highly skewed data).\n Generalised linear models 1: Introduction and binomial data\n Generalised linear models 2 Interpreting coefficients in glms  "
},
{
	"uri": "/statistics/mixed-models/mixed-model-3/",
	"title": "Generalised Mixed Models",
	"tags": [],
	"description": "",
	"content": "  Generalised linear mixed models\nYou will need to read Mixed models 1 and Mixed models 2 as an introduction to mixed models for continuous data, as well as the help pages on Generalised linear models as an introduction to modelling discrete data.\nThis page will combine the two to allow you to model discrete data (e.g., presence/absence) with random effects using generalised linear mixed models (GLMMs). Properties of mixed models Assumptions. The assumptions of generalised linear mixed models are a combination of the assumptions of GLMs and mixed models.\nThe observed \\(y\\) are independent, conditional on some predictors \\(x\\)\n The response \\(y\\) come from a known distribution from the exponential family, with a known mean variance relationship\n There is a straight line relationship between some known function (link) of the mean of \\(y\\) and the predictors \\(x\\) and random effects \\(z\\)\n Random effects \\(z\\) are independent of \\(y\\).\n Random effects \\(z\\) are normally distributed\n  ###Running the analysis We will analyse the same data set as the first two mixed model tutorials. This data set aimed to test the effect of water pollution on the abundance of some subtidal marine invertebrates by comparing samples from modified and pristine estuaries. In the first two tutorials, we analysed the total count of invertebrates, which we assumed to be continuous as the total counts were large. Here, we will analyse the counts and presence/absences of individual species, which require generalised linear mixed models.\nWe will use the package lme4 for all our mixed effect modelling. It allows us to model both continuous and discrete data with one or more random effects. There are however some limitations for discrete data.\nWhat lme4 can do * model binary data (e.g., presence/absence)\n* model counts with Poisson distribution\nWhat lme4 can’t do * model overdispersed counts (unfortunately these are really common in ecology)\n* provide good residual plots (we need these for assumption checking)\nFirst, load the package:\nlibrary(lme4) Download the sample data set, Estuaries.csv, and load into R.\nEstuaries \u0026lt;- read.csv(\u0026quot;Estuaries.csv\u0026quot;, header = T) In this example, we have a fixed effect (Modification; modified vs pristine) and a random effect (Estuary). To test whether there is an effect of modification on individual species counts and presence/absences, we need to use generalised linear mixed models with the with the glmer function.\nConsider the counts of hydroids (the variable Hydroid).\n## [1] 0 0 0 0 1 1 0 0 7 5 2 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 1 1 2 1 2 2 0 0 0 0 0 0 ## [39] 0 0 0 0 1 0 0 0 0 3 1 0 1 2 2 2 Looking at the data, you can see the counts are small, with many zeros, so we don’t want to treat these as continuous. We will model them as counts with a Poisson distribution, and also as presence/absence data.\nTo model presence/absence, we first create a variable HydroidPres which is 1 (TRUE) when Hydroids are present and 0 (FALSE) otherwise.\nEstuaries$HydroidPres \u0026lt;- Estuaries$Hydroid \u0026gt; 0 Binary data\nTo fit a model for the presence or absence of hydroids, we would use glmer with family=binomial.\nfit.bin \u0026lt;- glmer(HydroidPres ~ Modification + (1|Estuary), family=binomial, data=Estuaries) Checking assumptions As usual, we can examine residual plots to check assumptions.\npar(mfrow=c(1,2)) plot(residuals(fit.bin)~fitted(fit.bin),main=\u0026quot;residuals v.s. Fitted\u0026quot;) qqnorm(residuals(fit.bin)) Unfortunately, for binary data residual plots are quite difficult to interpret. In the residual v.s. fitted plot all the 0’s are in a line (lower left) and all the ones are in a line (upper right) due to the discreteness of the data. This stops us from being able to look for patterns. We have the same problem with the normal quantile plot.\nBriefly looking at our assumptions, Assumptions 1 and 4 we can’t check, but will be true if we sample randomly. Assumption 2 and 3 we should check with the residual plots, but given its failings we are unsure. Assumption 5 is hard to check in general and not crucial.\nHypothesis test for fixed effects\nFor generalised linear mixed models (GLMMs), we need to use the parametric bootstrap even for fixed effects inference. This is because the p-values from the anova function are quite approximate for GLMMs even for fixed effects. Sometimes the glmer function will give warnings or errors, so I’ve added a tryCatch to this code to handle that.\nnBoot \u0026lt;- 1000 lrStat \u0026lt;- rep(NA,nBoot) ft.null \u0026lt;- glmer(HydroidPres ~ 1 + (1|Estuary) ,family=binomial, data=Estuaries) #null model ft.alt \u0026lt;- glmer(HydroidPres ~ Modification + (1|Estuary) ,family=binomial, data=Estuaries) #alternate model lrObs \u0026lt;- 2*logLik(ft.alt) - 2*logLik(ft.null) #observed test stat for(iBoot in 1:nBoot) { Estuaries$HydroidPresSim \u0026lt;- unlist(simulate(ft.null)) #resampled data tryCatch({#sometimes the glmer code doesn\u0026#39;t converge bNull \u0026lt;- glmer(HydroidPresSim ~ 1 + (1|Estuary) ,family=binomial, data=Estuaries)#null model bAlt \u0026lt;- glmer(HydroidPresSim ~ Modification + (1|Estuary) ,family=binomial, data=Estuaries)#alternate model lrStat[iBoot] \u0026lt;- 2*logLik(bAlt) - 2*logLik(bNull) #resampled test stat },warning=function(war) {lrStat[iBoot]=NA},error=function(err){lrStat[iBoot]=NA}) #if code doesn\u0026#39;t converge skip sim } mean(lrStat\u0026gt;lrObs,na.rm=T) #P-value for test of Estuary effect ## [1] 0.03089245 We have evidence of an effect of modification on the presence of hydroids.\nCount data\nlme4 can model count data that has a Poisson distribution. If the data do not fit the Poisson mean/variance relationship, then things become much more complicated, and we won’t cover that situation here.\nTo model the counts of hydroids, we would use use glmer with family=poisson.\nfit.pois \u0026lt;- glmer(Hydroid ~ Modification + (1|Estuary) ,family=poisson, data=Estuaries) To check the assumptions:\npar(mfrow=c(1,2)) plot(residuals(fit.pois)~fitted(fit.pois),main=\u0026quot;Residuals vs. Fitted\u0026quot;) qqnorm(residuals(fit.pois)) Once again, the residual plots aren’t that useful, but we at least get an idea about whether the variance assumption is reasonable. There is no obvious fan shape, so a Poisson model seems okay.\nHypothesis test for fixed effects\nAgain, we can use parametric bootstrapping to test for an effect of Modification.\nnBoot \u0026lt;- 1000 lrStat \u0026lt;- rep(NA,nBoot) ft.null \u0026lt;- glmer(Hydroid ~ 1 + (1|Estuary) ,family=poisson, data=Estuaries) #null model ft.alt \u0026lt;- glmer(Hydroid ~ Modification + (1|Estuary) ,family=poisson, data=Estuaries) #alternate model lrObs \u0026lt;- 2*logLik(ft.alt) - 2*logLik(ft.null) #observed test stat for(iBoot in 1:nBoot) { Estuaries$HydroidSim \u0026lt;- unlist(simulate(ft.null)) #resampled data tryCatch({ bNull \u0026lt;- glmer(HydroidSim ~ 1 + (1|Estuary) ,family=poisson, data=Estuaries)#null model bAlt \u0026lt;- glmer(HydroidSim ~ Modification + (1|Estuary) ,family=poisson, data=Estuaries) #alternate model lrStat[iBoot] \u0026lt;- 2*logLik(bAlt) - 2*logLik(bNull) #resampled test stat },warning=function(war) {lrStat[iBoot]=NA},error=function(err){lrStat[iBoot]=NA}) #if code doesn\u0026#39;t converge skip sim# lrStat[iBoot] } ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular mean(lrStat\u0026gt;lrObs,na.rm=TRUE) #P-value for test of Estuary effect ## [1] 0.04202719 We have evidence of an effect of modification on hydroid abundance.\nA non Poisson example\nOften, count data will not fit a Poisson distribution. Look at what happens if you try and model the counts of the bryozoan, Schizoporella errata, from that same data set.\nfit.pois2 \u0026lt;- glmer(Schizoporella.errata ~ Modification + (1|Estuary), family=poisson, data=Estuaries) par(mfrow=c(1,2)) plot(residuals(fit.pois)~fitted(fit.pois),main=\u0026quot;residuals vs. Fitted\u0026quot;) qqnorm(residuals(fit.pois)) Here we can see a distinct fan shape in the residual vs. fitted plot. Unfortunately lme4 can’t handle this situation (overdispersion), and there is no easy way to model these data. If this happens in your data try the glmmADMB package.\nHypothesis test for random effects\nAs before you could run hypothesis tests on the random effects using a parametric bootstrap. See Mixed models 1 and Mixed models 2 for code that you could modify for this situation. ###Communicating results Written. Results of generalised linear mixed models are communicated in a similar way to results for linear models. In your results section you should mention that you are using mixed models with R package lme4, and list your random and fixed effects. You should also mention how you carried out inference, i.e. likelihood ratio tests (using the anova) or parametric bootstrap. In the results section for one predictor, it suffices to write one line, e.g. “There is strong evidence (p\u0026lt;0.001) of negative effect of modification on total abundance”. For multiple predictors it’s best to display the results in a table.\nVisual. The best way to visually communicate results will depend on your question, for a simple mixed model with one random effect, a plot of the raw data with the model means superimposed is one possibility.\nlibrary(Hmisc) fit.pois \u0026lt;- glmer(Hydroid ~ Modification + (1|Estuary) ,family=poisson, data=Estuaries) means \u0026lt;- fitted(fit.pois) #this will give the estimate at each data point ModEst \u0026lt;- unique(Estuaries[c(\u0026quot;Estuary\u0026quot;, \u0026quot;Modification\u0026quot;)])#find which Estuaries are modified cols \u0026lt;- as.numeric(ModEst[order(ModEst[,1]),2])+3 #Assign colour by modification ## Warning: NAs introduced by coercion boxplot(Hydroid~ Estuary,data=Estuaries,col=cols,xlab=\u0026quot;Estuary\u0026quot;,ylab=\u0026quot;Count of hydroids\u0026quot;) legend(\u0026quot;topleft\u0026quot;, inset=.02, c(\u0026quot;Modified\u0026quot;,\u0026quot;Pristine\u0026quot;), fill=unique(cols), horiz=TRUE, cex=0.8) Est.means \u0026lt;- summarize(means,Estuaries$Estuary, mean)$means #extract means by Estuary stripchart(Est.means~ sort(unique(Estuary)),data=Estuaries,pch=18,col=\u0026quot;red\u0026quot;,vertical = TRUE,add=TRUE) #plot means by estuary Further help \nYou can type ?glmer into R for help with this function.\nDraft book chapter from the authors of lme4.\nFaraway, JJ (2005) Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models. CRC Press. Zuur, A, EN Ieno and GM Smith (2007) Analysing ecological data. Springer Science \u0026amp; Business Media. \nAuthor: Gordana Popovic Last updated:\n## [1] \u0026quot;Mon Jan 24 12:19:07 2022\u0026quot;  "
},
{
	"uri": "/statistics/glms/interpret-glm-coeffs/",
	"title": "Interpreting GLMs",
	"tags": [],
	"description": "",
	"content": "  In linear models, the interpretation of model parameters is linear. For example, if a you were modelling plant height against altitude and your coefficient for altitude was -0.9, then plant height will decrease by 1.09 for every increase in altitude of 1 unit.\nFor generalised linear models, the interpretation is not this straightforward. Here, I will explain how to interpret the co-efficients in generalised linear models (glms). First you will want to read our pages on glms for binary and count data page on interpreting coefficients in linear models. Poisson and negative binomial GLMs \nIn Poisson and negative binomial glms, we use a log link. The actual model we fit with one covariate \\(x\\) looks like this\n\\[ Y \\sim \\text{Poisson} (\\lambda) \\] \\[ log(\\lambda) = \\beta_0 + \\beta_1 x \\]\nhere \\(\\lambda\\) is the mean of Y. So if we have an initial value of the covariate \\(x_0\\), then the predicted value of the mean \\(\\lambda_0\\) is given by\n\\[ log(\\lambda_0) = \\beta_0 + \\beta_1 x_0 \\]\nIf we now increase the covariate by 1, we get a new mean \\(\\lambda_1\\),\n\\[ log(\\lambda_1) = \\beta_0 + \\beta_1 (x_0 +1) = \\beta_0 + \\beta_1 x_0 +\\beta_1 = log(\\lambda_0) + \\beta_1\\]\nSo the log of the mean of Y increases by \\(\\beta_1\\) when we increase x by 1. But we are not really interested in how the log mean changes, we would like to know on average how Y changes. If we take the exponential of both sides\n\\[ \\lambda_1 = \\lambda_0 exp(\\beta_1)\\]\nSo the mean of Y is multiplied by \\(exp( \\beta_1 )\\) when we increase \\(x\\) by 1 unit.\nN \u0026lt;- 120 x \u0026lt;- rnorm(N) mu \u0026lt;- exp(1+0.2*x) Y \u0026lt;- rpois(N, lambda = mu) glm1 \u0026lt;- glm(Y~x, family = poisson) glm1$coefficients ## (Intercept) x ## 1.0429054 0.1601518 exp(glm1$coefficients[2]) ## x ## 1.173689 So here increasing \\(x\\) by 1 unit multiplies the mean value of Y by \\(exp( \\beta_1 ) = 1.25\\). The same thing is true for negative binomial glms as they have the same link function.  Binomial GLMs \n#### Logistic regression Things become much more complicated in binomial glms. The model here is actually a model of log odds, so we need to start with an explanation of those. The odds of an event are the probability success divided by the probability of failure. So if the probability of success is \\(p\\) then the odds are:\n\\[\\text{Odds} = \\frac{p}{1-p} \\]\nAs p increases, so do the odds. The equation for a logistic regression looks like this:\n\\[ Y \\sim \\text{binomial} (p) \\] \\[ log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 x \\]\nSkipping some maths that is very similar to the above, we can obtain an interpretation for the coefficient of \\(x\\) in the model in terms of the odds. When we increase \\(x\\) by one unit the odds are multiplied by \\(exp( \\beta_1 )\\). Odds are not the most intuitive thing to interpret, but they do increase when p increases, so that if your coefficient \\(\\beta_1\\) is positive, increasing \\(x\\) will increase your probability.\nbY \u0026lt;- Y\u0026gt;0 #turning counts into presence absence bin1 \u0026lt;- glm(bY~x,family = binomial) summary(bin1) ## ## Call: ## glm(formula = bY ~ x, family = binomial) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.6351 0.2406 0.3163 0.3775 0.5939 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) 2.9857 0.4626 6.454 1.09e-10 *** ## x 0.5731 0.3830 1.496 0.135 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 53.366 on 119 degrees of freedom ## Residual deviance: 50.960 on 118 degrees of freedom ## AIC: 54.96 ## ## Number of Fisher Scoring iterations: 6 So when we increase \\(x\\) by one unit, the odds of Y are multiplied by \\(exp( \\beta_1 ) = 2.11\\) Complementary log-log \nPossibly a more intuitive model is a binomial regression with a complementary log-log link function. This link function is based on the assumption that you have some counts, which are Poisson distributed, but you’ve decided to turn them into presence/absence.\n\\[ Y \\sim \\text{binomial} (p) \\] \\[ log(-log(1-p)) = \\beta_0 + \\beta_1 x \\]\nIn that case you can interpret your coefficients in a similar way as the Poisson regression. When you increase \\(x\\) by 1, the mean of your underlying count (which you have turned into presence/absence) is multiplied by \\(exp( \\beta_1 )\\).\nlibrary(mvabund) bin2 \u0026lt;- manyglm(bY~x, family = binomial(link = \u0026quot;cloglog\u0026quot;)) coef(bin2) ## bY ## (Intercept) 1.1046153 ## x 0.2089743 The interpretation is now the same as in the Poisson case, when we increase \\(x\\) by 1, the mean of the underlying count is multiplied by \\(exp( \\beta_1 )\\).  Log binomial model \nIt is possible to use a log link function with the binomial distribution family = binomial(link = log). In this case you can interpret the coefficients as multiplying the probabilities by \\(exp( \\beta_1 )\\), however these models can give you predicted probabilities greater than 1, and often don’t converge (don’t give an answer).   Offsets \nSometimes we know the effect of a particular variable (call it \\(z\\)) on the response is proportional, so that when we double \\(z\\) we expect the response to double on average. The most common time you see this is with sampling intensity.\nIf you sample soil and count critters, all other things being equal, you would expect twice the critters in twice the amount of soil. If you have a variable like this it is tempting to divide your response (count) by the amount of soil to standardise the data. Unfortunately this will take counts, which we know how to model with glms, and turn them into something we do not know how to model. Fortunately this situation is easily dealt with using offsets. First, let’s simulate some data for amount of soil, depth (our predictor variable) and count data (with a poisson distribution) where the couunts depend on how much soil was sampled.\nsoil \u0026lt;- exp(rbeta(N, shape1 = 8, shape2 = 1)) depth \u0026lt;- rnorm(N) mu \u0026lt;- soil*exp(0.5+0.5*depth) count \u0026lt;- rpois(N, lambda = mu) Now, we can model counts with depth as our predictor and soil quantity as an offset.\noff_mod \u0026lt;- glm(Y~depth+offset(log(soil)), family = poisson) summary(off_mod) ## ## Call: ## glm(formula = Y ~ depth + offset(log(soil)), family = poisson) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4684 -0.6413 -0.0673 0.5424 2.9223 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) 0.14922 0.05400 2.764 0.00572 ** ## depth -0.06784 0.05052 -1.343 0.17934 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 126.52 on 119 degrees of freedom ## Residual deviance: 124.73 on 118 degrees of freedom ## AIC: 455.06 ## ## Number of Fisher Scoring iterations: 5 If we ignored the soil amount, we could have misleading conclusions. If the soil amount is correlated with another variable in your model, then leaving out the offset will affect the coefficient of that variable, as in the discussion of conditional/marginal interpretations here. The offset will also often account for a lot of the variation in the response, so including it will give you a better model overall. What if you’re not sure if the relationship is exactly proportional? In that case just include the variable in your model as a coefficient, and the model will decide the best relationship between it and your response.\ncoef_mod \u0026lt;- glm(Y~depth+log(soil), family = poisson) summary(coef_mod) ## ## Call: ## glm(formula = Y ~ depth + log(soil), family = poisson) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.44436 -0.59978 -0.00574 0.51569 2.84527 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) 0.85732 0.58501 1.465 0.143 ## depth -0.07309 0.05086 -1.437 0.151 ## log(soil) 0.21700 0.64604 0.336 0.737 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 125.56 on 119 degrees of freedom ## Residual deviance: 123.29 on 117 degrees of freedom ## AIC: 455.62 ## ## Number of Fisher Scoring iterations: 5 The coefficient the model estimated is close to 1, which would be equivalent to an offset. Author: Gordana Popovic Last updated:\n## [1] \u0026quot;Fri Jan 21 17:07:54 2022\u0026quot;  "
},
{
	"uri": "/statistics/meta-analysis/meta-analysis-3/",
	"title": "More Complex Models",
	"tags": [],
	"description": "",
	"content": "  First read our introduction to meta analysis and become familiar with commonly used statistical models for meta-analysis. Now, we consider more complex models.\nMore complex models Up to now, we have completely ignored non-independence among effect sizes. We assumed that we have one effect size from one study (or paper). But in reality, a paper usually contains multiple effect sizes. These effect sizes from the same studies are not independent of each other. Let’s consider a model where we have several effect sizes from single studies like our data set. First, I give you a math representation:\n\\[\\begin{equation} y_{ij}=b_0+s_i+u_{ij}+e_{ij} \\\\ s_i\\sim \\mathcal{N}(0,\\tau^2)\\ \\\\ u_{ij}\\sim \\mathcal{N}(0,\\sigma^2)\\ \\\\ e_{ij}\\sim \\mathcal{N}(0,v_{ij})\\ \\end{equation}\\]\nwhere \\(u_{ij}\\) is a deviation from \\(s_i\\) (the within-study effect; the \\(j\\)th effect size from the \\(i\\)th study),it is normally distributed with \\(\\sigma^2\\) (other notations are comparable as above).\nWe can visualize this (again Figure 4 from Nakagawa et al. 2017). And we can see why this model is called, a ‘multilevel’ meta-analytic model, an extension of the random-effects model.\nWe can fit an equivalent model using the function rma.mv. We need to add paper (the between-study effect) and id (different effect sizes; the within-study effect) in our data set to the multilevel model as random factors.\nmultilevel_m \u0026lt;- rma.mv(yi = yi, V = vi, random = list(~1 | paper, ~1 | id), method = \u0026quot;REML\u0026quot;, data = dat) summary(multilevel_m) ## ## Multivariate Meta-Analysis Model (k = 102; method: REML) ## ## logLik Deviance AIC BIC AICc ## 7.1102 -14.2204 -8.2204 -0.3750 -7.9730 ## ## Variance Components: ## ## estim sqrt nlvls fixed factor ## sigma^2.1 0.0015 0.0392 29 no paper ## sigma^2.2 0.0248 0.1573 102 no id ## ## Test for Heterogeneity: ## Q(df = 101) = 769.0185, p-val \u0026lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## 0.2578 0.0222 11.6046 \u0026lt;.0001 0.2142 0.3013 *** ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 OK, this does not have \\(I^2\\). We have actually proposed a multilevel-model version of \\(I^2\\) (Nakagawa \u0026amp; Santos 2012), which, in this case, can be written as:\n\\[\\begin{equation} I^2=\\frac{\\tau^2+\\sigma^2}{(\\tau^2+\\sigma^2+\\bar{v})}, \\end{equation}\\]\nNote that we do have \\(\\tau^2\\) and \\(\\sigma^2\\), which are sigma^2.1 and sigma^2.2 in the output above, respectively. Using this formula, we have the total heterogeneity \\(I^2\\) of 88.93% (the \\(\\bar{v} = 0.0033\\) for our data set; see Nakagawa \u0026amp; Santos 2012 for how to get this). As you might expect, this value is nearly identical to what we got from the random-effect model (88.9%). But this model is better as we are explicitly dealing with non-independence arising from effect sizes from the same studies (although it turns out the problem is not completely solved…).\nAs you could probably imagine, we can add more levels to this multilevel models. For example, we could add genus in the data set, as related species are probably more similar to each other. But it is better to model this taxonomic non-independence using phylogeny (which is the topic of the next section). Note that we can also run meta-regression using rma.mv; more complex models (different versions of a multilevel model) are explained in Nakagawa \u0026amp; Santos (2012).\n Phylogenetic meta-analysis As I just mentioned, we have, so far, also ignored another type of non-independence, i.e. phylogenetic relatedness. Chuck Darwin unfortunately (or fortunately) found out all species on earth are related so we need to deal with this issue.\nActually, we just need to model phylogenetic non-independence by adding the degree of relatedness among species as a correlation matrix. The term, phylogeny or phylo, which we will create below, can be added as a random factor to a multilevel model.\nThis means that we need a phylogenetic tree for our data set. For this data set, we have prepared a tree for you to download here. But it is not that difficult to get a tree together by using the package called rotl.\nFirst install and load the package ape that we will use to import the tree file and visualise the phylogeny.\nlibrary(ape) tree \u0026lt;- read.tree(file = \u0026quot;tree_curtis1998.tre\u0026quot;) plot(tree, cex = 0.7) We can then make a correlation matrix (a relatedness matrix among species). I’ve skipped explantions of these operations - other than saying we have a correlation matrix to fit to the model\ntree \u0026lt;- compute.brlen(tree) cor \u0026lt;- vcv(tree, cor = T) We need a bit more preparation as we do have not a column which has the whole species names (we call it phylo). Also, it turns out that we need to correct some typos in genus and species columns in our data.\nlibrary(Hmisc) phylo \u0026lt;- tolower(paste(dat$genus, dat$species, sep = \u0026quot;_\u0026quot;)) # note: \u0026#39;populusx_euramericana\u0026#39; should be same as \u0026#39;populus_euramericana\u0026#39; phylo \u0026lt;- gsub(\u0026quot;populusx_euramericana\u0026quot;, \u0026quot;populus_euramericana\u0026quot;, phylo) # these two species are the two different names of the same species phylo \u0026lt;- gsub(\u0026quot;nothofagus_fusca\u0026quot;, \u0026quot;fuscospora_fusca\u0026quot;, phylo) phylo \u0026lt;- capitalize(phylo) dat[, \u0026quot;phylo\u0026quot;] \u0026lt;- phylo We now have our phylogenetic correlation cor and a column with species names phylo, and can run our meta-analysis again with a phylogenetic effect.\nphylo_m \u0026lt;- rma.mv(yi = yi, V = vi, random = list(~1 | phylo, ~1 | paper, ~1 | id), R = list(phylo = cor), method = \u0026quot;REML\u0026quot;, data = dat) summary(phylo_m) ## ## Multivariate Meta-Analysis Model (k = 102; method: REML) ## ## logLik Deviance AIC BIC AICc ## 7.1102 -14.2204 -6.2204 4.2401 -5.8037 ## ## Variance Components: ## ## estim sqrt nlvls fixed factor R ## sigma^2.1 0.0000 0.0000 36 no phylo yes ## sigma^2.2 0.0015 0.0392 29 no paper no ## sigma^2.3 0.0248 0.1573 102 no id no ## ## Test for Heterogeneity: ## Q(df = 101) = 769.0185, p-val \u0026lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## 0.2578 0.0222 11.6046 \u0026lt;.0001 0.2142 0.3013 *** ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 All this effort, there is no variation due to phylogeny! So we do not need this phylogeny term (i.e. phylo).\nAlso, this multilevel model can be considered as a comparative phylogenetic method. There are quite a few things you need to know and to be careful of, which I cannot cover (e.g. we assumed that the Brownian-motion model of evolution in the model above - what does this even mean?). But Will and I have written a nice ‘primer’ so please read that primer – Cornwell \u0026amp; Nakagawa (2017)\nUnfortunately, there are other types of non-independence from what covered here. We summaries all types in our recent paper – Noble et al. (2017). So read this as well if you are interested.\n Complex robust models (the last section!) We have a multilevel version of the robust model too. It is easy to fit using the function rma.mv (we do not include phylo as it did not explain any variance).\n# you can put a marix or vector to W which is equivalent to \u0026#39;weights\u0026#39; in rma robustml_m \u0026lt;- rma.mv(yi = yi, V = vi, W = wi, random = list(~1 | paper, ~1 | id), method = \u0026quot;REML\u0026quot;, data = dat) summary(robustml_m) ## ## Multivariate Meta-Analysis Model (k = 102; method: REML) ## ## logLik Deviance AIC BIC AICc ## 4.6819 -9.3639 -3.3639 4.4815 -3.1165 ## ## Variance Components: ## ## estim sqrt nlvls fixed factor ## sigma^2.1 0.0015 0.0392 29 no paper ## sigma^2.2 0.0248 0.1573 102 no id ## ## Test for Heterogeneity: ## Q(df = 101) = 769.0185, p-val \u0026lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## 0.2088 0.0483 4.3200 \u0026lt;.0001 0.1141 0.3036 *** ## ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 I think this is the model we have been looking for, i.e. our final model. At least for this data set.\n Further help (references) Any questions? Or email me (s(-dot-)nakagawa(-at-)unsw(-dot-)edu(-dot-)au). Also visit our website\nGo to the metafor package’s website. There you find many worked examples.\nCornwell, W., and S. Nakagawa. 2017. Phylogenetic comparative methods. Current Biology 27:R333-R336. Nakagawa, S., D. W. A. Noble, A. M. Senior, and M. Lagisz. 2017. Meta-evaluation of meta-analysis: ten appraisal questions for biologists. BMC Biology 15:18. Nakagawa, S., and E. S. A. Santos. 2012. Methodological issues and advances in biological meta-analysis. Evolutionary Ecology 26:1253-1274. Noble, D. W. A., M. Lagisz, R. E. O’Dea, and S. Nakagawa. 2017. Nonindependence and sensitivity analyses in ecological and evolutionary meta-analyses. Molecular Ecology 26:2410-2425. Authors: Shinichi Nakagawa and Malgorzata (Losia) Lagisz Last updated:\n## [1] \u0026quot;Mon Jan 24 13:01:51 2022\u0026quot;  "
},
{
	"uri": "/statistics/linear-models/anova/anova-nested/",
	"title": "Nested ANOVA",
	"tags": [],
	"description": "",
	"content": "  Usage In the two-way ANOVA design, the two factors are known as factorial (i.e., there was every combination of every level of each factor). Other experimental designs feature factors that are termed nested. This is when each level of one of the factors is unique to only one level of the other factor. The difference is best illustrated with the following two experimental designs where there are two factors, A and B.\nIn the nested design, the levels of factor B appear in only one of the levels in factor A, not both. This often happens with factors like “site” or “area” - they usually belong to only one level of your other factor (e.g., if contrasting north and south of the harbour, a suburb could not be in both categories).\nFactor B is termed nested within factor A, usually written as B(A). These designs have different sources of variance to the factorial designs, and do not have an interaction term. The designs are quite common in ecology and environmental sciences, and are often used to partition variance in spatially hierarchical sampling (e.g., habitats, areas within habitats, plots within areas etc.).\nThe examples below comes from an experiment investigating the impact of introduced American mink on small rodents (voles) in Finland. The hypothesis was that mink prey upon voles thereby reducing vole numbers and limiting their population size. To test this, minks were removed from large areas (\u0026gt; 20 km2) in the Baltic Sea. The Ho from the experiment is that the mean count of voles on islands in removal sites will be the same as the mean vole count on islands in control areas.\nThe data represent two treatments (mink removal and control) and two areas nested within each treatment. Then there are 10 samples in each area. Each of these samples represents the numbers of individual voles trapped on an island (all islands were more than 300 m apart ensuring some independence) over 4 nights.\nThe design is nested because an area cannot belong to both a removal treatment and a control. It is useful to think of areas as being the replicates for the treatment, and the individual samples as being replicates for each area.\n Running the analysis Data for a nested design should be in the format of samples as rows and variables as columns. A coloumn should correspond to the dependent variable y, in this case, number of voles. Another coloumn should contain the levels of the fixed factor A, Treatment. Finally, a column for the levels of the nested random factor B, Area.\n#Input data file Mink = read.csv(file = \u0026quot;Mink.csv\u0026quot;, header = TRUE) #Check the structure of the data str(Mink) ## \u0026#39;data.frame\u0026#39;: 40 obs. of 3 variables: ## $ Treatment: chr \u0026quot;Control\u0026quot; \u0026quot;Control\u0026quot; \u0026quot;Control\u0026quot; \u0026quot;Control\u0026quot; ... ## $ Area : chr \u0026quot;area1\u0026quot; \u0026quot;area1\u0026quot; \u0026quot;area1\u0026quot; \u0026quot;area1\u0026quot; ... ## $ Voles : int 8 16 11 15 9 10 11 9 8 14 ... #Run the analysis Mink.nested = aov(Voles ~ Treatment + Area%in%Treatment, data = Mink) summary(Mink.nested) ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Treatment 1 1416.1 1416.1 38.39 3.81e-07 *** ## Treatment:Area 2 357.8 178.9 4.85 0.0136 * ## Residuals 36 1328.0 36.9 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1  Interpreting the results The output is a little different to the factorial ANOVA. The top section gives a significance test of the fixed effect, Treatment, - this is what we’re interested in. The residuals for this test are those associated with the random effect ‘Area’.\nA significant F-ratio (P\u0026lt;0.05) for a nested factor indicates high variance among subgroups within a group. For example, a difference in mean vole numbers of the two areas within a treatment. This is expected, however, leads to few degrees of freedom to test main effects. Additionally, it suggests treatments may not have a uniform effect across levels of the nested factor. For example, voles in one removal area showed a stronger response than another area.\nF-ratios\n Among groups = MSamong/MSsubgroup Factor B = MSsubgroup/MSResidual  Degrees of freedom\n Among groups = (a - 1) (where a = number of levels of Factor A) Among subgroups = a(b - 1) (where b = number of levels of Factor B) Within subgroups = ab(n - 1) (where n = sample size)  Where there are greater than 2 levels of the the fixed factor of interest, post-hoc analysis can be used to determine which groups differ. Refer to the post-hoc module for further information.\nPooling\nAlways examine nested factors before the upper levels. If the variance explained by the nested factor is negligible, it can be pooled. If the F ratio of MSsubgroup/MSwithin is non significant then you don’t need subgroups and can perform a one factor analysis.\nEven if MSsubgroup/MSwithin is non-significant at a = 0.05, there may be subgroup effects (may be high Type II error). To be cautious, only pool SS when P\u0026gt;0.25, so there is very little chance that you are incorrectly accepting the null hypothesis of no effect.\n Assumptions to check The same assumptions of linear models apply to nested ANOVA’s; independence, normality and heterogeneity of variances. Indpendence needs to be considered at the design stage (see independence module). We can now check the assumptions of homgeneity of variance (namely that the residuals are homgeneous i.e., approximately equal), and normality (even disturbiton of data about the mean, no wonky outliers).\nBecause tests of the fixed factor A uses uses the means of the nested Factor B, the assumptions of homogeneity and normaility apply with respect to the means of Factor B. Normality of Factor A are likely to be normally distributed based upon the Central Limit Theorem.\nWe advocate a qualitative evalutation of the assumptions, rather than a formal test suc has Cochran’s test. Linear models in general are quite ‘robust’ for violating these assumptions (heterogeneity and normality), within reason.\nThe assumption of normality can be checked by a frequency histogram of the residuals or using a quantile plot where the residuals are plotted against the values expected from a normal distribution. The historgram of residuals should follow a normal distribution. If the points in the quantile plot lie mostly on the line, the residuals are normally distributed. Violations of normality can be fixed via transformations or by using a different error-distribution in a GLM. See the GLM module for more information. The plot() function on a model object provides a series of four graphical model diagnostics, the second of which is a quantile plot.\nhist(Mink.nested$residuals) plot(Mink.nested,which=2) Heterogenous variances is indicated by non-random pattern in the residuals vs. fitted plot. If there is strong patterns, one potential solution is to transform the response variable y. If this doesn’t fix the problem the best solution is to use a different error disturbiton in a gnerealised linear model framework (GLM).\nplot(Mink.nested$residuals~Mink.nested$fitted) #Alternative option plot(Turtles.ANOVA,which=1)  Communicating the results Written The subgroup factor is rarely of interest and so is given little emphasis in the results. For example, the abundance of voles was significantly greater where minks have been removed (F = 38.39, P \u0026lt;0.001).\nVisual A boxplot would be a suitable means of displaying the differences between the groups of the factor of interest, in this case Treatment.\n Further help Type ?aov to get the R help for this function.\nQuinn and Keough (2002) Experimental design and data analysis for biologist. Cambridge University Press\nMcKillup (2012) Statistics explained. An introductory guide for life scientists Cambridge University Press\n "
},
{
	"uri": "/graphics/basic-plotting/one-continuous-one-factor/",
	"title": "One Continuous and One Categorical Variable",
	"tags": [],
	"description": "",
	"content": "  Visualising how a measured variable relates to other variables of interest is essential for data exploration and communicating the results of scientific research. This page details how to plot a single, continuous variable against levels of a categorical predictor variable.\nThese sorts of plots are very commonly used in the biological, earth and environmental sciences. For example, to view how a given variable differs between an experimental treatment and a control, or among sites and sampling times in environmental sampling.\nWe will use sample data from an experiment that contrasted the metabolic rate of two species of prawns and introduce two commonly used types of plots for this purpose: boxplots and bar plots.\nFirstly, download the sample data file, Prawns_MR.csv, and import into R.\nPrawns \u0026lt;- read.csv(file = \u0026quot;Prawns_MR.csv\u0026quot;) \nBoxplots \nBoxplots are easily made with the boxplot function. Boxplots show the distribution of a variable by indicating the median, quartiles, maximum and minimum of a variable. The top and bottom whiskers are the maximum and minimum values (excluding any outliers that are indicated by a circle). The thick black line is the median, with the boxes either side of the median line the lower and upper quartiles.\nTo contrast metabolic rate across the two species, we would use:\nboxplot(Metabolic_rate ~ Species, data = Prawns) The continuous variable is on the left of the tilde (~) and the categorical variable is on the right. Straight away you can see that species B has a higher metabolic rate than species A.  Bar plots \nThese sorts of data are also commonly visualised with a bar plot that displays the means of the continuous variable for each level of the categorical variable, with error bars displaying some measures of variation within each category. The error bars could be the standard deviation, standard error or 95% confidence intervals.\nWhile commonly used, they are not so easy to create in the base functions in R. There are various ways to do this, but one is to use the summarise and group_by functions from the package dplyr to calculate the means and measures of variation for each level of your categorical variable (see Summarising data).\nHere is some sample code to plot means +/- standard deviations. For more control over error bars, we recommend using the more advanced plotting options in the package ggplot2 (see bar plots with error bars).\nlibrary(dplyr) Species.summary \u0026lt;- Prawns %\u0026gt;% # the names of the new data frame and the data frame to be summarised group_by(Species) %\u0026gt;% # the grouping variable summarise(mean = mean(Metabolic_rate), # calculates the mean sd = sd(Metabolic_rate), # calculates the standard deviation lower = mean(Metabolic_rate) - sd(Metabolic_rate), upper = mean(Metabolic_rate) + sd(Metabolic_rate)) In a new data frame called Species.summary, we now have the means, standard deviations and the lower and upper values that set the size of the error bars for each level of the grouping variable. The limits for the error bars were calculated by adding (upper) or subtracting (lower) the standard deviation from the mean.\nWe can now use the barplot and arrows functions to make a plot with error bars.\nPrawn.plot \u0026lt;- barplot(Species.summary$mean, names.arg = Species.summary$Species, ylab=\u0026quot;Metabolic rate\u0026quot;, xlab = \u0026quot;Species\u0026quot;,ylim=c(0,1)) arrows(Prawn.plot, Species.summary$lower, Prawn.plot, Species.summary$upper, angle=90, code=3) Note that plots of means and error bars can be misleading as they hide the true distributions of the data. Means can also be misleading when data are very skewed, and calculations for error bars using t statistics (e.g., 95% confidence intervals) assume the data are normally distributed.  Formatting plots \nBox plots and bar plots can be formatted using the basic R formatting in the base graphics package. The code below details some of the more commonly used formatting commands for these plots. These commands can be used for any plotting function in the graphics package.\nAdd axis labels or titles\nAxis labels are produced with the xlab and ylab arguments. Titles are provided with the main argument. Note that figures in scientific publications rarely have a title, but include information about the plot in a figure legend presented below the plot.\nboxplot(Metabolic_rate~Species, data = Prawns, xlab = \u0026#39;Species\u0026#39;, ylab = \u0026#39;Metabolic rate\u0026#39;) Edit axis limits\nAxis limits are set by the xlim and ylim arguments, where a vector of the minimum and maximum limits is required. For example to set the Y axis to have a minimum of zero and a maximum of 1, use:\nboxplot(Metabolic_rate~Species, data = Prawns, xlab = \u0026#39;Species\u0026#39;, ylab = \u0026#39;Metabolic rate\u0026#39;, ylim = c(0,1)) Renaming levels of the categorical factor\nIf the levels of your categorical factor are not ideal for the plot, you can rename those with the names argument. For example, to put the actual species names on:\nboxplot(Metabolic_rate~Species, data = Prawns, xlab = \u0026#39;Species\u0026#39;, ylab = \u0026#39;Metabolic rate\u0026#39;, names = c(\u0026quot;Penaeus monodon\u0026quot;,\u0026quot;Fenneropenaeus merguiensis\u0026quot;)) Adding colour Colour can be added to any part of the plots (axis, fonts etc.) using col argument. There are over 600 colours that can be plotted, type colours() for the whole range.\nHere we will simply change the colour of the bars in the bar plot to red.\nbarplot(Species.summary$mean, names.arg = Species.summary$Species, ylab=\u0026quot;Metabolic rate\u0026quot;, xlab = \u0026quot;Species\u0026quot;,ylim=c(0,1),col=\u0026#39;red\u0026#39;)  Further help \nType ?boxplot and ?barplot to get the R help for these functions. Authors: Stephanie Brodie \u0026amp; Alistair Poore Last updated:\n## [1] \u0026quot;Thu Jan 20 13:22:50 2022\u0026quot;  "
},
{
	"uri": "/statistics/t-tests/paired-t-test/",
	"title": "Paired T-test",
	"tags": [],
	"description": "",
	"content": "  Paired t-tests are used to compare the means of two groups of measurements when individual objects are measured twice, once for each type of measurement. Data could be paired in various ways: if the same measure is taken from a single object in two different treatments or at two different times, or if different types of measures are being contrasted from the same object.\nFor example, to contrast the photosynthetic performance of ten plants in two environments in a greenhouse (shady and sunny), we could measure performance in each individual plant twice, once in the shade and once in the sun. The measures are paired by belonging to the same individual plant.\nFor this experimental design, we would use a paired t-test to compare the measurements taken in the two environments. The 20 individual measurements are not independent of each other because we would expect the pair of measurements taken from the same individual to be more similar to each other than if randomly sampled from all available plants. We are thus unable to use an independent samples t test - that test would be appropriate if each plant was used only once, with some plants measured in the shady treatment and different set of plants measured in the sunny treatment.\nPairing data like this is usually done to reduce the likely variation among measurements with the aim of better detecting differences between groups. In this example, the difference between the two measures of photosynthetic performance on a given plant should reflect mostly the effect of sunlight, while in an independent samples design, the difference between a plant in the shade and another plant in the sun will reflect both differences in the effects of sunlight and differences between the individual plants.\nFor a paired t-test, the test statistic, t is:\n\\[t = \\frac{\\bar{d}}{SE_{d}}\\]\nWhere the \\(\\bar{d}\\) is the mean of the differences between values for each pair, and SEd is the standard error of that set of differences.\nNote that this equation is identical to a One sample t-test, used to contrast any sample mean (\\(\\bar{x}\\)) to a known population mean (\\(\\mu\\)) or hypothesised value. What you are doing here is testing whether your sample of differences is likely to have come from a population of differences that have a mean of zero (another way of saying that your groups are the same).\n\\[t = \\frac{\\bar{x}-\\mu}{SE}\\] Running the analysis \nThe test statistic t is relatively straightforward to calculate manually. The test statistic can then checked against a t distribution in order to determine the probability of obtaining that value of the test statistic if the null hypothesis is true. In R, to calculate the probability associated with a given value of t use:\npt(q, df = your.df, lower.tail = FALSE)*2 where q is your value of t, your.df is the degrees of freedom (the number of pairs-1). The lower.tail = FALSE ensures that you are calculating the probability of getting a t value larger than yours (i.e the upper tail, P[X \u0026gt; x]). Note that the critical value for t (\\(\\alpha = 0.05\\)) varies depending on the number of degrees of freedom - larger degrees of freedom = smaller critical value of t.\nThe t.test function gives you the test statistic and its associated probability in one output. For an paired t-test, we would use:\nt.test(x = my_sample1, y = my_sample2, paired = TRUE) where my_sample1 and my_sample2 are vectors containing the measurements from each sample. You would need to make sure the two vectors have the same number of values and that data from each pair were in the matching rows.\nAlternatively, if you have a data frame with the response and predictor variables in separate columns you can use a formula statement, y ~ x, rather than the code above. Again, you would need to ensure the matching pairs were in the right order (e.g., the fourth row of the shady treatment is the data collected from the same plant as the fourth row of the sunny treatment).\nDownload a sample data set in this format, Greenhouse.csv, and import into R\nGreenhouse = read.csv(file = \u0026quot;Greenhouse.csv\u0026quot;, header = TRUE) The paired t-test is run with the t.test function, with the arguments specifying the response variable (Performance) to the left of the ~, the predictor variable (Treatment) to the right of the ~, the data frame to be used and the fact that it is a paired t-test.\nt.test(Performance ~ Treatment, data = Greenhouse, paired = TRUE) \n Interpreting the results \n## ## Paired t-test ## ## data: Performance by Treatment ## t = -18.812, df = 9, p-value = 1.557e-08 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.2111674 -0.1658326 ## sample estimates: ## mean of the differences ## -0.1885 The important output of a paired t-test includes the test statistic t, in this case 18.8, the degrees of freedom (in this case 9) and the probability associated with that value of t. In this case, we have a very low p value (p \u0026lt; 0.001) and can reject the null hypothesis that the plants can photosynthesise with the same performance in the two light environments.\nYou also get the mean and 95% confidence intervals for the differences between measurements in each pair (this will not overlap zero when the test is significant).  Assumptions to check \nt-tests are parametric tests, which implies we can specify a probability distribution for the population of the variable from which samples were taken. Parametric (and non-parametric) tests have a number of assumptions. If these assumptions are violated we can no longer be sure that the test statistic follows a t distribution, in which case p-values may be inaccurate.\nNormality. For a paired t-test, it is assumed the the sample of differences is normally distributed. If these are highly skewed, transformations may be used to achieve a distribution closer to normal.\nIndependence. The paired design takes into account that the two measures from each pair are not independent. It is still important, however, that each pair of objects measured are independent from other pairs. If they are linked in any way (e.g., groups of plants sharing a water tray) then more complex analytical design that account for additional factors may be required.  Communicating the results \nWritten. As a minimum, the observed t statistic, the P-value and the number of degrees of freedom should be reported. For example, you could write “The photosynthetic performance of plants was significantly greater in sunny environments in contrast to shady environments (paired t-test: t = 18.81, df = 9, P \u0026lt; 0.001)”.\nVisual. Box plots or column graphs with error bars are effective ways of communicating the variation in a single continuous response variable versus a single categorical predictor variable.\nboxplot(Performance~Treatment, data = Greenhouse, xlab = \u0026quot;Light environment\u0026quot;, ylab = \u0026quot;Photosynthetic performance (FvFm)\u0026quot;)  Further help \nType ?t.test to get the R help for this function.\nQuinn and Keough (2002) Experimental design and data analysis for biologists. Cambridge University Press. Chapter 9: Hypothesis testing. McKillup (2012) Statistics explained. An introductory guide for life scientists. Cambridge University Press. Chapter 9: Comparing the means of one and two samples of normally distributed data. \nAuthor: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 15:59:54 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/summarising-data/",
	"title": "Summarising data",
	"tags": [],
	"description": "",
	"content": "  Summarising our data is often the first step in data exploration and needed to understanding patterns in the magnitude and variability of our measurements.\nWe will use the package dplyr which has many convenient functions for summarising data, so let’s start by loading the package.\nlibrary(dplyr) As with the help page on Subsetting data, we will use a data set where bats were sampled across regrowth forest in south-eastern Australia that had been thinned to reduce the density of trees. Download the data set, Bats_data.csv, and import into R.\nBats \u0026lt;- read.csv(file=\u0026quot;Bats_data.csv\u0026quot;, header=T, stringsAsFactors=F) \nSummarising data with dplyr \nObtaining summary measures from a single variable\nWe can use the function summarise with a range of built-in summary functions from R to obtain summary statistics from our data.\nFor example, to the mean activity of bats across all nightly measurements in the study, I would use the \u0026gt;mean summary function within the summarise function as follows, specifying the data frame (Bats), the variable I want to get the mean of (Activity) and a name for the new variable (Mean.Activity):\nsummarise(Bats, Mean.Activity=mean(Activity)) ## Mean.Activity ## 1 316.0405 We can add as many other measurements to this as we like, including a wide range of summary functions (described with #).\nsummarise(Bats, mean.activity=mean(Activity), # mean min.Activity=min(Activity), # minimum max.Activity=max(Activity), # maximum med.Activity=median(Activity), # median sd.Activity=sd(Activity), # standard deviation var.Activity=var(Activity), # variance n.Activity=n(), # sample size se.Activity=sd.Activity/sqrt(n.Activity), # standard error IQR.Activity=IQR(Activity)) # interquartile range ## mean.activity min.Activity max.Activity med.Activity sd.Activity var.Activity ## 1 316.0405 9 1070 282 203.1081 41252.89 ## n.Activity se.Activity IQR.Activity ## 1 173 15.44202 292 If we are looking at factors, especially if they are ordered in some way, we may find some of the other dplyr summary functions useful. For example:\nsummarise(Bats, first.site=first(Site), # first value in Site variable last.Site=last(Site), # last value in Site variable third.Site=nth(Site, 3), # nth value of Site n.Sites=n_distinct(Site)) # number of distinct sites ## first.site last.Site third.Site n.Sites ## 1 CC02A1 KC33A2 CC02A1 47 Obtaining summary measures from groups of rows\nVery often we’re interested in measurements of mean values and variability across categories, so need to calculate summary measures for variables within each category.\nFor example, in this dataset, we may want to compare bat activity across forests that vary in their history of thinning. The sites belong to four categories of thinning history: dense regrowth sites that were thinned recently (“short-term”) and in the medium term (“medium-term”, ), sites that were never thinned (“unthinned”“) and mature open forest (”reference”).\nTo summarise any variables for each of these categories, we use the group_by function in dplyr.\nBats_by_Treatment \u0026lt;- group_by(Bats, Treatment.thinned) In order to retain our original datset as is, I have used the function to make a new dataset called “Bats_by_Treatment”. Now I can use exactly the same code as we used above to summarise the data for each of the groups.\nTreatment.summary \u0026lt;- summarise(Bats_by_Treatment, mean.Activity=mean(Activity), # mean min.Activity=min(Activity), # minimum max.Activity=max(Activity), # maximum med.Activity=median(Activity), # median sd.Activity=sd(Activity), # standard deviation var.Activity=var(Activity), # variance n.Activity=n(), # sample size se.Activity=sd.Activity/sqrt(n.Activity), # standard error IQR.Activity=IQR(Activity)) # interquartile range Note that the input data frame is now “Bats_by_Treatment”, rather than “Bats”.\nThe new summarised data has been placed in a new object (Treatment.summary), which of tbl class, particular to dplyr. To convert this to the more broadly used data frame class, we can use as.data.frame.\nTreatment.summary \u0026lt;- as.data.frame(Treatment.summary) View this new data frame to see the summary statistics for each of the four forest categories.\nView(Treatment.summary) You can also combine the grouping and summarising into some neater code by “piping” with %\u0026gt;%. For example, the code above could be replaced with:\nTreatment.summary \u0026lt;- Bats %\u0026gt;% group_by(Treatment.thinned) %\u0026gt;% summarise(mean.Activity=mean(Activity), # mean min.Activity=min(Activity), # minimum max.Activity=max(Activity), # maximum med.Activity=median(Activity), # median sd.Activity=sd(Activity), # standard deviation var.Activity=var(Activity), # variance n.Activity=n(), # sample size se.Activity=sd.Activity/sqrt(n.Activity), # standard error IQR.Activity=IQR(Activity)) # interquartile range \nIssues with missing data\nThings can go wrong in the field and we don’t always collect all the data we need at each site.\nTo show you how this affects the summarise function, we can make a new variable (Activity2), which is a copy of Activity but with some of the activity data (the first four rows) now missing.\nBats$Activity2 \u0026lt;- Bats$Activity Bats$Activity2[1:4] \u0026lt;- rep(NA, 4) Next, let’s try summarising the data:\nsummarise(Bats, mean.Activity=mean(Activity2))  ## mean.Activity ## 1 NA You’ll see we get an NA for the result. To obtain the mean for all the values that are present, we can add an argument, na.rm=TRUE, to remove the rows that are NA.\nsummarise(Bats, mean.Activity=mean(Activity2, na.rm=TRUE))  ## mean.Activity ## 1 314.8757 Just remember that this will decrease your sample size. This will work for the summary functions apart from the n function that counts the number of values in a vector. To count the non-missing data, you can use this (slightly more complicated) piece of code to get your new sample size.\nlength(Bats$Activity2[!is.na(Bats$Activity2)]) ## [1] 169 This calculates the number of values, length, of the vector of bat activity values, Bats$Activity2, where they are not NA, !is.na. Revising the Subsetting data may help you understand this statement.  Communicating the results \nWritten If we were writing a paper about bat activity across different forest thinning treatments, we could use our summarised data to make some broad observations at the beginning of our results section, prior to further analysis. For example: “Bats were twice as active in in mature open (reference) forest (365 ? 27) compared to unthinned regrowth (166 ? 21) (mean ? SE). However bat activity was similar across medium-term (385 ? 36) and short-term (350 ? 27) thinned and reference forests”.\nVisual Presenting means and standard errors of categorical data gives us a way to visually communicate a treatment effect (as long as it is supported by appropriate statistical analysis). Here we’ve used the ggplot2 package to make a simple bar graph with means ? standard error (error bars).\n Further help \nThis tutorial was based on the excellent Data wrangling with dplyr and tidyr cheat sheet produced by Rstudio.Images were sourced from the same document.\nYou can type ?dplyr to get help with this package.\nIntroduction to dplyr\nIf you’d like to learn more about the ggplot language for plotting, have a look at our worksheets on plotting, starting with Plotting with gglpot: the basics.\nAuthor: Rachel V. Blakey Last updated:\n## [1] \u0026quot;Wed Jan 19 12:13:38 2022\u0026quot;  "
},
{
	"uri": "/graphics/ggplot/ggplot-labels/",
	"title": "Titles and Axes Labels",
	"tags": [],
	"description": "",
	"content": "  ggplots are almost entirely customisable. This gives you the freedom to create a plot design that perfectly matches your report, essay or paper.\nThis page provides help for adding titles, legends and axis labels.\nBefore you get started, read the page on the basics of plotting with ggplot and install the package ggplot2.\nlibrary(ggplot2) \nIn these examples, let’s use a data set that is already in R with the length and width of floral parts for three species of iris. First, load the data set:\ndata(iris) The following code for a scatter plot of petal length vs sepal length with the three species colour-coded is the base that we will use throughout this tutorial:\nIrisPlot \u0026lt;- ggplot(iris, aes(Sepal.Length, Petal.Length, colour=Species)) + geom_point()  Adding a title \nTo add a title to your plot, add the code +ggtitle(\"Your Title Here\") to your line of basic ggplot code. Ensure you have quotation marks at the start and end of your title.\nprint(IrisPlot + ggtitle(\u0026quot;Petal and sepal length of iris\u0026quot;)) If you have a particulary long title that would work better on two lines, use \\n for a new line. Make sure to use the correct slash.\nprint(IrisPlot + ggtitle(\u0026quot;Petal and sepal length \\nof three species of iris\u0026quot;))  Changing axis labels \nTo alter the labels on the axis, add the code +labs(y= \"y axis name\", x = \"x axis name\") to your line of basic ggplot code.\nprint(IrisPlot + labs(y=\u0026quot;Petal length (cm)\u0026quot;, x = \u0026quot;Sepal length (cm)\u0026quot;)) Note: You can also use +labs(title = \"Title\") which is equivalent to ggtitle.\nFor example:\nprint(IrisPlot + labs(title= \u0026quot;Petal and Sepal Length \\nof Iris\u0026quot;, y=\u0026quot;Petal Length (cm)\u0026quot;, x = \u0026quot;Sepal Length (cm)\u0026quot;)) \n Changing the legend title \nIn the same way you edited the title and axis names, you can alter the legend title by adding +labs(colour = \"Legend Title\") to the end of your basic plot code. Note: This will only work if you have actually added an extra variable to your basic aes code (in this case, using colour=Species to group the points by Species).\nIrisPlot \u0026lt;- ggplot(iris, aes(Sepal.Length, Petal.Length, colour=Species)) + geom_point() print(IrisPlot + labs(colour = \u0026quot;Iris species\u0026quot;)) Note: If you are using a histogram, boxplot or bar graph then it is slightly different. You must use fill instead of colour.\nIrisBox \u0026lt;- ggplot(iris, aes(Species, Sepal.Length, fill = Species)) + geom_boxplot() print(IrisBox+ labs(fill = \u0026quot;Iris species\u0026quot;)) \n Altering the text style of your legend, axis or title \nThe font, colour, size and emphasis of your labels and text can all be altered. To do this, use the code theme() and customise with element_text() to alter these properties.\nThe basic format is: mytheme \u0026lt;- theme(title type = element_text(your formats))\nWhere “title type” specifies which particular text you want to edit. These can be:\n plot title. - plot.title = element_text()\n axis title. - axis.title = element_text()\n legend title. - legend.title = element_text()\n legend categories - legend.text = element_text()\n appearance of axis values/numbers. - axis.text = element_text()\n  Formatting choices The font, colour, size and emphasis of any of these labels can be altered by arguments within element_text(your format).\n family. - the font style. Examples of fonts include: “Palatino”, “Helvetica”, “Courier”, “Times”. Further font choices can be seen here. For example, family = \"Palatino\"\n face. - the type of emphasis, with options including bold, italic and “bold.italic”. For example, face = \"bold.italic\"\n colour. - the colour can be changed to any of the colours listed here. Remember to include “” before and after the colour name. For example, colour = \"steelblue2\".\n size. - the size of the text. This is specified by entering a number. For example, size = (3).\n   Example code \nHere is an example of a theme that customises the title, the legend, the axis labels and specifies the font, emphasis, size and colour of each of these. The figure is then plotted with this theme and further code that provides the content of the title and axis labels:\nmynamestheme \u0026lt;- theme(plot.title = element_text(family = \u0026quot;Helvetica\u0026quot;, face = \u0026quot;bold\u0026quot;, size = (15)), legend.title = element_text(colour = \u0026quot;steelblue\u0026quot;, face = \u0026quot;bold.italic\u0026quot;, family = \u0026quot;Helvetica\u0026quot;), legend.text = element_text(face = \u0026quot;italic\u0026quot;, colour=\u0026quot;steelblue4\u0026quot;,family = \u0026quot;Helvetica\u0026quot;), axis.title = element_text(family = \u0026quot;Helvetica\u0026quot;, size = (10), colour = \u0026quot;steelblue4\u0026quot;), axis.text = element_text(family = \u0026quot;Courier\u0026quot;, colour = \u0026quot;cornflowerblue\u0026quot;, size = (10))) print(IrisPlot + mynamestheme + labs( title= \u0026quot;Petal and sepal \\nlength of iris\u0026quot;, y=\u0026quot;Petal length (cm)\u0026quot;, x = \u0026quot;Sepal length (cm)\u0026quot;))  Removing a label \nAnother option is to remove the text from the plot entirely. To do this you use the code = element_blank(), remembering those open and closed brackets. The following code would remove the legend title and axis text.\nmyblanktheme \u0026lt;- theme(plot.title = element_text(family = \u0026quot;Helvetica\u0026quot;, face = \u0026quot;bold\u0026quot;, size = (15)), legend.title = element_blank(), legend.text = element_text(face = \u0026quot;italic\u0026quot;, colour=\u0026quot;steelblue4\u0026quot;,family = \u0026quot;Helvetica\u0026quot;), axis.title = element_text(family = \u0026quot;Helvetica\u0026quot;, size = (10), colour = \u0026quot;steelblue4\u0026quot;), axis.text = element_blank()) print(IrisPlot +myblanktheme + labs( title= \u0026quot;Petal and sepal \\nlength of iris\u0026quot;, y=\u0026quot;Petal length (cm)\u0026quot;, x = \u0026quot;Sepal length (cm)\u0026quot;)) \n###Further help To further customise the aesthetics of the graph, including colour and formatting, see our other ggplot help pages:\n* altering overall appearance.\n* colours and symbols.\nHelp on all the ggplot functions can be found at the The master ggplot help site.\nA useful cheat sheet on commonly used functions can be downloaded here.\nChang, W (2012) R Graphics cookbook. O’Reilly Media. - a guide to ggplot with quite a bit of help online here \nAuthor: Fiona Robinson Last updated:\n## [1] \u0026quot;Thu Jan 20 13:40:57 2022\u0026quot;  "
},
{
	"uri": "/coding-skills/loops/",
	"title": "Using Loops",
	"tags": [],
	"description": "",
	"content": "  Do you find yourself cutting and pasting R code a lot?\nThis usually will create problems for yourself later. One principle of good coding is to try and reduce repetition to the minimum possible. There are two approaches to both make your code organized and save you work. The first one is to use functions and the second one, covered here, is to use loops.\nWe often want to do repetitive tasks in the environmental sciences. For example, we may like to loop through a list of files and do the same thing over and over. There are many packages in R with functions that will do all of the hard work for you (e.g. check out dplyr, tidyr and reshape2 covered here. The dplyr approach works well if your data is “tidy” and in a data frame. If your data are in many different files, then a loop may be a quicker solution.\n###Basic syntax of loops The syntax of loops is relatively simple - the essential components are for(){} with the the for() part dicating how often operations within the {} part are done.\nConsider the loop below. The first time we run through the loop, the value i will be equal to 1, and this value will be displayed with the print function. It will then repeat with i = 2, all the way up to i = 10, doing whatever task is within the {} each time.\nfor (i in 1:10) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 We can change the range of numbers (1:10) to anything we like, they don’t have to be a sequence or integers, or even numbers. You can also change i to anything you like.\nnums \u0026lt;- c(3.2, 890, 0.0001, 400) for (bat in nums) { print(bat) } ## [1] 3.2 ## [1] 890 ## [1] 1e-04 ## [1] 400 chars \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;o\u0026quot;, \u0026quot;u\u0026quot;, \u0026quot;z\u0026quot;) for (bat in chars) { print(bat) } ## [1] \u0026quot;a\u0026quot; ## [1] \u0026quot;o\u0026quot; ## [1] \u0026quot;u\u0026quot; ## [1] \u0026quot;z\u0026quot; Of the most interest to us is changing what is within the {} or the operation we are performing on our data. We can insert anything we like in here. Here is a loop that will print the square and the square root of the numbers 1 to 10.\nfor (i in 1:10) { print(i^2) print(sqrt(i)) } Often we will want to keep the results that we get back from our loop. The first option is to make a blank vector or data frame and append the results to it. This takes longer to run, but doesn’t really matter with simple loops, but can increase your wait times for longer and more complicated loop structures.\nHere is code that will store the square of the numbers 1 to 10 in a new vector called x\nx \u0026lt;- vector() # makes a blank vector for (i in 1:10) { y \u0026lt;- i^2 # performs an operation x \u0026lt;- append(x,y) # overwrites \u0026#39;x\u0026#39; with y appended to it } Here is code that will store both the square and the square root of the numbers 1 to 10 in two columns of a new data frame called x2\nx2 \u0026lt;- data.frame(col1=vector(), col2=vector()) # makes a blank data frame with two columns for (i in 1:10) { col1 \u0026lt;- i^2 # performs first operation col2 \u0026lt;- sqrt(i) # performs second operation x2 \u0026lt;- rbind(x2, cbind(col1, col2)) # overwrites \u0026#39;x2\u0026#39; values including the new row } The second option is to make a blank vector or dataframe of known dimensions and then place the results into it directly. For example, if we had a loop with 10 elements, we could store the results of each operation in a vector with a length of 10\nx \u0026lt;- vector(length=10) # makes a blank vector with a length of 10 for (i in 1:10) { y \u0026lt;- i^2 x[i] \u0026lt;- y # places the output in position i in the vector x } Alternatively, store the results of multiple operations in a new data frame.\nx2 \u0026lt;- data.frame(col1=vector(length=10),col2=vector(length=10)) # makes a blank data frame with two columns and 10 rows for (i in 1:10) { col1 \u0026lt;- i^2 # performs first operation col2 \u0026lt;- sqrt(i) # performs second operation x2[i,1] \u0026lt;- col1 # places the first result into row i, column 1 x2[i,2] \u0026lt;- col2 # places the second result into row i, column 2 } \n###An ecological example Now we can use your new loop skills in an ecological context. As with the Subsetting data tutorial, we will use a dataset where bats were sampled across regrowth forest in south-eastern Australia which has been thinned to reduce the density of trees.\nBats \u0026lt;- read.csv(file=\u0026quot;Bats_data.csv\u0026quot;, header=T, stringsAsFactors=F) str(Bats) ## \u0026#39;data.frame\u0026#39;: 173 obs. of 10 variables: ## $ Site : chr \u0026quot;CC02A1\u0026quot; \u0026quot;CC02A1\u0026quot; \u0026quot;CC02A1\u0026quot; \u0026quot;CC02A2\u0026quot; ... ## $ Activity : int 299 276 530 356 571 631 144 124 220 468 ... ## $ Foraging : int 0 6 14 5 3 17 3 0 7 8 ... ## $ Date : chr \u0026quot;9/01/2013\u0026quot; \u0026quot;8/01/2013\u0026quot; \u0026quot;7/01/2013\u0026quot; \u0026quot;8/01/2013\u0026quot; ... ## $ Treatment.thinned : chr \u0026quot;medium-term\u0026quot; \u0026quot;medium-term\u0026quot; \u0026quot;medium-term\u0026quot; \u0026quot;medium-term\u0026quot; ... ## $ Area.thinned : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Time.since.thinned : int 7 7 7 7 7 7 7 7 7 7 ... ## $ Exclusion.thinned : num 25.1 25.1 25.1 25.1 25.1 ... ## $ Distance.murray.water: num 190 190 190 216 216 ... ## $ Distance.creek.water : num 444 444 444 885 885 ... Having a look at the structure of this data, we have two response variables: activity (no. of bat calls recorded in a night) and foraging (no. of bat feeding calls recorded in a night). These data were collected over a total of 173 survey nights and at 47 different sites. There are eight potential predictor variables in the dataframe, one of which is a factor (Treatment.thinned), and seven of which are continuous variables (Area.thinned, Time.since.thinned, Exclusion.thinned, Distance.murray.water, Distance.creek.water, Mean.T, Mean.H).\nLet’s say we are exploring our data and we would like to know how well bat activity correlates with our continuous covariates. We’d like to calculate Pearson’s correlation coefficient for activity and each of the covariates separately. Pearson’s correlation coefficient, calculated with the function cor, ranges from -1 (perfect negative correlation) to 1 (perfect positive correlation) with 0 being no correlation. We will store all our correlations in a new data frame called Correlations.\nFirst, use select from dplyr to make a subset of the data with the response variable (activity) and the 5 predictor variables.\nlibrary(dplyr) Bats_subset \u0026lt;- select(Bats, Activity, Area.thinned:Distance.creek.water) Next, make an empty data frame with two columns (the name of the variable and the correlation) and the number of rows needed to store all the correlations.\nrows \u0026lt;- ncol(Bats_subset)-1 # the number of rows needed in our output dataframe Correlations \u0026lt;- data.frame(variable=character(length=rows), correlation=numeric(length=rows), stringsAsFactors=F)  Finally, we can use a loop to calculate each of the correlations and store the output in our new dataframe.\nfor (i in 1:rows) { temp1 \u0026lt;- colnames(Bats_subset[i+1]) # retrieves the name of predictor variable temp2 \u0026lt;- cor(Bats_subset[,1], Bats_subset[,i+1], method=\u0026quot;pearson\u0026quot;) # calculates the correlation between activity and predictor variable Correlations[i,1] \u0026lt;- temp1 # places the variable name into row i, column 1 Correlations[i,2] \u0026lt;- temp2 # places the correlation into row i, column 2 } ## variable correlation ## 1 Area.thinned -0.40890389 ## 2 Time.since.thinned -0.02135752 ## 3 Exclusion.thinned 0.17562438 ## 4 Distance.murray.water -0.18071570 ## 5 Distance.creek.water -0.09130258 Now we can see at a glance that activity is most strongly (negatively) correlated to area thinned and that it is not at all correlated to time since thinned or mean temperature. We might then like to further investigate some of these relationships with appropriate statistical models and tests.\n###Further help DataCamp’s tutorial on loops\nYou can find some more good examples of loops, lists and if/else statements on the BEES R User group GitHub site loops and lists by Mitch. Author: Rachel V. Blakey\nLast updated:\n## [1] \u0026quot;Wed Jan 19 16:45:35 2022\u0026quot; "
},
{
	"uri": "/coding-skills/",
	"title": "Coding Skills",
	"tags": [],
	"description": "",
	"content": "  You might think having skills in computer coding is just for web site and game developers, but skills in coding are increasing valuable for environmental scientists. Running your data analyses and graphics using code means that your research methods are explicitly saved, reproducible and easily shared with colleagues or supervisors.\nOn these pages, we give some advice for writing effective code and some of the very useful coding skills that will save you lots of time.\n Good practice for writing scripts Writing simple functions\n Using loops Using Lists…coming soon Logical control…coming soon Version control  Author: Alistair Poore \u0026amp; Will Cornwell\nLast updated:\n## [1] \u0026quot;Thu Jan 20 14:28:44 2022\u0026quot; "
},
{
	"uri": "/graphics/ggplot/ggplot-colour-shapes/",
	"title": "Colours and Shapes",
	"tags": [],
	"description": "",
	"content": "  Before you get started, read the page on the basics of plotting with ggplot and install the package ggplot2.\nlibrary(ggplot2) \nIn these examples, let’s use a data set that is already in R with the length and width of floral parts for three species of iris. First, load the data set:\ndata(iris) The following plots will be used as the base code throughout of this tutorial\n* a scatter plot of petal length vs sepal length\n* a box plot of sepal length vs species\n* a frequency histogram of sepal length\nIrisPlot \u0026lt;- ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() IrisBox \u0026lt;- ggplot(iris, aes(Species, Sepal.Length, fill = Species)) + geom_boxplot() IrisHist \u0026lt;- ggplot(iris, aes(Sepal.Length)) + geom_histogram()  Changing the colour of the whole plot or its outline \nTo colour your entire plot one colour, add fill = \"colour\" or colour = \"colour\" into the brackets following the geom_... code where you specified what type of graph you want.\nNote that for most plots, fill = \"colour\" will colour the whole shape, whereas colour = \"colour\" will fill in the outline.\nFor example, to make a blue box plot with a red outline, or a yellow histogram with an green outline::\nIrisBox \u0026lt;- ggplot(iris, aes(Species, Sepal.Length)) + geom_boxplot(fill = \u0026quot;blue\u0026quot;, colour = \u0026quot;red\u0026quot;) IrisHist \u0026lt;- ggplot(iris, aes(Sepal.Length)) + geom_histogram(fill = \u0026quot;yellow\u0026quot;, colour = \u0026quot;green\u0026quot;) For scatterplots, colour = \"colour\" will specify the fill colour for the point shape.\nIrisPlot \u0026lt;- ggplot(iris, aes(Petal.Length, Sepal.Length)) + geom_point(colour = \u0026quot;red\u0026quot;)  The plots and outlines can be changed to any colour listed here. Remember to include “” before and after the colour name.  Using colour to visualise additional variables \nAdditional categorical variables\nIf you wish to colour point on a scatter plot by a third categorical variable, then add colour = variable.name within your aes brackets. This tells ggplot that this third variable will colour the points. To colour the points by the variable Species:\nIrisPlot \u0026lt;- ggplot(iris, aes(Petal.Length, Sepal.Length, colour = Species)) + geom_point()  To colour box plots or bar plots by a given categorical variable, you use you use fill = variable.name instead of colour.\nIrisBox \u0026lt;- ggplot(iris, aes(Species, Sepal.Length, fill = Species)) + geom_boxplot()  Additional continuous variables\nThe basic format for colouring a continuous variable is very similar to a categorical variable. The only real difference is you need to use + scale_colour_gradient(low = \"colour1\", high = \"colour2\"). The other colour scales will not work as they are for categorical variables. For example, here is a plot of sepal length vs petal length, with the symbols colored by their value of sepal width.\nIrisPlot.continuous \u0026lt;- ggplot(iris, aes(Petal.Length, Sepal.Length, colour = Sepal.Width)) + geom_point() print(IrisPlot.continuous) To make the gradient more effective, specify two colours within the + scale_colour_gradient brackets to represent either end of the gradient. For example:\nprint(IrisPlot.continuous + scale_colour_gradient(low = \u0026quot;black\u0026quot;, high = \u0026quot;white\u0026quot;)) print(IrisPlot.continuous + scale_colour_gradient(low = \u0026quot;darkolivegreen1\u0026quot;, high = \u0026quot;darkolivegreen\u0026quot;))  Choosing your own colours for these variables \nThis can be done in numerous ways. The basic format is to add + scale_colour_yourchoice() for scatter plots or + scale_fill_yourchoice() for box plots to the code where you ‘print’ your graph, where yourchoice() is one of several options. The syntax is:\nprint(your.basic.graph + your.theme + scale_colour_yourchoice())\nThere are numerous options for the + scale_colour_yourchoice() part.\nIndividually select colours. To manually choose colours, you can use + scale_colour_manual() or + scale_fill_manual(). For example, to choose three colours for the iris plots:\nprint(IrisPlot + scale_colour_manual(values = c(\u0026quot;Blue\u0026quot;, \u0026quot;Red\u0026quot;, \u0026quot;Green\u0026quot;))) print(IrisBox + scale_fill_manual(values = c(\u0026quot;Black\u0026quot;, \u0026quot;Orange\u0026quot;, \u0026quot;Brown\u0026quot;))) Assign tones on a greyscale. Use + scale_colour_grey() or + scale_fill_grey()\nprint(IrisPlot + scale_colour_grey()) print(IrisBox + scale_fill_grey()) Assign colours from a pre-made pallette. Use + scale_colour_brewer() or + scale_fill_brewer. To do this you will need to install the package RColorBrewer and load in R.\nlibrary(RColorBrewer) This can then be added to the end of your graph code just like the others + scale_colour_brewer(palette = \"chosen.palette\") for scatterplots and + scale_fill_brewer(palette = \"chosen.palette\") for boxplots, where \"chosen.pallete\" is one of the available palletes. For example,\nprint(IrisPlot + scale_colour_brewer(palette = \u0026quot;Dark2\u0026quot;)) print(IrisBox+ scale_fill_brewer(palette = \u0026quot;Oranges\u0026quot;))  Changing symbols in a scatterplot \nIn a simple scatterplot with no grouping variables, you can change the shape of the symbol by adding shape = ? to the geom_point() code, where ? is one of the following numbers for different shapes.\nFor example, to use a filled triangle,\nIrisPlot \u0026lt;- ggplot(iris, aes(Petal.Length, Sepal.Length)) + geom_point(shape = 17)  Different symbols can be used to group data in a scatterplot. This can be very helpful when printing in black and white or to further distinguish your categories.\nTo do this, you need to add shape = variable.name within your basic plot aes brackets, where variable.name is the name of your grouping variable. For example, to have different symbols for each species, we would use.\nIrisPlot.shape \u0026lt;- ggplot(iris, aes(Petal.Length, Sepal.Length, shape = Species)) + geom_point()  To set the symbols manually, we can use the symbol codes in scale_shape_manual() added to your print function.\nprint(IrisPlot.shape + scale_shape_manual(values = c(0, 16, 3))) This can be used with colour to further distinguish and group your variables.\nIrisPlot.shape \u0026lt;- ggplot(iris, aes(Petal.Length, Sepal.Length, shape = Species, colour = Species)) + geom_point() print(IrisPlot.shape + scale_shape_manual(values = c(0, 16, 3)) + scale_colour_manual(values = c(\u0026quot;chartreuse4\u0026quot;, \u0026quot;chocolate\u0026quot;, \u0026quot;slateblue4\u0026quot;))) ###Further help To further customise the aesthetics of the graph, including colour and formatting, see our other ggplot help pages:\naltering overall appearance.\nadding titles and axis names\nHelp on all the ggplot functions can be found at the The master ggplot help site.\nA useful cheat sheet on commonly used functions can be downloaded here.\nChang, W (2012) R Graphics cookbook. O’Reilly Media. - a guide to ggplot with quite a bit of help online here \nAuthor: Fiona Robinson Last updated:\n## [1] \u0026quot;Thu Jan 20 14:34:34 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/combining-datasets/",
	"title": "Combining datasets",
	"tags": [],
	"description": "",
	"content": "  Combining data sets is an essential task for many projects. For example, we may have data on the abundance of species, but also a data set from external sources on the environmental conditions during our observations (e.g., temperature, rainfall, elevation, vegetation type).\nWe will use the package dplyr which has many convenient functions for combining data sets, First, load the package:\nlibrary(dplyr) As with the help page for Subsetting data, we will use a dataset where bats were sampled across regrowth forest in south-eastern Australia which has been thinned to reduce the density of trees.\nWe will also read in a dataset giving geographic locations for each site (for example, downloaded from a GPS) and nightly weather data (in this case downloaded and summarised from the Bureau of Meteorology data online). If you would like to know more about downloading weather and climate data, our help on Accessing weather data in Australia.\nDownload the three sample data sets (Bats_data.csv, Geo_data.csv, and Weather_vars.csv) and import into R.\nBats \u0026lt;- read.csv(file=\u0026quot;Bats_data.csv\u0026quot;, header=T, stringsAsFactors=F) Geo \u0026lt;- read.csv(file=\u0026quot;Geo_data.csv\u0026quot;, header=T, stringsAsFactors=F) Weather \u0026lt;- read.csv(file=\u0026quot;Weather_vars.csv\u0026quot;, header=T, stringsAsFactors=F) You’ll notice that we used the argument stringsAsFactors=F. This is because the factor format can confuse the joining process, so best to leave our non-numeric columns as “character” vectors. Joining data \ndplyr has a function for simply adding all columns from one data set (z) to another (y):\nbind_cols(y,z) This is only useful if the two data sets have the same number of rows and the rows are arranged in the same order (it just matches up rows by their position).\nIn this case, we have two quite different datasets that we want to join to our main dataset on bat abundance. The data set of geographic locations has been measured at the site-scale, so each separate site has a separate measurement of latitude and longitude.\nThe second dataset with weather information has used the same weather station for all sites, but has been measured for each separate survey night. Therefore we will use the Site column to join the Geo dataset and the Date column to join the Weather dataset.\nThe function left_join will add matching rows from a second dataset onto a first, specifying which variable in the first is used to make the match.\nTo add the geographic locations to the Bats data set, using the Site column to match the rows, we would use:\nBats_withGeo \u0026lt;- left_join(Bats, Geo, by=\u0026quot;Site\u0026quot;) To now add the weather data to that new data set, using the Date variable to match rows, we would use:\nBats_withGeoWeather \u0026lt;- left_join(Bats_withGeo, Weather, by=\u0026quot;Date\u0026quot;) You can check what has happened by viewing the data set, using the function dim, to find the dimensions of our datasets, or colnames to see a list of column names.\ndim(Bats) dim(Bats_withGeoWeather) colnames(Bats_withGeo) colnames(geo.weather.join) You will see that the new dataset, Bats_withGeoWeather has the same number of rows as the original, Bats, but an additional four columns: “Latitude”, “Longitude”, “Mean_temperature” and “Mean_humidity”.  Dealing with messy datasets \nThat was a nice neat example, where we have all of the codes in our main dataset (Bats) matching up to codes in the data sets we wanted to join on. There are also a series of functions that help with messier data situations.\nLet’s simulate a couple of messy datasets. Imagine you have bat activity data for five sites and tree density data for five sites, but only two of those sites (D and E) contain measurements for both variables. This may happen when you are using datasets collected by different people or for different purposes in the same study.\nBat_sim \u0026lt;- as.data.frame(cbind(Site = c(\u0026quot;A\u0026quot;,\u0026quot;B\u0026quot;,\u0026quot;C\u0026quot;,\u0026quot;D\u0026quot;,\u0026quot;E\u0026quot;), Activity =c(62,29,30,23,24)),stringsAsFactors = F) Tree_sim \u0026lt;- as.data.frame(cbind(Site = c(\u0026quot;D\u0026quot;,\u0026quot;E\u0026quot;,\u0026quot;F\u0026quot;,\u0026quot;G\u0026quot;,\u0026quot;H\u0026quot;), Tree_density=c(525,390,477,778,817)),stringsAsFactors = F) ## Site Activity ## 1 A 62 ## 2 B 29 ## 3 C 30 ## 4 D 23 ## 5 E 24 ## Site Tree_density ## 1 D 525 ## 2 E 390 ## 3 F 477 ## 4 G 778 ## 5 H 817 If we want to combine data sets for only rows where we have both bat activity AND tree density measured and don’t care about the rest of the data, we can use inner_join.\nBat_withTree_inn.join \u0026lt;- inner_join(Bat_sim, Tree_sim, by=\u0026quot;Site\u0026quot;) print(Bat_withTree_inn.join) ## Site Activity Tree_density ## 1 D 23 525 ## 2 E 24 390 If we are interested primarily in the bat dataset, we can use left_join() as above to keep all of the bat measurements and add tree densities where we have them. The missing tree density data will be NA.\nBat_withTree_left.join \u0026lt;- left_join(Bat_sim, Tree_sim, by=\u0026quot;Site\u0026quot;) ## Site Activity Tree_density ## 1 A 62 \u0026lt;NA\u0026gt; ## 2 B 29 \u0026lt;NA\u0026gt; ## 3 C 30 \u0026lt;NA\u0026gt; ## 4 D 23 525 ## 5 E 24 390 Conversely if we are primarily interested in tree densities, we can use right_join to keep all the tree density data and include bat activity where we have measured it. The missing bat data will be NA.\nBat_withTree_right.join \u0026lt;- right_join(Bat_sim, Tree_sim, by=\u0026quot;Site\u0026quot;) ## Site Activity Tree_density ## 1 D 23 525 ## 2 E 24 390 ## 3 F \u0026lt;NA\u0026gt; 477 ## 4 G \u0026lt;NA\u0026gt; 778 ## 5 H \u0026lt;NA\u0026gt; 817 Alternatively, if we want to keep ALL of the data and decide for ourselves what to exclude later, we can use full_join.\nBat_withTree_full.join \u0026lt;- full_join(Bat_sim, Tree_sim, by=\u0026quot;Site\u0026quot;) ## Site Activity Tree_density ## 1 A 62 \u0026lt;NA\u0026gt; ## 2 B 29 \u0026lt;NA\u0026gt; ## 3 C 30 \u0026lt;NA\u0026gt; ## 4 D 23 525 ## 5 E 24 390 ## 6 F \u0026lt;NA\u0026gt; 477 ## 7 G \u0026lt;NA\u0026gt; 778 ## 8 H \u0026lt;NA\u0026gt; 817 Finally, we can interrogate which rows of our data do or don’t have matches in another table. For example, we can use semi_join to print only the rows of bat measurements that have a matching site where trees were measured, or useanti_join to find the opposite, where trees were not measured.\nBat_inTree \u0026lt;- semi_join(Bat_sim, Tree_sim, by=\u0026quot;Site\u0026quot;) ## Site Activity ## 1 D 23 ## 2 E 24 Bat_notinTree \u0026lt;- anti_join(Bat_sim, Tree_sim, by=\u0026quot;Site\u0026quot;) ## Site Activity ## 1 A 62 ## 2 B 29 ## 3 C 30 \n Further help \nThis tutorial was based on the excellent Data wrangling with dplyr and tidyr cheat sheet produced by Rstudio. Images were sourced from the same document. You can use ?dplyr to get help with this package.\nAuthor: Rachel V. Blakey\nLast updated:\n## [1] \u0026quot;Wed Jan 19 12:13:50 2022\u0026quot;  "
},
{
	"uri": "/getting-started-with-r/data-entry/",
	"title": "Data Entry",
	"tags": [],
	"description": "",
	"content": "  Data is the life-blood of science. As part of the scientific process, we invest an enormous amount of time collecting, analysing and presenting data. Before we can analyse data, however, we typically need to get it into a format that can be interpreted by others, and more importantly by the software used for analysis. Do this well and you can save yourself a lot of time; do this badly and you may end up wasting considerable time ‘cleaning’ and structuring the data to make it usable. What should a data set look like? \nMost data sets consist of rectangular tables of values (usually numbers or text). Each value belongs to a variable and an observation. A variable consists of values of the same type (e.g., temperature, duration or abundance). An observation consists of all values measured on the same unit (e.g., plot or individual). The convention is to store variables in columns and observations in rows.\nHere is an abridged data set from some insect sampling that shows you the desired format. It consists of five variables and data from the first nine replicate observations. Note the first row consists of a header listing the names of each variable in each column. The variables are:\nSite, with two possible values reflecting the habitat type (woodland or rainforest) Method, with two possible values reflecting the sampling technique (leaflitter or lighttrap) Insect, with the possible values reflecting the type of insect (ant, beetle, springtail, wasp, moth or termite). Number, with values reflecting the abundance of each insect in each observation. Group, with one possible value reflecting the identity of the collector (A, B, C etc.)   ## Site Method Insect Number Group ## 1 woodland leaflitter ant 26 A ## 2 woodland leaflitter beetle 8 A ## 3 woodland leaflitter springtail 6 A ## 4 woodland lighttrap beetle 8 A ## 5 woodland lighttrap wasp 1 A ## 6 woodland lighttrap moth 1 A ## 7 rainforest leaflitter ant 16 A ## 8 rainforest leaflitter termite 2 A ## 9 rainforest leaflitter springtail 63 A \nThis table is structured so that new data can be added with ease. For instance, we may wish to combine the data for multiple ‘collecting groups’, in which case it is straight-forward to add news rows to the existing dataset. If an additional set of samples has new insect species, we do not need to add new columns for each new species, just new values for the Insect variable. This is known as a long format. Some analyses (e.g., contrasts of species composition) will require each species as a separate column. See our Reshaping data for help on swapping between long and wide formats.  6 Golden rules of data entry \n1. Each column should contain only one type of information (i.e., text, numbers, dates, boolean). For instance, if text is inserted within or below the dataset, R or other analysis software will try to interpret the text as a value in the corresponding column. Similarly, if summary text is provided above the data (a common mistake), this will be interpreted as the first line or header of the actual data.\n2. Extensive metadata (e.g., site descriptions) should usually be documented in a separate file, but if sufficiently brief it can useful to include this information in its own column in the data table.\n3. Only use ASCII characters (upper and lower case English letters, numbers and common punctuation marks) for file names, variable names, and data values.\n4. Although it won’t affect analyses, to aid with visualisation of the raw data, it is good practise to order fixed variables first, followed by measured variables. In Table 1, Site and Method are fixed in that we know them in advance of data collection, whereas Insect and Number are measured. This, however, is not a hard and fast rule. For instance, we may want to order Group last as this information will typically be treated as metadata rather than data of actual interest for the analysis.\n5. Do not manipulate the raw data once digitized. Ideally the raw data should be treated as ‘read-only’ and any further transformations or manipulations should be done using saved R scripts (or an alternative programming language). This avoids accidentally inserting errors into the raw data each time you want to tweak something.\n6. Finally, always store data as .csv or .txt NOT .xls, .xlsx or other proprietary formats as those cannot be easily read into R or shared with collaborators. Text files do not require specific software to be read.  Further help \nOnce your data is entered in .csv or .txt format, see Importing data for help on importing into R.\nBorer, ET, EW Seabloom, MB Jones \u0026amp; M Schildhauer. 2009. Some simple guidelines for effective data management. Bulletin of the Ecological Society of America, 90: 205-214. link Wickham, H. 2014. Tidy data. Journal of Statistical Software, 59:(10). link \nAuthor: Andrew Letten Last updated:\n## [1] \u0026quot;Tue Jan 18 18:27:06 2022\u0026quot;  "
},
{
	"uri": "/graphics/multivariate-vis/heatmaps/",
	"title": "Heatmaps",
	"tags": [],
	"description": "",
	"content": "  Heatmaps are a useful method to explore large multivariate data sets. Response variables (e.g., abundances) are visualised using colour gradients or colour schemes. With the right transformation, and row and column clustering, interesting patterns within the data can be seen. They can also be used to show the results after statistical analysis, for example, to show those variables that differ between treatment groups.\nIn this tutorial, we will use heatmaps to visualise patterns in the bacterial communities found within marine habitats in the presence of two macrophytes (seagrass and Caulerpa) at two densities (sparse and dense). There are also samples from unvegetated sediment (Other). There are three replicate samples in each group.\nWe will use the package pheatmap (pretty heatmaps) to draw our heatmaps. The base package of R can draw heatmaps as well, but is somewhat limited. First, install the package and load into R. We will also need the package dplyr for selecting rows and columns.\nlibrary(pheatmap) library(dplyr) \nReading in the data \nWith multivariate data, we often have two data frames with 1) the counts per sample and 2) the factors that group samples. Download these two data files, Bac.counts.csv and Bac.factors.csv, and import into R.\nBac.counts \u0026lt;- read.csv(file = \u0026quot;Bac.counts.csv\u0026quot;, header = TRUE, row.names=1) Bac.factors \u0026lt;- read.csv(file = \u0026quot;Bac.factors.csv\u0026quot;, header = TRUE, row.names=1) The row.names=1 argument assigns the first column of the spreadsheet as row names in the data frame. We should check the data structure of the counts using the head command. Given there are many columns, we’ll only check the first 10 using indexing (use of [,] after the object, with row numbers before the comma and column numbers after).\nhead(Bac.counts[,1:10])  DC1 DC2 DC3 DS1 DS2 DS3 SC1 SC2 SC3 SS1 Otu00002 2906 2619 2200 2959 3205 2455 2815 2761 2275 3519 Otu00003 1631 1323 1258 1055 1552 1509 1345 1255 1270 1180 Otu00005 1493 1416 1592 984 1131 879 1430 1448 1296 1431 Otu00004 1171 1164 1489 936 1514 1174 1271 1310 1207 1278 Otu00006 1160 1226 1245 764 1134 1271 906 983 1110 1251 Otu00007 1112 1042 1211 1060 1155 1103 1283 1198 1175 1485 We can see that the row names of the data have the code numbers for each operational taxonomic unit (OTU) of bacteria and there are integer counts of these in each sample. Now, we will check the dimensions of the data (number of rows and columns).\ndim(Bac.counts) [1] 4299 15 There 4299 bacterial operational taxonomic units (OTUs) as rows among 15 samples as columns.\nNext we can check the structure of the factor information using str. In this experiment, samples are categorised by a treatment ID (each combination of density and species), density levels and species levels. The other columns are for plotting purposes elsewhere.\nstr(Bac.factors) \u0026#39;data.frame\u0026#39;: 15 obs. of 6 variables: $ Treatment_ID: chr \u0026quot;DC\u0026quot; \u0026quot;DC\u0026quot; \u0026quot;DC\u0026quot; \u0026quot;DS\u0026quot; ... $ Density : chr \u0026quot;Dense\u0026quot; \u0026quot;Dense\u0026quot; \u0026quot;Dense\u0026quot; \u0026quot;Dense\u0026quot; ... $ Species : chr \u0026quot;Caulerpa\u0026quot; \u0026quot;Caulerpa\u0026quot; \u0026quot;Caulerpa\u0026quot; \u0026quot;Seagrass\u0026quot; ... $ pch1 : int 16 16 16 15 15 15 21 21 21 22 ... $ pch2 : int 4 22 21 15 16 NA NA NA NA NA ... $ legend : chr \u0026quot;U - Unvegetated\u0026quot; \u0026quot;SZ - Sparse Zostera \u0026quot; \u0026quot;SC - Sparse Caulerpa\u0026quot; \u0026quot;DS - Dense Zostera\u0026quot; ... \n Drawing a heatmap \nThe basic function is pheatmap. Let’s try it without special arguments, except that we will only look at the first 500 OTUs (they are arranged from highest to lowest total abundance already). The function slice in dplyr can take any subset of numbered rows (see Subsetting data).\nBac.counts500 \u0026lt;- slice(Bac.counts, 1:500) pheatmap(Bac.counts500) In the figure, samples are columns and bacterial OTUs are rows, with the colour representing the range of counts of each OTU in each sample. Red means most abundant (~3500 counts), blue the least abundant (0 counts) and light yellow somewhere in the middle. Note that both the rows and columns have been rearranged based on measures of similarity among rows and columns (see Cluster analysis).\nData transformation. Now you might notice that we have a scale issue. The data are full of rare-ish bacteria (blue) and that is all we can see on the heatmap. To visualise this more effectively, we can try a log10 transformation with + 1 constant to deal with zeros.\nBac.Log10.counts500 \u0026lt;- log10(Bac.counts500 + 1) pheatmap(Bac.Log10.counts500) The view of the data has really changed with transformation, so has the row and column clustering. There appears to be some very abundant OTUs (red/yellow), some mid abundant (white/low) and low in low abundance (blue).\nThis would not have been seen so clearly if we did not cluster the rows and columns, and if we had just plotted them “as is” from the data table (although some row ordering had already been done here). You can see this if we draw the heatmap again without clustering the rows and columns.\npheatmap(Bac.Log10.counts500, cluster_rows = FALSE, cluster_cols = FALSE)  Colouring sample groups \nBefore looking further at how clustering effects the patterns observed, we should add some colours associated with the treatment groups next. The simplest method is to use the Bac.factors dataframe as input, taking care that you 1) specify categorical covariates (factor groups) and numerical covariates (e.g. concentration) properly, 2) that row names in Bac.factors match those in Bac.counts, and 3) then remove the factors you do not want to show.\nTo extract just the density and species columns from our factors data frame, we can use select from the package dplyr and then use these to colour code our samples.\nBac.factorsDS \u0026lt;- select(Bac.factors, Density, Species) pheatmap(Bac.Log10.counts500, annotation_col = Bac.factorsDS) The colours are pretty ugly. To make your own is tricky, but involves making named colour vectors and then adding them to a list. This represents the “colour annotation” information. We have to define colours for categorical covariate (factor groups) and colour ranges for numerical covariates (e.g. concentration).\n# Reorder Density levels to Sparse, Dense, Other Bac.factorsDS$Density = factor(Bac.factorsDS$Density, levels = c(\u0026quot;Sparse\u0026quot;, \u0026quot;Dense\u0026quot;, \u0026quot;Other\u0026quot;)) DensityCol \u0026lt;- c(\u0026quot;darkorchid\u0026quot;, \u0026quot;darkorange\u0026quot;, \u0026quot;grey80\u0026quot;) names(DensityCol) \u0026lt;- levels(Bac.factorsDS$Density) # Reorder Species to Seagrass, Caulerpa, Other Bac.factorsDS$Species \u0026lt;- factor(Bac.factorsDS$Species, levels = c(\u0026quot;Seagrass\u0026quot;, \u0026quot;Caulerpa\u0026quot;, \u0026quot;Other\u0026quot;)) SpeciesCol \u0026lt;- c(\u0026quot;forestgreen\u0026quot;, \u0026quot;blue3\u0026quot;, \u0026quot;grey80\u0026quot;) names(SpeciesCol) \u0026lt;- levels(Bac.factorsDS$Species) # Add to a list, where names match those in factors dataframe AnnColour \u0026lt;- list( Density = DensityCol, Species = SpeciesCol) # Check the output AnnColour $Density Sparse Dense Other \u0026quot;darkorchid\u0026quot; \u0026quot;darkorange\u0026quot; \u0026quot;grey80\u0026quot; $Species Seagrass Caulerpa Other \u0026quot;forestgreen\u0026quot; \u0026quot;blue3\u0026quot; \u0026quot;grey80\u0026quot;  We can now redraw the heatmap with our chosen colours.\npheatmap(Bac.Log10.counts500, annotation_col = Bac.factorsDS, annotation_colors = AnnColour) In this case, letting the data speak for itself (with default row and column clustering) shows that the unvegetated samples (Other) are dissimilar to the macrophyte samples (regardless of density) and that the seagrass samples generally cluster together. Note that other methods (e.g., ordination) can show sample to sample comparisons much better than heatmaps, but heatmaps reveal the patterns of the variables unlike those methods. Understanding what the data is doing is often overlooked in multivariate analysis.  Row and column clustering methods \nBy default, pheatmap is using Euclidean distance as the similarity measure and clustering samples based on the ‘complete’ method. There are various other distance and clustering methods available by using additional arguments: clustering_distance_rows, clustering_distance_cols and clustering_method.\nSome are better than others, but you’ll have to consult the literature further on this. For clustering, however, ‘average’ clustering seems superior in many computer science applications. Again, the benefit of heatmaps is that you see what the data are doing relative to the options you have chosen.\nLet’s see what is produced by using the Manhattan distance as the measure of similarity between rows and columns, and the average clustering method.\npheatmap(Bac.Log10.counts500, clustering_distance_rows = \u0026quot;manhattan\u0026quot;, clustering_distance_cols = \u0026quot;manhattan\u0026quot;, clustering_method = \u0026#39;average\u0026#39;, annotation_colors = AnnColour, annotation_col = Bac.factorsDS) You can see that changing the clustering has significantly changed the heatmap produced.  Scaling variables \nWe may want to compare the abundance of each bacterial OTU only among samples rather than contrasting their abundance with other OTUs of varying abundance. To do this, we can scale the abundances within each OTU such that the colour scale shows only the relative range of abundance for each individual OTU. In this example, that involves scaling abundance for each row with scale=\"row\".\npheatmap(Bac.Log10.counts500, scale = \u0026quot;row\u0026quot;, clustering_distance_rows = \u0026quot;manhattan\u0026quot;, clustering_method = \u0026#39;average\u0026#39;, annotation_colors = AnnColour, annotation_col = Bac.factorsDS) We can now see how many standard deviations the Log10 abundance of a single OTU is away from the mean for that OTU in a sample compared only with other samples for that OTU. The legend shows that the number of standard deviations ranges from +3 to -3. We can see how a number of the bacterial OTUs are under-represented in the in the unvegetated sediment (blue abundances in the bottom left) compared with the sediment with macrophytes (yellow/red abundances).  Sorting by group \nWe can also sort the samples by their groups or treatments rather than sorting by similarity among rows or columns. This is done by ordering the input data and turning off the clustering of the columns with cluster_cols=FALSE.\nSampleOrder = order(Bac.factorsDS$Species, Bac.factorsDS$Density) pheatmap(Bac.Log10.counts500[ , SampleOrder], cluster_cols = FALSE, clustering_method = \u0026#39;average\u0026#39;, annotation_colors = AnnColour, annotation_col = Bac.factorsDS)  Using heatmaps after statistical analyses \nIf we have analysed our multivariate data and identified those variables that differed between treatments, we can choose to plot only them in the heatmap. In this example, we will only look at those bacterial OTUs that differed between the two levels of the Species factor after removal of the unvegetated samples.\nWe will analyse the abundances of all OTUs with multivariate generalised linear models using the function manyglm in the package mvabund. The specifics of that analysis are not described further here (see the Introduction to mvabund for help with that package). Note that running anova.manyglm is quite slow.\n# Create factor and data file without the U1, U2 and U3 samples Bac.factorsDS_noU \u0026lt;- filter(Bac.factors, Treatment_ID != \u0026quot;U\u0026quot;) Bac.counts500DS_noU \u0026lt;- select(Bac.counts500, -contains(\u0026quot;U\u0026quot;)) # Mvabund library(mvabund) dat.mva \u0026lt;- mvabund(t(Bac.counts500DS_noU)) plot(dat.mva) dat.nb \u0026lt;- manyglm(dat.mva ~ Species * Density, data = Bac.factorsDS_noU) dat.aov \u0026lt;- anova.manyglm(dat.nb, p.uni = \u0026quot;unadjusted\u0026quot;, nBoot = 500) dat.aov$uni.p[ ,1:5] SpeciesDiffs \u0026lt;- which(dat.aov$uni.p[\u0026quot;Species\u0026quot;,] \u0026lt; 0.05 \u0026amp; dat.aov$uni.p[\u0026quot;Species:Density\u0026quot;,] \u0026gt; 0.05) We can include the argument cutree for the rows and columns, to split data into the two expected groups. Fingers crossed it shows that we expect.\n# Create a vector that will be used to select samples that are not from the sediment DS = Bac.factors$Treatment_ID != \u0026quot;U\u0026quot; pheatmap(Bac.Log10.counts500[SpeciesDiffs, DS], scale = \u0026quot;row\u0026quot;, clustering_method = \u0026#39;average\u0026#39;, annotation_col = Bac.factorsDS, cutree_rows = 2, cutree_cols = 2) And the results are as expected. The top half of the heatmap shows those variables over-represented in the Species level Caulerpa. The bottom half are those over-represented in seagrass.\nHappy heatmapping!\n Further help \nType ?pheatmap for the R help on this function. Author: Shaun Nielsen Last updated:\n[1] \u0026quot;Thu Jan 20 14:38:08 2022\u0026quot;  "
},
{
	"uri": "/statistics/mixed-models/",
	"title": "Mixed Models",
	"tags": [],
	"description": "",
	"content": "  Mixed models are those with a mixture of fixed and random effects. Random effects are categorical factors where the levels have been selected from many possible levels and the investigator would like to make inferences beyond just the levels chosen. Tricky concept, but imagine contrasting two habitat types (forest and grassland) by sampling five sites within each, and five replicate measures within each site. Habitat type is a fixed factor with the researcher only interested in those two levels of habitat type. If the five sites were chosen from a larger collection of possible sites, then site is considered a random effect with 10 levels.\n Mixed models 1: Linear mixed models with one random effect\n Mixed models 2: Linear mixed models with several random effects\n Mixed models 3: Generalised linear mixed models  Photo: N. Murray\n"
},
{
	"uri": "/graphics/multivariate-vis/",
	"title": "Multivariate Data",
	"tags": [],
	"description": "",
	"content": "  R has a very wide range of functions and packages for visualising multivariate data. Here is some help for some of the more commonly used techniques:\n multidimensional scaling\n principal componenents analysis\n cluster analysis  "
},
{
	"uri": "/graphics/spatial-vis/basic-raster/",
	"title": "The Basics of Rasters",
	"tags": [],
	"description": "",
	"content": "             Being able to produce interactive maps on the fly can greatly speed up exploratory analysis and is a useful tool for displaying data that would be less informative on a static map.\nLeaflet is an open source JavaScript library that is used to create interactive maps on websites. In this post we will look at the the leaflet R package and create some cool interactive maps!\nInstallation The leaflet R package can be installed from CRAN by running:\ninstall.packages(\u0026quot;leaflet\u0026quot;)  Basics Creating a basic interactive map is simple!\nlibrary(leaflet) leaflet() %\u0026gt;% addTiles()  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]}]},\"evals\":[],\"jsHooks\":[]} The Leaflet R package has been designed to be used with pipes (%\u0026gt;%), which makes it easy to add layers and controls such as a scale bar and a mini map.\nMost of the time however we will have an area or a study site that we are interested in that we want to view:\nleaflet() %\u0026gt;% addTiles() %\u0026gt;% addScaleBar() %\u0026gt;% setView(lng = 151.2, lat = -33.86, zoom = 10) %\u0026gt;% addMiniMap()  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addMiniMap\",\"args\":[null,null,\"bottomright\",150,150,19,19,-5,false,false,false,false,false,false,{\"color\":\"#ff7800\",\"weight\":1,\"clickable\":false},{\"color\":\"#000000\",\"weight\":1,\"clickable\":false,\"opacity\":0,\"fillOpacity\":0},{\"hideText\":\"Hide MiniMap\",\"showText\":\"Show MiniMap\"},[]]}],\"setView\":[[-33.86,151.2],10,[]]},\"evals\":[],\"jsHooks\":[]}  Markers Lets plot some species occurence data from GBIF using the rgbif package: We will be displaying all eucalypt observations within the Macquarie Marshes region:\n## Getting the data # install.packages(\u0026#39;gbif\u0026#39;) library(rgbif) gbif_query \u0026lt;- occ_search(genusKey = 7493935, geometry = rgbif::gbif_bbox2wkt(minx = 147.8,miny = -30.6,maxx = 147.4,maxy = -31)) euc \u0026lt;- gbif_query$data euc$label \u0026lt;- paste(euc$name, \u0026#39;|\u0026#39;, euc$vernacularName, \u0026#39;|\u0026#39;, euc$year, \u0026#39;-\u0026#39;, month.abb[euc$month]) ## Warning: Unknown or uninitialised column: `vernacularName`. ## Creating a map base \u0026lt;- leaflet() %\u0026gt;% addTiles() %\u0026gt;% addScaleBar() %\u0026gt;% setView(lat = mean(euc$decimalLatitude), lng = mean(euc$decimalLongitude), zoom = 10) base %\u0026gt;% addMarkers(lng = euc$decimalLongitude, lat = euc$decimalLatitude, label = euc$label)  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addMarkers\",\"args\":[[-30.750814,-30.703291,-30.604462,-30.604462,-30.769092,-30.921591,-30.703291,-30.601113,-30.703291,-30.810721,-30.815145,-30.753627,-30.640037,-30.60431,-30.921591,-30.945585,-30.753627,-30.719613,-30.753627,-30.601113,-30.719613,-30.766362,-30.767348,-30.704111,-30.704111,-30.656114,-30.65522,-30.766121,-30.921591,-30.660411,-30.701996,-30.718844,-30.766362,-30.656114,-30.750814,-30.656114,-30.753627,-30.937148,-30.604462,-30.719613,-30.60431,-30.954014,-30.60431,-30.704111,-30.927857,-30.879618,-30.814503,-30.939658,-30.813377,-30.930152,-30.930152,-30.928292,-30.939658,-30.91317,-30.791342,-30.729886,-30.604363,-30.802549,-30.729886,-30.937148,-30.703291,-30.91317,-30.60431,-30.766362,-30.640037,-30.701996,-30.753627,-30.767348,-30.766362,-30.753627,-30.815145,-30.769092,-30.753627,-30.814503,-30.766362,-30.704111,-30.810721,-30.766121,-30.604462,-30.601113,-30.921591,-30.813377,-30.604462,-30.750814,-30.616533,-30.659222,-30.618136,-30.701186,-30.957967,-30.623736,-30.698339,-30.616533,-30.911464,-30.980719,-30.701186,-30.967936,-30.985558,-30.65522,-30.879618,-30.954014,-30.718844,-30.719613,-30.656114,-30.930152,-30.660411,-30.928292,-30.945585,-30.927857,-30.921452,-30.769092,-30.655197,-30.660409,-30.769092,-30.766392,-30.655197,-30.655197,-30.766392,-30.921452,-30.701973,-30.766392,-30.937037,-30.604462,-30.753627,-30.640037,-30.656114,-30.703291,-30.60431,-30.921591,-30.815145,-30.601113,-30.718844,-30.767348,-30.937148,-30.769092,-30.753627,-30.753627,-30.719613,-30.813377,-30.703291,-30.750814,-30.766362,-30.718844,-30.704111,-30.769092,-30.719613,-30.766362,-30.815145,-30.814503,-30.810721,-30.604462,-30.640037,-30.815145,-30.766362,-30.60431,-30.750814,-30.65522,-30.660411,-30.701996,-30.749466,-30.766121,-30.921591,-30.750814,-30.704111,-30.704082,-30.754485,-30.766131,-30.829983,-30.76399,-30.700046,-30.704082,-30.766225,-30.761738,-30.76399,-30.791342,-30.930152,-30.939658,-30.930152,-30.930152,-30.928292,-30.879618,-30.939658,-30.91317,-30.656114,-30.945585,-30.945585,-30.656114,-30.601113,-30.65522,-30.766362,-30.815145,-30.640037,-30.703291,-30.921591,-30.939658,-30.814503,-30.815145,-30.753627,-30.660411,-30.91317,-30.939658,-30.767348,-30.60431,-30.750814,-30.719613,-30.604462,-30.945585,-30.704111,-30.703291,-30.753627,-30.769092,-30.656114,-30.750814,-30.704111,-30.767348,-30.701996,-30.939658,-30.928292,-30.815145,-30.60431,-30.719613,-30.921591,-30.928292,-30.750814,-30.766121,-30.813377,-30.753627,-30.704111,-30.640037,-30.930152,-30.604462,-30.930152,-30.703291,-30.810721,-30.937148,-30.954014,-30.930152,-30.750814,-30.601113,-30.921591,-30.701996,-30.769092,-30.766362,-30.954014,-30.640037,-30.766362,-30.649431,-30.767348,-30.767348,-30.704111,-30.769092,-30.750814,-30.921591,-30.813377,-30.954014,-30.945585,-30.939658,-30.601113,-30.814503,-30.719613,-30.704111,-30.810721,-30.640037,-30.766362,-30.719613,-30.750814,-30.60431,-30.766121,-30.937148,-30.604462,-30.753627,-30.928292,-30.604462,-30.930152,-30.753627,-30.814503,-30.945585,-30.945585,-30.939658,-30.753627,-30.703291,-30.703291,-30.810721,-30.815145,-30.815145,-30.815145,-30.814503,-30.814503,-30.753627,-30.769092,-30.945585,-30.937148,-30.704111,-30.767348,-30.930152,-30.769092,-30.704111,-30.945585,-30.753627,-30.640037,-30.807249,-30.719613,-30.928292,-30.954014,-30.813377,-30.939658,-30.719613,-30.921591,-30.91317,-30.921591,-30.939658,-30.704111,-30.930152,-30.703291,-30.906377,-30.791342,-30.766362,-30.649431,-30.703291,-30.769092,-30.719613,-30.701996,-30.750814,-30.753627,-30.766121,-30.813377,-30.60431,-30.656114,-30.640037,-30.921591,-30.719613,-30.750814,-30.65522,-30.769092,-30.719613,-30.939658,-30.604462,-30.815145,-30.939658,-30.750814,-30.930152,-30.937148,-30.815145,-30.601113,-30.769092,-30.814503,-30.814503,-30.656114,-30.60431,-30.604462,-30.928292,-30.701996,-30.704111,-30.704111,-30.753627,-30.791342,-30.703291,-30.766121,-30.704111,-30.879618,-30.703291,-30.766612,-30.82503,-30.839146,-30.840318,-30.769828,-30.766362,-30.939658,-30.928292,-30.930152,-30.930152,-30.719613,-30.766121,-30.767348,-30.939658,-30.767348,-30.879618,-30.928292,-30.766371,-30.879618,-30.767267,-30.766371,-30.719613,-30.930152,-30.930152,-30.928292,-30.939676,-30.928292,-30.879618,-30.939676,-30.767267,-30.930152,-30.767267,-30.719613,-30.939676,-30.938446,-30.928292,-30.767267,-30.907631,-30.907631,-30.907113,-30.907113,-30.908284,-30.806428,-30.806428,-30.7957,-30.7957,-30.7957,-30.795688,-30.795688,-30.795688,-30.795688,-30.845656,-30.845726,-30.845656,-30.796766,-30.796766,-30.797001,-30.797001,-30.663997,-30.675933,-30.671777,-30.766594,-30.840372,-30.839,-30.766594,-30.839,-30.840372,-30.769828,-30.769828,-30.845441,-30.840318,-30.839146,-30.813377,-30.906377,-30.921591,-30.701996,-30.906377,-30.937148,-30.906377,-30.813377,-30.813377,-30.906377,-30.906377,-30.906377,-30.719613,-30.703291,-30.704111,-30.793352,-30.791342,-30.640037,-30.704111,-30.810721,-30.793452,-30.719613,-30.791342,-30.719613,-30.791342,-30.810721,-30.810721,-30.793452,-30.939658,-30.750814,-30.807249,-30.753627,-30.930152,-30.750814,-30.766121,-30.930152,-30.769092,-30.753627,-30.928292,-30.769092,-30.767348,-30.766362,-30.879618,-30.879618,-30.928292,-30.91317,-30.750814,-30.939658,-30.807249,-30.930152,-30.767267,-30.769137,-30.767267,-30.928292,-30.930152,-30.928292,-30.879618,-30.928292,-30.879618,-30.750813,-30.750813,-30.750813,-30.91272,-30.766371,-30.879618,-30.939676,-30.939676,-30.938446],[147.524845,147.5079,147.575984,147.575984,147.50976,147.543892,147.5079,147.567942,147.5079,147.513252,147.519486,147.544951,147.507757,147.577683,147.543892,147.582867,147.544951,147.591508,147.544951,147.567942,147.591508,147.526873,147.526178,147.508332,147.508332,147.587646,147.59574,147.539285,147.543892,147.597285,147.504593,147.597822,147.526873,147.587646,147.524845,147.587646,147.544951,147.566548,147.575984,147.591508,147.577683,147.578437,147.577683,147.508332,147.733051,147.687375,147.519597,147.741201,147.507903,147.727688,147.727688,147.734331,147.741201,147.504285,147.714527,147.497054,147.506215,147.4692,147.497054,147.566548,147.5079,147.504285,147.577683,147.526873,147.507757,147.504593,147.544951,147.526178,147.526873,147.544951,147.519486,147.50976,147.544951,147.519597,147.526873,147.508332,147.513252,147.539285,147.575984,147.567942,147.543892,147.507903,147.575984,147.524845,147.510589,147.494828,147.512542,147.502992,147.488953,147.505233,147.502228,147.510589,147.554778,147.481078,147.502992,147.479569,147.481461,147.59574,147.687375,147.578437,147.597822,147.591508,147.587646,147.727688,147.597285,147.734331,147.582867,147.733051,147.543637,147.50976,147.595752,147.597311,147.50976,147.526831,147.595752,147.595752,147.526831,147.543637,147.5046,147.526831,147.566653,147.575984,147.544951,147.507757,147.587646,147.5079,147.577683,147.543892,147.519486,147.567942,147.597822,147.526178,147.566548,147.50976,147.544951,147.544951,147.591508,147.507903,147.5079,147.524845,147.526873,147.597822,147.508332,147.50976,147.591508,147.526873,147.519486,147.519597,147.513252,147.575984,147.507757,147.519486,147.526873,147.577683,147.524845,147.59574,147.597285,147.504593,147.525694,147.539285,147.543892,147.524845,147.508332,147.508315,147.548517,147.539278,147.531095,147.510815,147.511105,147.508315,147.537397,147.562657,147.510815,147.714527,147.727688,147.741201,147.727688,147.727688,147.734331,147.687375,147.741201,147.504285,147.587646,147.582867,147.582867,147.587646,147.567942,147.59574,147.526873,147.519486,147.507757,147.5079,147.543892,147.741201,147.519597,147.519486,147.544951,147.597285,147.504285,147.741201,147.526178,147.577683,147.524845,147.591508,147.575984,147.582867,147.508332,147.5079,147.544951,147.50976,147.587646,147.524845,147.508332,147.526178,147.504593,147.741201,147.734331,147.519486,147.577683,147.591508,147.543892,147.734331,147.524845,147.539285,147.507903,147.544951,147.508332,147.507757,147.727688,147.575984,147.727688,147.5079,147.513252,147.566548,147.578437,147.727688,147.524845,147.567942,147.543892,147.504593,147.50976,147.526873,147.578437,147.507757,147.526873,147.519193,147.526178,147.526178,147.508332,147.50976,147.524845,147.543892,147.507903,147.578437,147.582867,147.741201,147.567942,147.519597,147.591508,147.508332,147.513252,147.507757,147.526873,147.591508,147.524845,147.577683,147.539285,147.566548,147.575984,147.544951,147.734331,147.575984,147.727688,147.544951,147.519597,147.582867,147.582867,147.741201,147.544951,147.5079,147.5079,147.513252,147.519486,147.519486,147.519486,147.519597,147.519597,147.544951,147.50976,147.582867,147.566548,147.508332,147.526178,147.727688,147.50976,147.508332,147.582867,147.544951,147.507757,147.674262,147.591508,147.734331,147.578437,147.507903,147.741201,147.591508,147.543892,147.504285,147.543892,147.741201,147.508332,147.727688,147.5079,147.484995,147.714527,147.526873,147.519193,147.5079,147.50976,147.591508,147.504593,147.524845,147.544951,147.539285,147.507903,147.577683,147.587646,147.507757,147.543892,147.591508,147.524845,147.59574,147.50976,147.591508,147.741201,147.575984,147.519486,147.741201,147.524845,147.727688,147.566548,147.519486,147.567942,147.50976,147.519597,147.519597,147.587646,147.577683,147.575984,147.734331,147.504593,147.508332,147.508332,147.544951,147.714527,147.5079,147.539285,147.508332,147.687375,147.5079,147.527501,147.524892,147.545978,147.541843,147.524373,147.526873,147.741201,147.734331,147.727688,147.727688,147.591508,147.539285,147.526178,147.741201,147.526178,147.687375,147.734331,147.526873,147.687375,147.526177,147.526873,147.591508,147.727688,147.727688,147.734331,147.741128,147.734331,147.687375,147.741128,147.526177,147.727688,147.526177,147.591508,147.741128,147.746331,147.734331,147.526177,147.485054,147.485054,147.486066,147.486066,147.489054,147.501229,147.501229,147.489142,147.489142,147.489142,147.490083,147.490083,147.490083,147.490083,147.49087,147.491414,147.49087,147.471744,147.471744,147.471724,147.471724,147.729068,147.75321,147.749409,147.527449,147.541864,147.546322,147.527449,147.546322,147.541864,147.524373,147.524373,147.542332,147.541843,147.545978,147.507903,147.484995,147.543892,147.504593,147.484995,147.566548,147.484995,147.507903,147.507903,147.484995,147.484995,147.484995,147.591508,147.5079,147.508332,147.706651,147.714527,147.507757,147.508332,147.513252,147.706641,147.591508,147.714527,147.591508,147.714527,147.513252,147.513252,147.706641,147.741201,147.524845,147.674262,147.544951,147.727688,147.524845,147.539285,147.727688,147.50976,147.544951,147.734331,147.50976,147.526178,147.526873,147.687375,147.687375,147.734331,147.504285,147.524845,147.741201,147.674262,147.727688,147.526177,147.509761,147.526177,147.734331,147.727688,147.734331,147.687375,147.734331,147.687375,147.525054,147.525054,147.525054,147.608935,147.526873,147.687375,147.741128,147.741128,147.746331],null,null,null,{\"interactive\":true,\"draggable\":false,\"keyboard\":true,\"title\":\"\",\"alt\":\"\",\"zIndexOffset\":0,\"opacity\":1,\"riseOnHover\":false,\"riseOffset\":250},null,null,null,null,[\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus largiflorens F.Muell. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus populnea F.Muell. | | 2017 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus populnea F.Muell. | | 2014 - May\",\"Eucalyptus largiflorens F.Muell. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus largiflorens F.Muell. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]}],\"setView\":[[-30.789030468,147.570597894],10,[]],\"limits\":{\"lat\":[-30.985558,-30.601113],\"lng\":[147.4692,147.75321]}},\"evals\":[],\"jsHooks\":[]}  Clustering markers Nice! but it is a bit cluttered, we can add clustering by specifying the clusterOptions argument to try and solve this issue:\nbase %\u0026gt;% addMarkers(lng = euc$decimalLongitude, lat = euc$decimalLatitude, clusterOptions = markerClusterOptions(), label = euc$label)  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addMarkers\",\"args\":[[-30.750814,-30.703291,-30.604462,-30.604462,-30.769092,-30.921591,-30.703291,-30.601113,-30.703291,-30.810721,-30.815145,-30.753627,-30.640037,-30.60431,-30.921591,-30.945585,-30.753627,-30.719613,-30.753627,-30.601113,-30.719613,-30.766362,-30.767348,-30.704111,-30.704111,-30.656114,-30.65522,-30.766121,-30.921591,-30.660411,-30.701996,-30.718844,-30.766362,-30.656114,-30.750814,-30.656114,-30.753627,-30.937148,-30.604462,-30.719613,-30.60431,-30.954014,-30.60431,-30.704111,-30.927857,-30.879618,-30.814503,-30.939658,-30.813377,-30.930152,-30.930152,-30.928292,-30.939658,-30.91317,-30.791342,-30.729886,-30.604363,-30.802549,-30.729886,-30.937148,-30.703291,-30.91317,-30.60431,-30.766362,-30.640037,-30.701996,-30.753627,-30.767348,-30.766362,-30.753627,-30.815145,-30.769092,-30.753627,-30.814503,-30.766362,-30.704111,-30.810721,-30.766121,-30.604462,-30.601113,-30.921591,-30.813377,-30.604462,-30.750814,-30.616533,-30.659222,-30.618136,-30.701186,-30.957967,-30.623736,-30.698339,-30.616533,-30.911464,-30.980719,-30.701186,-30.967936,-30.985558,-30.65522,-30.879618,-30.954014,-30.718844,-30.719613,-30.656114,-30.930152,-30.660411,-30.928292,-30.945585,-30.927857,-30.921452,-30.769092,-30.655197,-30.660409,-30.769092,-30.766392,-30.655197,-30.655197,-30.766392,-30.921452,-30.701973,-30.766392,-30.937037,-30.604462,-30.753627,-30.640037,-30.656114,-30.703291,-30.60431,-30.921591,-30.815145,-30.601113,-30.718844,-30.767348,-30.937148,-30.769092,-30.753627,-30.753627,-30.719613,-30.813377,-30.703291,-30.750814,-30.766362,-30.718844,-30.704111,-30.769092,-30.719613,-30.766362,-30.815145,-30.814503,-30.810721,-30.604462,-30.640037,-30.815145,-30.766362,-30.60431,-30.750814,-30.65522,-30.660411,-30.701996,-30.749466,-30.766121,-30.921591,-30.750814,-30.704111,-30.704082,-30.754485,-30.766131,-30.829983,-30.76399,-30.700046,-30.704082,-30.766225,-30.761738,-30.76399,-30.791342,-30.930152,-30.939658,-30.930152,-30.930152,-30.928292,-30.879618,-30.939658,-30.91317,-30.656114,-30.945585,-30.945585,-30.656114,-30.601113,-30.65522,-30.766362,-30.815145,-30.640037,-30.703291,-30.921591,-30.939658,-30.814503,-30.815145,-30.753627,-30.660411,-30.91317,-30.939658,-30.767348,-30.60431,-30.750814,-30.719613,-30.604462,-30.945585,-30.704111,-30.703291,-30.753627,-30.769092,-30.656114,-30.750814,-30.704111,-30.767348,-30.701996,-30.939658,-30.928292,-30.815145,-30.60431,-30.719613,-30.921591,-30.928292,-30.750814,-30.766121,-30.813377,-30.753627,-30.704111,-30.640037,-30.930152,-30.604462,-30.930152,-30.703291,-30.810721,-30.937148,-30.954014,-30.930152,-30.750814,-30.601113,-30.921591,-30.701996,-30.769092,-30.766362,-30.954014,-30.640037,-30.766362,-30.649431,-30.767348,-30.767348,-30.704111,-30.769092,-30.750814,-30.921591,-30.813377,-30.954014,-30.945585,-30.939658,-30.601113,-30.814503,-30.719613,-30.704111,-30.810721,-30.640037,-30.766362,-30.719613,-30.750814,-30.60431,-30.766121,-30.937148,-30.604462,-30.753627,-30.928292,-30.604462,-30.930152,-30.753627,-30.814503,-30.945585,-30.945585,-30.939658,-30.753627,-30.703291,-30.703291,-30.810721,-30.815145,-30.815145,-30.815145,-30.814503,-30.814503,-30.753627,-30.769092,-30.945585,-30.937148,-30.704111,-30.767348,-30.930152,-30.769092,-30.704111,-30.945585,-30.753627,-30.640037,-30.807249,-30.719613,-30.928292,-30.954014,-30.813377,-30.939658,-30.719613,-30.921591,-30.91317,-30.921591,-30.939658,-30.704111,-30.930152,-30.703291,-30.906377,-30.791342,-30.766362,-30.649431,-30.703291,-30.769092,-30.719613,-30.701996,-30.750814,-30.753627,-30.766121,-30.813377,-30.60431,-30.656114,-30.640037,-30.921591,-30.719613,-30.750814,-30.65522,-30.769092,-30.719613,-30.939658,-30.604462,-30.815145,-30.939658,-30.750814,-30.930152,-30.937148,-30.815145,-30.601113,-30.769092,-30.814503,-30.814503,-30.656114,-30.60431,-30.604462,-30.928292,-30.701996,-30.704111,-30.704111,-30.753627,-30.791342,-30.703291,-30.766121,-30.704111,-30.879618,-30.703291,-30.766612,-30.82503,-30.839146,-30.840318,-30.769828,-30.766362,-30.939658,-30.928292,-30.930152,-30.930152,-30.719613,-30.766121,-30.767348,-30.939658,-30.767348,-30.879618,-30.928292,-30.766371,-30.879618,-30.767267,-30.766371,-30.719613,-30.930152,-30.930152,-30.928292,-30.939676,-30.928292,-30.879618,-30.939676,-30.767267,-30.930152,-30.767267,-30.719613,-30.939676,-30.938446,-30.928292,-30.767267,-30.907631,-30.907631,-30.907113,-30.907113,-30.908284,-30.806428,-30.806428,-30.7957,-30.7957,-30.7957,-30.795688,-30.795688,-30.795688,-30.795688,-30.845656,-30.845726,-30.845656,-30.796766,-30.796766,-30.797001,-30.797001,-30.663997,-30.675933,-30.671777,-30.766594,-30.840372,-30.839,-30.766594,-30.839,-30.840372,-30.769828,-30.769828,-30.845441,-30.840318,-30.839146,-30.813377,-30.906377,-30.921591,-30.701996,-30.906377,-30.937148,-30.906377,-30.813377,-30.813377,-30.906377,-30.906377,-30.906377,-30.719613,-30.703291,-30.704111,-30.793352,-30.791342,-30.640037,-30.704111,-30.810721,-30.793452,-30.719613,-30.791342,-30.719613,-30.791342,-30.810721,-30.810721,-30.793452,-30.939658,-30.750814,-30.807249,-30.753627,-30.930152,-30.750814,-30.766121,-30.930152,-30.769092,-30.753627,-30.928292,-30.769092,-30.767348,-30.766362,-30.879618,-30.879618,-30.928292,-30.91317,-30.750814,-30.939658,-30.807249,-30.930152,-30.767267,-30.769137,-30.767267,-30.928292,-30.930152,-30.928292,-30.879618,-30.928292,-30.879618,-30.750813,-30.750813,-30.750813,-30.91272,-30.766371,-30.879618,-30.939676,-30.939676,-30.938446],[147.524845,147.5079,147.575984,147.575984,147.50976,147.543892,147.5079,147.567942,147.5079,147.513252,147.519486,147.544951,147.507757,147.577683,147.543892,147.582867,147.544951,147.591508,147.544951,147.567942,147.591508,147.526873,147.526178,147.508332,147.508332,147.587646,147.59574,147.539285,147.543892,147.597285,147.504593,147.597822,147.526873,147.587646,147.524845,147.587646,147.544951,147.566548,147.575984,147.591508,147.577683,147.578437,147.577683,147.508332,147.733051,147.687375,147.519597,147.741201,147.507903,147.727688,147.727688,147.734331,147.741201,147.504285,147.714527,147.497054,147.506215,147.4692,147.497054,147.566548,147.5079,147.504285,147.577683,147.526873,147.507757,147.504593,147.544951,147.526178,147.526873,147.544951,147.519486,147.50976,147.544951,147.519597,147.526873,147.508332,147.513252,147.539285,147.575984,147.567942,147.543892,147.507903,147.575984,147.524845,147.510589,147.494828,147.512542,147.502992,147.488953,147.505233,147.502228,147.510589,147.554778,147.481078,147.502992,147.479569,147.481461,147.59574,147.687375,147.578437,147.597822,147.591508,147.587646,147.727688,147.597285,147.734331,147.582867,147.733051,147.543637,147.50976,147.595752,147.597311,147.50976,147.526831,147.595752,147.595752,147.526831,147.543637,147.5046,147.526831,147.566653,147.575984,147.544951,147.507757,147.587646,147.5079,147.577683,147.543892,147.519486,147.567942,147.597822,147.526178,147.566548,147.50976,147.544951,147.544951,147.591508,147.507903,147.5079,147.524845,147.526873,147.597822,147.508332,147.50976,147.591508,147.526873,147.519486,147.519597,147.513252,147.575984,147.507757,147.519486,147.526873,147.577683,147.524845,147.59574,147.597285,147.504593,147.525694,147.539285,147.543892,147.524845,147.508332,147.508315,147.548517,147.539278,147.531095,147.510815,147.511105,147.508315,147.537397,147.562657,147.510815,147.714527,147.727688,147.741201,147.727688,147.727688,147.734331,147.687375,147.741201,147.504285,147.587646,147.582867,147.582867,147.587646,147.567942,147.59574,147.526873,147.519486,147.507757,147.5079,147.543892,147.741201,147.519597,147.519486,147.544951,147.597285,147.504285,147.741201,147.526178,147.577683,147.524845,147.591508,147.575984,147.582867,147.508332,147.5079,147.544951,147.50976,147.587646,147.524845,147.508332,147.526178,147.504593,147.741201,147.734331,147.519486,147.577683,147.591508,147.543892,147.734331,147.524845,147.539285,147.507903,147.544951,147.508332,147.507757,147.727688,147.575984,147.727688,147.5079,147.513252,147.566548,147.578437,147.727688,147.524845,147.567942,147.543892,147.504593,147.50976,147.526873,147.578437,147.507757,147.526873,147.519193,147.526178,147.526178,147.508332,147.50976,147.524845,147.543892,147.507903,147.578437,147.582867,147.741201,147.567942,147.519597,147.591508,147.508332,147.513252,147.507757,147.526873,147.591508,147.524845,147.577683,147.539285,147.566548,147.575984,147.544951,147.734331,147.575984,147.727688,147.544951,147.519597,147.582867,147.582867,147.741201,147.544951,147.5079,147.5079,147.513252,147.519486,147.519486,147.519486,147.519597,147.519597,147.544951,147.50976,147.582867,147.566548,147.508332,147.526178,147.727688,147.50976,147.508332,147.582867,147.544951,147.507757,147.674262,147.591508,147.734331,147.578437,147.507903,147.741201,147.591508,147.543892,147.504285,147.543892,147.741201,147.508332,147.727688,147.5079,147.484995,147.714527,147.526873,147.519193,147.5079,147.50976,147.591508,147.504593,147.524845,147.544951,147.539285,147.507903,147.577683,147.587646,147.507757,147.543892,147.591508,147.524845,147.59574,147.50976,147.591508,147.741201,147.575984,147.519486,147.741201,147.524845,147.727688,147.566548,147.519486,147.567942,147.50976,147.519597,147.519597,147.587646,147.577683,147.575984,147.734331,147.504593,147.508332,147.508332,147.544951,147.714527,147.5079,147.539285,147.508332,147.687375,147.5079,147.527501,147.524892,147.545978,147.541843,147.524373,147.526873,147.741201,147.734331,147.727688,147.727688,147.591508,147.539285,147.526178,147.741201,147.526178,147.687375,147.734331,147.526873,147.687375,147.526177,147.526873,147.591508,147.727688,147.727688,147.734331,147.741128,147.734331,147.687375,147.741128,147.526177,147.727688,147.526177,147.591508,147.741128,147.746331,147.734331,147.526177,147.485054,147.485054,147.486066,147.486066,147.489054,147.501229,147.501229,147.489142,147.489142,147.489142,147.490083,147.490083,147.490083,147.490083,147.49087,147.491414,147.49087,147.471744,147.471744,147.471724,147.471724,147.729068,147.75321,147.749409,147.527449,147.541864,147.546322,147.527449,147.546322,147.541864,147.524373,147.524373,147.542332,147.541843,147.545978,147.507903,147.484995,147.543892,147.504593,147.484995,147.566548,147.484995,147.507903,147.507903,147.484995,147.484995,147.484995,147.591508,147.5079,147.508332,147.706651,147.714527,147.507757,147.508332,147.513252,147.706641,147.591508,147.714527,147.591508,147.714527,147.513252,147.513252,147.706641,147.741201,147.524845,147.674262,147.544951,147.727688,147.524845,147.539285,147.727688,147.50976,147.544951,147.734331,147.50976,147.526178,147.526873,147.687375,147.687375,147.734331,147.504285,147.524845,147.741201,147.674262,147.727688,147.526177,147.509761,147.526177,147.734331,147.727688,147.734331,147.687375,147.734331,147.687375,147.525054,147.525054,147.525054,147.608935,147.526873,147.687375,147.741128,147.741128,147.746331],null,null,null,{\"interactive\":true,\"draggable\":false,\"keyboard\":true,\"title\":\"\",\"alt\":\"\",\"zIndexOffset\":0,\"opacity\":1,\"riseOnHover\":false,\"riseOffset\":250},null,null,{\"showCoverageOnHover\":true,\"zoomToBoundsOnClick\":true,\"spiderfyOnMaxZoom\":true,\"removeOutsideVisibleBounds\":true,\"spiderLegPolylineOptions\":{\"weight\":1.5,\"color\":\"#222\",\"opacity\":0.5},\"freezeAtZoom\":false},null,[\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus largiflorens F.Muell. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus populnea F.Muell. | | 2017 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus populnea F.Muell. | | 2014 - May\",\"Eucalyptus largiflorens F.Muell. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus largiflorens F.Muell. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]}],\"setView\":[[-30.789030468,147.570597894],10,[]],\"limits\":{\"lat\":[-30.985558,-30.601113],\"lng\":[147.4692,147.75321]}},\"evals\":[],\"jsHooks\":[]}  Colouring markers You can also add circle markers which can have custom colours, and add a legend:\ncolor_function \u0026lt;- colorFactor(\u0026quot;RdYlBu\u0026quot;, domain = NULL) base %\u0026gt;% addCircleMarkers(lng = euc$decimalLongitude, lat = euc$decimalLatitude, color = color_function(euc$name), label = euc$label) %\u0026gt;% addLegend(pal = color_function, values = euc$name)  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addScaleBar\",\"args\":[{\"maxWidth\":100,\"metric\":true,\"imperial\":true,\"updateWhenIdle\":true,\"position\":\"topright\"}]},{\"method\":\"addCircleMarkers\",\"args\":[[-30.750814,-30.703291,-30.604462,-30.604462,-30.769092,-30.921591,-30.703291,-30.601113,-30.703291,-30.810721,-30.815145,-30.753627,-30.640037,-30.60431,-30.921591,-30.945585,-30.753627,-30.719613,-30.753627,-30.601113,-30.719613,-30.766362,-30.767348,-30.704111,-30.704111,-30.656114,-30.65522,-30.766121,-30.921591,-30.660411,-30.701996,-30.718844,-30.766362,-30.656114,-30.750814,-30.656114,-30.753627,-30.937148,-30.604462,-30.719613,-30.60431,-30.954014,-30.60431,-30.704111,-30.927857,-30.879618,-30.814503,-30.939658,-30.813377,-30.930152,-30.930152,-30.928292,-30.939658,-30.91317,-30.791342,-30.729886,-30.604363,-30.802549,-30.729886,-30.937148,-30.703291,-30.91317,-30.60431,-30.766362,-30.640037,-30.701996,-30.753627,-30.767348,-30.766362,-30.753627,-30.815145,-30.769092,-30.753627,-30.814503,-30.766362,-30.704111,-30.810721,-30.766121,-30.604462,-30.601113,-30.921591,-30.813377,-30.604462,-30.750814,-30.616533,-30.659222,-30.618136,-30.701186,-30.957967,-30.623736,-30.698339,-30.616533,-30.911464,-30.980719,-30.701186,-30.967936,-30.985558,-30.65522,-30.879618,-30.954014,-30.718844,-30.719613,-30.656114,-30.930152,-30.660411,-30.928292,-30.945585,-30.927857,-30.921452,-30.769092,-30.655197,-30.660409,-30.769092,-30.766392,-30.655197,-30.655197,-30.766392,-30.921452,-30.701973,-30.766392,-30.937037,-30.604462,-30.753627,-30.640037,-30.656114,-30.703291,-30.60431,-30.921591,-30.815145,-30.601113,-30.718844,-30.767348,-30.937148,-30.769092,-30.753627,-30.753627,-30.719613,-30.813377,-30.703291,-30.750814,-30.766362,-30.718844,-30.704111,-30.769092,-30.719613,-30.766362,-30.815145,-30.814503,-30.810721,-30.604462,-30.640037,-30.815145,-30.766362,-30.60431,-30.750814,-30.65522,-30.660411,-30.701996,-30.749466,-30.766121,-30.921591,-30.750814,-30.704111,-30.704082,-30.754485,-30.766131,-30.829983,-30.76399,-30.700046,-30.704082,-30.766225,-30.761738,-30.76399,-30.791342,-30.930152,-30.939658,-30.930152,-30.930152,-30.928292,-30.879618,-30.939658,-30.91317,-30.656114,-30.945585,-30.945585,-30.656114,-30.601113,-30.65522,-30.766362,-30.815145,-30.640037,-30.703291,-30.921591,-30.939658,-30.814503,-30.815145,-30.753627,-30.660411,-30.91317,-30.939658,-30.767348,-30.60431,-30.750814,-30.719613,-30.604462,-30.945585,-30.704111,-30.703291,-30.753627,-30.769092,-30.656114,-30.750814,-30.704111,-30.767348,-30.701996,-30.939658,-30.928292,-30.815145,-30.60431,-30.719613,-30.921591,-30.928292,-30.750814,-30.766121,-30.813377,-30.753627,-30.704111,-30.640037,-30.930152,-30.604462,-30.930152,-30.703291,-30.810721,-30.937148,-30.954014,-30.930152,-30.750814,-30.601113,-30.921591,-30.701996,-30.769092,-30.766362,-30.954014,-30.640037,-30.766362,-30.649431,-30.767348,-30.767348,-30.704111,-30.769092,-30.750814,-30.921591,-30.813377,-30.954014,-30.945585,-30.939658,-30.601113,-30.814503,-30.719613,-30.704111,-30.810721,-30.640037,-30.766362,-30.719613,-30.750814,-30.60431,-30.766121,-30.937148,-30.604462,-30.753627,-30.928292,-30.604462,-30.930152,-30.753627,-30.814503,-30.945585,-30.945585,-30.939658,-30.753627,-30.703291,-30.703291,-30.810721,-30.815145,-30.815145,-30.815145,-30.814503,-30.814503,-30.753627,-30.769092,-30.945585,-30.937148,-30.704111,-30.767348,-30.930152,-30.769092,-30.704111,-30.945585,-30.753627,-30.640037,-30.807249,-30.719613,-30.928292,-30.954014,-30.813377,-30.939658,-30.719613,-30.921591,-30.91317,-30.921591,-30.939658,-30.704111,-30.930152,-30.703291,-30.906377,-30.791342,-30.766362,-30.649431,-30.703291,-30.769092,-30.719613,-30.701996,-30.750814,-30.753627,-30.766121,-30.813377,-30.60431,-30.656114,-30.640037,-30.921591,-30.719613,-30.750814,-30.65522,-30.769092,-30.719613,-30.939658,-30.604462,-30.815145,-30.939658,-30.750814,-30.930152,-30.937148,-30.815145,-30.601113,-30.769092,-30.814503,-30.814503,-30.656114,-30.60431,-30.604462,-30.928292,-30.701996,-30.704111,-30.704111,-30.753627,-30.791342,-30.703291,-30.766121,-30.704111,-30.879618,-30.703291,-30.766612,-30.82503,-30.839146,-30.840318,-30.769828,-30.766362,-30.939658,-30.928292,-30.930152,-30.930152,-30.719613,-30.766121,-30.767348,-30.939658,-30.767348,-30.879618,-30.928292,-30.766371,-30.879618,-30.767267,-30.766371,-30.719613,-30.930152,-30.930152,-30.928292,-30.939676,-30.928292,-30.879618,-30.939676,-30.767267,-30.930152,-30.767267,-30.719613,-30.939676,-30.938446,-30.928292,-30.767267,-30.907631,-30.907631,-30.907113,-30.907113,-30.908284,-30.806428,-30.806428,-30.7957,-30.7957,-30.7957,-30.795688,-30.795688,-30.795688,-30.795688,-30.845656,-30.845726,-30.845656,-30.796766,-30.796766,-30.797001,-30.797001,-30.663997,-30.675933,-30.671777,-30.766594,-30.840372,-30.839,-30.766594,-30.839,-30.840372,-30.769828,-30.769828,-30.845441,-30.840318,-30.839146,-30.813377,-30.906377,-30.921591,-30.701996,-30.906377,-30.937148,-30.906377,-30.813377,-30.813377,-30.906377,-30.906377,-30.906377,-30.719613,-30.703291,-30.704111,-30.793352,-30.791342,-30.640037,-30.704111,-30.810721,-30.793452,-30.719613,-30.791342,-30.719613,-30.791342,-30.810721,-30.810721,-30.793452,-30.939658,-30.750814,-30.807249,-30.753627,-30.930152,-30.750814,-30.766121,-30.930152,-30.769092,-30.753627,-30.928292,-30.769092,-30.767348,-30.766362,-30.879618,-30.879618,-30.928292,-30.91317,-30.750814,-30.939658,-30.807249,-30.930152,-30.767267,-30.769137,-30.767267,-30.928292,-30.930152,-30.928292,-30.879618,-30.928292,-30.879618,-30.750813,-30.750813,-30.750813,-30.91272,-30.766371,-30.879618,-30.939676,-30.939676,-30.938446],[147.524845,147.5079,147.575984,147.575984,147.50976,147.543892,147.5079,147.567942,147.5079,147.513252,147.519486,147.544951,147.507757,147.577683,147.543892,147.582867,147.544951,147.591508,147.544951,147.567942,147.591508,147.526873,147.526178,147.508332,147.508332,147.587646,147.59574,147.539285,147.543892,147.597285,147.504593,147.597822,147.526873,147.587646,147.524845,147.587646,147.544951,147.566548,147.575984,147.591508,147.577683,147.578437,147.577683,147.508332,147.733051,147.687375,147.519597,147.741201,147.507903,147.727688,147.727688,147.734331,147.741201,147.504285,147.714527,147.497054,147.506215,147.4692,147.497054,147.566548,147.5079,147.504285,147.577683,147.526873,147.507757,147.504593,147.544951,147.526178,147.526873,147.544951,147.519486,147.50976,147.544951,147.519597,147.526873,147.508332,147.513252,147.539285,147.575984,147.567942,147.543892,147.507903,147.575984,147.524845,147.510589,147.494828,147.512542,147.502992,147.488953,147.505233,147.502228,147.510589,147.554778,147.481078,147.502992,147.479569,147.481461,147.59574,147.687375,147.578437,147.597822,147.591508,147.587646,147.727688,147.597285,147.734331,147.582867,147.733051,147.543637,147.50976,147.595752,147.597311,147.50976,147.526831,147.595752,147.595752,147.526831,147.543637,147.5046,147.526831,147.566653,147.575984,147.544951,147.507757,147.587646,147.5079,147.577683,147.543892,147.519486,147.567942,147.597822,147.526178,147.566548,147.50976,147.544951,147.544951,147.591508,147.507903,147.5079,147.524845,147.526873,147.597822,147.508332,147.50976,147.591508,147.526873,147.519486,147.519597,147.513252,147.575984,147.507757,147.519486,147.526873,147.577683,147.524845,147.59574,147.597285,147.504593,147.525694,147.539285,147.543892,147.524845,147.508332,147.508315,147.548517,147.539278,147.531095,147.510815,147.511105,147.508315,147.537397,147.562657,147.510815,147.714527,147.727688,147.741201,147.727688,147.727688,147.734331,147.687375,147.741201,147.504285,147.587646,147.582867,147.582867,147.587646,147.567942,147.59574,147.526873,147.519486,147.507757,147.5079,147.543892,147.741201,147.519597,147.519486,147.544951,147.597285,147.504285,147.741201,147.526178,147.577683,147.524845,147.591508,147.575984,147.582867,147.508332,147.5079,147.544951,147.50976,147.587646,147.524845,147.508332,147.526178,147.504593,147.741201,147.734331,147.519486,147.577683,147.591508,147.543892,147.734331,147.524845,147.539285,147.507903,147.544951,147.508332,147.507757,147.727688,147.575984,147.727688,147.5079,147.513252,147.566548,147.578437,147.727688,147.524845,147.567942,147.543892,147.504593,147.50976,147.526873,147.578437,147.507757,147.526873,147.519193,147.526178,147.526178,147.508332,147.50976,147.524845,147.543892,147.507903,147.578437,147.582867,147.741201,147.567942,147.519597,147.591508,147.508332,147.513252,147.507757,147.526873,147.591508,147.524845,147.577683,147.539285,147.566548,147.575984,147.544951,147.734331,147.575984,147.727688,147.544951,147.519597,147.582867,147.582867,147.741201,147.544951,147.5079,147.5079,147.513252,147.519486,147.519486,147.519486,147.519597,147.519597,147.544951,147.50976,147.582867,147.566548,147.508332,147.526178,147.727688,147.50976,147.508332,147.582867,147.544951,147.507757,147.674262,147.591508,147.734331,147.578437,147.507903,147.741201,147.591508,147.543892,147.504285,147.543892,147.741201,147.508332,147.727688,147.5079,147.484995,147.714527,147.526873,147.519193,147.5079,147.50976,147.591508,147.504593,147.524845,147.544951,147.539285,147.507903,147.577683,147.587646,147.507757,147.543892,147.591508,147.524845,147.59574,147.50976,147.591508,147.741201,147.575984,147.519486,147.741201,147.524845,147.727688,147.566548,147.519486,147.567942,147.50976,147.519597,147.519597,147.587646,147.577683,147.575984,147.734331,147.504593,147.508332,147.508332,147.544951,147.714527,147.5079,147.539285,147.508332,147.687375,147.5079,147.527501,147.524892,147.545978,147.541843,147.524373,147.526873,147.741201,147.734331,147.727688,147.727688,147.591508,147.539285,147.526178,147.741201,147.526178,147.687375,147.734331,147.526873,147.687375,147.526177,147.526873,147.591508,147.727688,147.727688,147.734331,147.741128,147.734331,147.687375,147.741128,147.526177,147.727688,147.526177,147.591508,147.741128,147.746331,147.734331,147.526177,147.485054,147.485054,147.486066,147.486066,147.489054,147.501229,147.501229,147.489142,147.489142,147.489142,147.490083,147.490083,147.490083,147.490083,147.49087,147.491414,147.49087,147.471744,147.471744,147.471724,147.471724,147.729068,147.75321,147.749409,147.527449,147.541864,147.546322,147.527449,147.546322,147.541864,147.524373,147.524373,147.542332,147.541843,147.545978,147.507903,147.484995,147.543892,147.504593,147.484995,147.566548,147.484995,147.507903,147.507903,147.484995,147.484995,147.484995,147.591508,147.5079,147.508332,147.706651,147.714527,147.507757,147.508332,147.513252,147.706641,147.591508,147.714527,147.591508,147.714527,147.513252,147.513252,147.706641,147.741201,147.524845,147.674262,147.544951,147.727688,147.524845,147.539285,147.727688,147.50976,147.544951,147.734331,147.50976,147.526178,147.526873,147.687375,147.687375,147.734331,147.504285,147.524845,147.741201,147.674262,147.727688,147.526177,147.509761,147.526177,147.734331,147.727688,147.734331,147.687375,147.734331,147.687375,147.525054,147.525054,147.525054,147.608935,147.526873,147.687375,147.741128,147.741128,147.746331],10,null,null,{\"interactive\":true,\"className\":\"\",\"stroke\":true,\"color\":[\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\"],\"weight\":5,\"opacity\":0.5,\"fill\":true,\"fillColor\":[\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#2C7BB6\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#FDAE61\",\"#FDAE61\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#FDAE61\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#2C7BB6\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#ABD9E9\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#2C7BB6\",\"#D7191C\",\"#D7191C\",\"#FDAE61\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#D7191C\",\"#ABD9E9\"],\"fillOpacity\":0.2},null,null,null,null,[\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus largiflorens F.Muell. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2019 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus largiflorens F.Muell. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2018 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2017 - Apr\",\"Eucalyptus populnea F.Muell. | | 2017 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2017 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2016 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2016 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2015 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus populnea F.Muell. | | 2014 - May\",\"Eucalyptus largiflorens F.Muell. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2014 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus largiflorens F.Muell. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2013 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2012 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus largiflorens F.Muell. | | 2012 - Sep\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Mar\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Mar\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Mar\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus populnea F.Muell. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Apr\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus populnea F.Muell. | | 2011 - May\",\"Eucalyptus largiflorens F.Muell. | | 2011 - May\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jun\",\"Eucalyptus populnea F.Muell. | | 2011 - Jun\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus coolabah Blakely \u0026amp; Jacobs | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus camaldulensis Dehnh. | | 2011 - Jul\",\"Eucalyptus largiflorens F.Muell. | | 2011 - Jul\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]},{\"method\":\"addLegend\",\"args\":[{\"colors\":[\"#D7191C\",\"#FDAE61\",\"#ABD9E9\",\"#2C7BB6\"],\"labels\":[\"Eucalyptus camaldulensis Dehnh.\",\"Eucalyptus coolabah Blakely \u0026 Jacobs\",\"Eucalyptus largiflorens F.Muell.\",\"Eucalyptus populnea F.Muell.\"],\"na_color\":null,\"na_label\":\"NA\",\"opacity\":0.5,\"position\":\"topright\",\"type\":\"factor\",\"title\":null,\"extra\":null,\"layerId\":null,\"className\":\"info legend\",\"group\":null}]}],\"setView\":[[-30.789030468,147.570597894],10,[]],\"limits\":{\"lat\":[-30.985558,-30.601113],\"lng\":[147.4692,147.75321]}},\"evals\":[],\"jsHooks\":[]}  Other stuff to try out!  addMeasure() adds a ruler and an area estimator control to the map addProviderTiles() Other tiles (base maps) can be added by using this function. Try out: leaflet() %\u0026gt;% addProviderTiles(provider = providers$CartoDB) ! addLayersControl() adds a selector for choosing multiple layers if you have added them. addRasterImage() creates an image overlay from raster data! addGeoJSON() adds GeoJSON polygons to the interactive map!   Resources:  RStudios leaflet guide rgbif  Author: John Wilshire\nLast updated:\n## [1] \u0026quot;Thu Jan 20 16:15:30 2022\u0026quot;  "
},
{
	"uri": "/statistics/linear-models/interactions/",
	"title": "Understanding Interactions",
	"tags": [],
	"description": "",
	"content": "  Sampling or experimental designs with more than one factor give us the opportunity to test whether the factors interact. An interaction between factors is when the effect of one factor is dependent on the conditions in the other factor. If there is no interaction, then the two factors are acting independently. When learning statistics, interactions make our lives a bit more difficult because we aren’t able to make simple statements about the main effects (each factor in isolation) - the observed results are due to factors acting in combination. It is very important to understand these, however, as we are often interested in whether various environmental variables act together to independently. Consider any of the following questions:\nDoes the effect of removing predators vary between habitats?\nDoes the effect of contamination vary with water temperature?\nDoes the effect of temperature vary with food supply?\nDoes the effect of nutrient pollution vary across soil types?\nDo the benefits of establishing a reserve vary with reserve size?\nThese are all questions that would be answered by a formal statistical test of the interaction between factors.\nUnderstanding interactions can be best understood visually. Let’s consider how the growth of coral may be affected by two very important stressors currently affecting the world’s oceans: increasing temperature and increasing acidification. An experimental design to test this could be one that grows corals in the laboratory in all combinations of several temperatures and several pH conditions.\nFor simplicity, let’s consider just two levels of each treatment: a control and warmed treatment for temperature and a control and acidified treatment for pH. Corals would be grown in all four combinations. These three plots for coral growth illustrate scenarios where the two factors of temperature and pH do not interact.\n In the top left figure, there is an effect of warming (growth reduced in the warmer treatment) and no effect of pH.\n In the top right figure, there is an effect of pH (growth reduced in the acid treatment) and no effect of warming.\n In the bottom figure, there is an effect of both temperature (growth reduced in the warmer treatment) and pH (growth reduced in the acid treatment).  The next three plots for coral growth illustrate scenarios where there is an interaction between the factors of temperature and pH.\n In the top left figure, there is an effect of pH (growth reduced in the acid treatment) only in the warm treatment. The effect of warming is only evident in the acid pH treatment.\n In the top right figure, there is an effect of temperature (growth reduced in the warm treatment) and an effect of pH (growth reduced in the no effect of warming) but the effect of the acid treatment is greater in the warm treatment. The effect of warming is greater in the acid treatment.\n In the bottom figure, the effect of the acid treatment temperature completely changes in the two temperature treatments. Growth is reduced in the acid treatment in the control temperature, but increased in the warm temperature.  In all these cases with interactions, note that lines are not parallel (compare to the first three figures above).\nThe same ideas extend to sampling or experimental designs with more that two levels for each factor, and for designs where the predictor variables are continuous rather than categorical.\nIn this figure, there is an effect of pH (reduced growth in the acid treatment) in the warm and hot temperature treatments, but not the control temperature. Coral growth was always reduced in the hot treatment, but in the warm treatment, growth was slowed relative to the control only in the acid treatment. Communicating results \nWritten. If you have significant interaction between two factors in your design, then communicating your results requires text that describes how the effects of one factor depend on the other. In the examples with interactions above, you could not simply say that “ocean acidification reduced the growth of corals” because this result varied across the temperature treatments.\nIn designs with categorical factors, post-hoc tests are commonly used to test which means differ from which (i.e., compare all four combinations of temperature and pH in the design above). The results from these can be placed in the text or onto figures to show which means differ from which. You would then have statistical support for statements that contrast particular treatments. A sentence for the results section for the top left figure in the interactions plots above would be something like “Temperature interacted with pH to affect the growth of corals (Table 1), with reduced growth in the warm treatment only (Fig. 1)” where Table 1 would hold the statistical details of the given test (e.g., factorial ANOVA). Author: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 16:41:36 2022\u0026quot;  "
},
{
	"uri": "/coding-skills/version-control/",
	"title": "Version Control",
	"tags": [],
	"description": "",
	"content": "  Advantages, disadvantages and solutions \nFundamental to project organization is maintaining a consistent, uniform and simple set of working files that can be understood by your future self, collaborators and interested folks wanting to reproduce your analyses or re-use code or your data. However, for complex projects with many collaborators maintaining tidiness and keeping track of changing files can be very challenging!\nWhile file sharing services like Dropbox are easy to use and can maintain a consistent file set on your computer(s) and/or among collaborators, it has some serious disadvantages. Specifically, it can’t tell you what has changed within files. It also can’t deal with conflicts between files when you and your collaborators are working at the same time on the same things. This often leads to a build up of files that no one seems to know what are for or how they differ. Its limited capacity for tracking deleted files also leads to a build up of “too afraid to delete” files. As projects develop, theses become papers and go through countless rounds of revisions. A little bit of organizing can keep chaos from compounding and maintain reproducibility (for both you and others) through all the changes.\nIdeally, it would be nice to easily see the current (and hopefully best) set of files, but be able to see who has changed them and what specific parts of the files have been modified. Keeping a record of the evolution of a particular project is also important to be able to quickly solve problems when (not if) they arise. Setting up your projects under a version control system basically allows you to do all of the above and more.\nAdvantages. The major advantages of using verison control over just using Dropbox include:\nIt keeps track of all files relevant to a specific project and/or that are necessary for its reproducibility by assigning them a unique identifier.\n It documents the evolution of every file in a project, including data, manuscripts and code, by permitting the user to assign a commit tag describing how the file was changed.\n It automatically indicates who, when and where a specific file was modified, identifying the in text locations that have changed.\n It keeps a recorded history of all the changed files, allowing you to move back in time to look at older version of files or the state of the project at an earlier time.\n It auto merges files that you and collaborators are working on at the same time and introduces conflict markers in the text of the file if the same lines have been edited. This forces one to deal with and correct conflicts immediately.\n It makes running analyses and scripts on servers much easier.\n It promotes easier collaboration between lab members and co-authors by keeping files in sync and annotated across diverse platforms.\n Makes it much easier at the end of a project to quickly share and store data and code relevant for reproducing the project (analyses, paper etc) which is often a necessary pre-requisite for publishing.\n Makes it easier to correct mistakes within a project by allowing you to track down the relevant colleague (or vise versa) when issues arise after updates or changes.\n Forces you to think about the relevant parts of the project that are essential for it’s reproducibility and allows you to customize what is tracked.\n  Disadvantages. While the above is definitely appealing, version control and git do have some disadvantages. First, you will at some point need to spend a bit of time coding before and after a days work. Although, the small time investment to do this pays off a lot down the line. Second, the additional coding can make it challenging to get collaborators up and running on a version control system. Not everyone will be as familiar with the terminal or command line and this can create barriers to entry.\nSolutions. Fortunately, there are some very easy and simple solutions to many of the problems above. For example, there are now very useful and easy to use graphical user interfaces (GUI’s) like SourceTree that remove the need to use the command line all together, make it easy and seamless to set up repositories and are cross platform (i.e., Windows, Mac etc).  How it works \nGiven that not everyone will want to use the command line, we’ll show some basics using both the command line and a GUI (SourceTree). We’ll do this because we believe that the benefits of using version control far outweigh the costs of not using it, and so this should ensure mostly people can get started straight away.\nWe will also demonstrate how the command line relates to the GUI. We will not cover important topics like setting up SSH keychains, setting up a gitconfig file, dealing with conflicts all of which are covered thoroughly elsewhere. Rather, we provide a basic overview of how to set up a repository and the day-to-day workings of tracking project files.\nSetting up a repository.\nTo begin tracking files for a project, we need to set up a project repository that keeps all the relevant files (i.e., data, meta-data, code, functions, manuscript etc) in one place. The project directory will form the basis of a reproducible project (see project management for more details).\nTo take full advantage of version control, we want to have both a local (on your computer) and remote (cloud) copy of our repository. There are a number of hosting sites that will allow you to create an cloud repository including GitHub and BitBucket. Bitbucket allows you to create private repositories for free, whereas anything on GitHub is open (although you can pay for private repositories).\nTo set up a remote server, you will need to first create an account on one of these hosting sites. Once you have finished that you will also need to download and install Git (if using the command line), which is the version control system we’ll be using. Creating a repository on line is easy, log on to your account and go to Repositories -\u0026gt; Create new repository. Give it a name and then that’s it, if you’re on bitbucket it will literally tell you what to do next on the command line (Figure 1 \u0026amp; 2).\nFigure 1 - Setting up a repository for a project on Bitbucket\n Figure 2 - Bitbucket’s explanation of how to link the repository on the server to a local repository. See also Figure 4 below\n If you’re using the command line, you can literally just navigate to the place you want the folder and type in the commands in Figure 2 above. It will also take you through a few important steps on how Git works, but we’ll get to those later. The key component from this repository that is needed to set it up and connect it to a folder on your computer is the ssh or http pathname:\nhttps://UNSW_EnvComp@bitbucket.org/UNSW_EnvComp/unsw_envcomp.git.\nThis path name will make the connection between a local project folder (i.e. a folder on your computer) and the existing one on the server (i.e. Bitbucket). It will also allow you to clone the entire repository on your computer if needed. If you want to clone the repository on your computer, use the command line to navigate to where you want the folder and type in the following:\ngit clone https://UNSW_EnvComp@bitbucket.org/UNSW_EnvComp/unsw_envcomp.git\nThis will effectively copy down from the server your entire repository in the location you desire and is nearly identical to the commands suggested in Figure 2. It will also automatically create a connection between your local directory and the server. You can also provide this pathname to collaborators, and provided they are given access to reading and writing the repository (can be changed in repository settings online), they can grab everything from the server as well in the same way described above.\nCreating a repository in SourceTree is also quite easy. Once you have the pathname for your repository, go into source tree, click New Repository -\u0026gt; Clone from URL (Figure 3). Add in the ssh or http:// pathname, decide where you want the repository to live on your computer and then click clone. This will then bring down the contents of the repository (if it is not empty) and set this connection up in SourceTree for you to begin tracking and pushing to the server. If the repository already exists on your computer and you want to add it to SourceTree, just click Add existing local repository instead of Clone from URL.\n Tracking files and pushing to the cloud \nNow that you are set up and have cloned or initiated a repository in a local folder, the trick is to keep track of important files, such as data, R code and manuscripts (i.e., .Rmd, .md, .txt etc.). How does Git do this? Well, there are basically a set of key commands that are needed and that are continually implemented to keep track a new or modified files. You use these commands at the end of your working day, or when you have made huge progress and want to get the changes to the server ASAP. The key commands and their order of execution are as follows:\nGet a large cup of coffee (or tea)\n This command pulls new files from the server.\n   git pull  Do a whole bunch of things to files in the project then check out what has changed   git status  Add a modified or untracked file to the staging area. Replace filename with the path and name of the file (e.g. /R/function.R). You can also add many files at once using --all in replace of filename.   git add filename  Once added, leave a message about what the file does, how it was changed etc   git commit -m \"add a message about the changes to file\"  Push the changes to the server   git push  Go home and relax–your project is under version control!  The step-by-step procedures above is used whenever you want to track changes, and these commands are literally typed in the command line in the order presented (See Figure 4). Step 2 is only needed when beginning work in the directory, and will pull any changes that collaborators may have made that you do not yet know about. If you’re the only one working on the project and you only use one computer, then step 2 is optional because your local directory will always have the most up-to-date files.\nFigure 4 - Example of sequence of steps in the Terminal window. The commands are highlighted in blue, and demonstrate how to initialize a new repository, checkout untracked files, add these files and commit and push these to the server.\n SourceTree makes the above way easier by just providing you with a bunch of click boxes and buttons that you can use to do all this very quickly. To add a file to be tracked just click the boxes of the relevant files (or all of them) in the “Unstaged files” area (Figure 5). Once you have clicked all the boxes, the files will be in the “Staged files” area. This is equivalent to git add from the command line. They are now ready to be committed, and you can leave a commit message in the window at the bottom of the screen and click the Commit button in the right corner. This is equivalent to the git commit -m \"message\" in the command line.\nFigure 5 - Example of how add, commit and push in SourceTree\n Once your files have been committed, the files that are ready to be pushed will show up in the “Push” button at the top of the screen (Figure 5). Click this and they will be moved to the server. As you edit and add files, new files will appear in the staging area and you can just repeat the above sequence to add, commit and push these to the server. The “Pull” button corresponds to step two in the Git sequence above and should always be used at the start of a day if you’re working with collaborators.\nIgnoring files you don’t want to track\nIn many cases there will be files within a project that you do not want to track. This could be because they are not necessary for the reproducibility of the project, or are just files for you and not needed for your collaborators. These could include helpful notes relevant only to you, papers you are interested in or even large output files. Files such as these don’t need to be tracked - for example, there may be no need to track figures and tables as in many instances these can be re-generated from the project code and they take a lot of space on the server. Ignoring these files is easy using what is called a .gitignore file. The “.” in front of the file means that it is hidden and will not be shown in a normal working directory. Fortunately, Git and SourceTree will recognize these files. The .gitignore is a file that remains in the main directory of your project folder and is usually tracked. You can create a .gitignore file in the command line easily using a few lines of code (Figure 6).\nFigure 6 - Example of how create a .gitignore file and ignore the photos/ folder of the imaginary Git repository\n In Figure 6, I’ve ignored a “photos/” folder. We can see that this now disappears (compare with Figure 4) from our staging area in the Terminal window. We can just add any file or folder we don’t want tracked here before adding it so that Git ignores them. If we want to start tracking a file we have ignore, just open the .gitignore file up in a text editor and remove the file you want to track. Save the .gitignore file and then add, commit and push this as above.  Further help \nVersion control systems, and Git in particular, can do quite a lot more then what we have covered above. We have just provided an brief introduction on how to get started and use Git to track your project files. If you want to know more about how to create branches, deal with conflicts and many other useful features you can visit the Git web page where you can fins all the relevant information to do more advanced stuff. Author: Daniel Noble Last updated:\n## [1] \u0026quot;Wed Jan 19 16:49:03 2022\u0026quot;  "
},
{
	"uri": "/coding-skills/asking-code-questions/",
	"title": "Asking code questions",
	"tags": [],
	"description": "",
	"content": "  When you started to learn R, one of the first things you probably figured out was how to get your data into R. You had to use some method to read your lovely excel datasets into R so you could achieve what you wanted. Maybe read.csv or read.table, or maybe you use Hadley Wickham’s recent package readr.\nThis tutorial is intended to ‘go back to the basics’ a little bit, and learn how to ‘create’ our own data. Why would you want to create your own data? \nYou probably already have your data in a nice fancy excel document and, as such, there may seem like no good reason to ‘make up’ data. There are, however, a number of good reasons that this can come in handy:\n1. To work on small-scale problems before using all your data\n2. You might want to run some sort of simulation study\n3. You might want to simulate data you expect to collect, to ensure you have the right methods listed in your proposal 4. You might get stuck and want to ask for help\nThe focus here will be on the last point. It is pretty inevitable you’ll get stuck with some sort of coding problem. We all do! When this happens, and you want to send some code to a friend, colleague, or even ask a question on the internet, you need to provide a reproducible example!\nBy doing this, you avoid the need to send your code file and entire data set as attachments to a friend or colleague to have a look. A reproducible example means that someone can quickly, and efficiently copy and paste just the code that you send and reproduce your error or issue you are having.\nIt’s important to note here that in order for someone to help you, they don’t need the whole dataset. They only need to be able to see the problem and have the associated question to fix/solve!\nThis tutorial is intended to help people who are relatively new to R create a reproducible example and also make fake data for other purposes.  So, how do you create a ‘fake’ dataset? \nIn the simplest case, you can create multiple vectors and then combine them into a data.frame.\nfactor \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;e\u0026quot;) value \u0026lt;- c(1, 2, 3, 4, 5) df \u0026lt;- data.frame(factor, value) df ## factor value ## 1 a 1 ## 2 b 2 ## 3 c 3 ## 4 d 4 ## 5 e 5 Alternatively, you can do it all in one step (noting that you are now using ‘=’, not ‘\u0026lt;-’ when specifying the vectors with a data.frame call:\ndf \u0026lt;- data.frame( factor = c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;e\u0026quot;), value = c(1, 2, 3, 4, 5) ) df ## factor value ## 1 a 1 ## 2 b 2 ## 3 c 3 ## 4 d 4 ## 5 e 5 This technique may work for a variety of situations, but it also may be too simple at times. For instance, if you have multiple vectors it may be complicated to make many of vectors and then combine them, or if you have some complicated experimental design (like a hierarchical blocked design) that you would like to replicate.\nA nice shortcut is to use sample, rnorm, or runif to create some data.\nsample creates RANDOM data from the specified size with or without replacement. For example, 10 random numbers without replacement:\ndata \u0026lt;- sample(10) data ## [1] 1 4 6 7 8 2 10 5 9 3 Or, 10 random numbers with replacement:\ndata \u0026lt;- sample(10, replace=TRUE) data ## [1] 7 9 9 7 1 1 7 8 6 2 You can create a vector and then sample from it:\nfactor \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;e\u0026quot;) data \u0026lt;- sample(factor, replace=TRUE) data ## [1] \u0026quot;a\u0026quot; \u0026quot;d\u0026quot; \u0026quot;e\u0026quot; \u0026quot;e\u0026quot; \u0026quot;c\u0026quot; You can also sample n number of times, making it a very convenient function. For example, draw from the four suits of cards, 100 times:\nsuits \u0026lt;- c(\u0026quot;Hearts\u0026quot;, \u0026quot;Spades\u0026quot;, \u0026quot;Clubs\u0026quot;, \u0026quot;Hearts\u0026quot;) cards \u0026lt;- sample(suits, size=100, replace=TRUE) Note that in the above examples, it doesn’t return data frames, which may or may not matter. Use as.data.frame for this, if necessary.\ndata \u0026lt;- as.data.frame(sample(10)) Creating data from a known distribution\nrnorm creates data from a normal distribution\ndata \u0026lt;- rnorm(100) By default, rnorm draws from a population with mean = 0, and sd = 1. We can change either of these to get a sample from a normal distribution with specified mean and standard deviaition. For example, to get 100 numbers from a normal distribution with a mean of 25 and s.d. of 1.5:\ndata \u0026lt;- rnorm(100, mean=25, sd=1.5) runif creates data from a uniform distribution\ndata \u0026lt;- runif(100) head(data) ## [1] 0.1155269 0.9630043 0.9035410 0.9978502 0.5536373 0.5380825 Similarly to above, runif draws from a distribution with min=0 and max=1. We can change this to whatever we want. For example, to get 100 random numbers between -10 and 5:\ndata \u0026lt;- runif(100, min=-10, max=-5) Luckily, R has just about every distribution built in to draw from. This is really helpful if you are theorizing data before you start collection of data! A comprehensive list is here.  What if your problem is a little more complicated? For instance, what if your data come from four replicates from each of five sites and you want to recreate a vector for the repeating factor values.\nYou could do this:\nsite \u0026lt;- c(\u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;e\u0026quot;, \u0026quot;e\u0026quot;, \u0026quot;e\u0026quot;, \u0026quot;e\u0026quot;) Much better, is to take advantage of the rep function. It replicates values in a vector or list. The same outcome as above is achieved with this.\nsite \u0026lt;- c(rep(\u0026quot;a\u0026quot;, 4), rep(\u0026quot;b\u0026quot;, 4), rep(\u0026quot;c\u0026quot;, 4), rep(\u0026quot;e\u0026quot;, 4)) Alternatively:\nsite \u0026lt;- rep(c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;), each=4) Or, you can replicate until a certain length of the vector is reached. To get 50 replicates from each of the four sites, we would use:\nsite \u0026lt;- rep(c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;), length=50) This becomes increasingly valuable as you increase the number of repetitions and/or factors to include!  Creating all combinations of multiple categorical factors \nexpand.grid is very useful for creating a data frame that has every combination of all levels from multiple factors. For example, if we had sampled four sites from each of four regions in each of three states, we could use this to create\nstudy \u0026lt;- expand.grid(state=c(\u0026quot;NSW\u0026quot;, \u0026quot;VIC\u0026quot;, \u0026quot;QLD\u0026quot;), region=c(\u0026quot;N\u0026quot;, \u0026quot;E\u0026quot;, \u0026quot;S\u0026quot;, \u0026quot;W\u0026quot;), site=c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;)) We could then add some data to simluate species richness at each site:\nstudy$richness \u0026lt;- rnorm(nrow(study), mean=15, sd=3) The nrow argument is used in order to replace the correct amount of data into the dataframe (in this case, 48, the number of rows in your study design).  What are some other options to make a reproducible example? \nYou could use a built in dataset that is loaded in base R, in order to reproduce your problem. You can quickly see the list of built-in datasets.\nlibrary(help=\u0026quot;datasets\u0026quot;) Then load a dataset using:\ndata(iris)  What if you NEED to use your own data? Maybe you have ultra-complicated data and can’t figure out how to reproduce the problem using fake data. Well, that’s what dput is for. dput is commonly used to write an object to a file or to recreate it.\nLet’s give an example. Say you are working with the quakes dataset.\ndata(quakes) head(quakes) ## lat long depth mag stations ## 1 -20.42 181.62 562 4.8 41 ## 2 -20.62 181.03 650 4.2 15 ## 3 -26.00 184.10 42 5.4 43 ## 4 -17.97 181.66 626 4.1 19 ## 5 -20.42 181.96 649 4.0 11 ## 6 -19.68 184.31 195 4.0 12 If it was just the structure of the data that we wanted to reproduce, then we could just use head combined with dput.\ndput(head(quakes)) ## structure(list(lat = c(-20.42, -20.62, -26, -17.97, -20.42, -19.68 ## ), long = c(181.62, 181.03, 184.1, 181.66, 181.96, 184.31), depth = c(562L, ## 650L, 42L, 626L, 649L, 195L), mag = c(4.8, 4.2, 5.4, 4.1, 4, ## 4), stations = c(41L, 15L, 43L, 19L, 11L, 12L)), row.names = c(NA, ## 6L), class = \u0026quot;data.frame\u0026quot;) We can then copy and paste this output into an email, etc. However, be sure to name the df first in order to create an object for whoever will be using it!\nreproduced_df \u0026lt;- structure(list(lat = c(-20.42, -20.62, -26, -17.97, -20.42, -19.68 ), long = c(181.62, 181.03, 184.1, 181.66, 181.96, 184.31), depth = c(562L, 650L, 42L, 626L, 649L, 195L), mag = c(4.8, 4.2, 5.4, 4.1, 4, 4), stations = c(41L, 15L, 43L, 19L, 11L, 12L)), .Names = c(\u0026quot;lat\u0026quot;, \u0026quot;long\u0026quot;, \u0026quot;depth\u0026quot;, \u0026quot;mag\u0026quot;, \u0026quot;stations\u0026quot;), row.names = c(NA, 6L), class = \u0026quot;data.frame\u0026quot;) What if its only certain rows we are having trouble with?\ntmp \u0026lt;- quakes[30:40,] dput(tmp) ## structure(list(lat = c(-19.84, -22.58, -16.32, -15.55, -23.55, ## -16.3, -25.82, -18.73, -17.64, -17.66, -18.82), long = c(182.37, ## 179.24, 166.74, 185.05, 180.8, 186, 179.33, 169.23, 181.28, 181.4, ## 169.33), depth = c(328L, 553L, 50L, 292L, 349L, 48L, 600L, 206L, ## 574L, 585L, 230L), mag = c(4.4, 4.6, 4.7, 4.8, 4, 4.5, 4.3, 4.5, ## 4.6, 4.1, 4.4), stations = c(17L, 21L, 30L, 42L, 10L, 10L, 13L, ## 17L, 17L, 17L, 11L)), row.names = 30:40, class = \u0026quot;data.frame\u0026quot;) This is a really great way to send code to someone to ask for help!  What about really complex problems? \nThis tutorial is mainly intended for new R users, and it is likely the tips and tricks above will help other people to help you a large majority of the time. However, in the case it doesn’t, it might be necessary to give some extra information.sessionInfo() gives a summary of the R version currently running, the operating system and which packages are loaded\nsessionInfo() ## R version 4.1.2 (2021-11-01) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.24 digest_0.6.29 R6_2.5.1 jsonlite_1.7.2 ## [5] magrittr_2.0.1 evaluate_0.14 blogdown_1.7 stringi_1.7.6 ## [9] rlang_0.4.12 jquerylib_0.1.4 bslib_0.3.1 rmarkdown_2.11 ## [13] tools_4.1.2 stringr_1.4.0 xfun_0.29 yaml_2.2.1 ## [17] fastmap_1.1.0 compiler_4.1.2 htmltools_0.5.2 knitr_1.37 ## [21] sass_0.4.0 \nOther important notes 1. Be sure to clearly define what you are after. Do you have a purely statistics question, or do you have a coding question? 2. It is a good idea to include any neccessary packages that you are using in which the problem occurs. 3. You should always note what you have already tried, as far as code, and/or any reference sites you are using.\nConcluding remarks\n1. There are a number of reasons we may want to use fake data.\n2. It is pretty easy to create fake data.\n3. If you send the easiest possible reproducible example to someone, the greater the likelihood they will help you, and more efficiently.\n4. A lot of the time, by simplifying the problem, you may even solve it yourself!\n5. Learn how to use dput, but don’t forget to name the object when copying the code from the R console.\n Where can you get further help? \nAll of this information isn’t really useful unless you have someone to answer your question after you’ve made your nice reproducible example. One alternative to asking for help from colleagues and friends is to use online websites, such as Stack Overflow. The tips in this tutorial will help you to ask a question that is not removed or banned. Also, when you ask a question be sure to show you have done previous research.\n  There is more help on the web for making reproducible examples. For instance, see here, here, here, or here. Author: Corey T. Callaghan Last updated:\n## [1] \u0026quot;Wed Jan 19 16:55:39 2022\u0026quot;  "
},
{
	"uri": "/graphics/ggplot/ggplot-barplot/",
	"title": "Barplot with Errorbars",
	"tags": [],
	"description": "",
	"content": "  Bar plots with error bars are very frequently used in the environmental sciences to represent the variation in a continuous variable within one or more categorical variables. These are not always straightforward to make with the base functions in R. This page introduces you to making these plots with the package ggplot2.\nBefore you get started, read the page on the basics of plotting with ggplot and install the package ggplot2.\nlibrary(ggplot2) \nIn this examples, let’s use a data set that is already in R with the length and width of floral parts for three species of iris. First, load the data set:\ndata(iris) To contrast a variable across species, we first need to summarise the data to obtain means and a measure of variation for each of the three species in the data set. There are several ways to do this in R, but we like the summarise and group_by functions in the package dplyr. See here for more details on using dplyr for summarising data.\nThe following code will make a new data frame with the summary data per species.\nlibrary(dplyr) Iris_summary \u0026lt;- iris %\u0026gt;% # the names of the new data frame and the data frame to be summarised group_by(Species) %\u0026gt;% # the grouping variable summarise(mean_PL = mean(Petal.Length), # calculates the mean of each group sd_PL = sd(Petal.Length), # calculates the standard deviation of each group n_PL = n(), # calculates the sample size per group SE_PL = sd(Petal.Length)/sqrt(n())) # calculates the standard error of each group We can now make a bar plot of means vs species, with standard deviations or standard errors as the error bar. The following code uses the standard deviations.\nIrisPlot \u0026lt;- ggplot(Iris_summary, aes(Species, mean_PL)) + geom_col() + geom_errorbar(aes(ymin=mean_PL-sd_PL, ymax=mean_PL + sd_PL), width=0.2) IrisPlot + labs(y=\u0026quot;Petal length (cm) +/- s.d.\u0026quot;, x = \u0026quot;Species\u0026quot;) + theme_classic() geom_col uses the value of the y variable (mean_PL) as the height of the bars.\nIn the geom_errorbar code, ymin and ymax are the top and bottom of the error bars (defined here as mean +/- sd), and width defines how wide the error bars are.\n###Further help To further customise the aesthetics of the graph, including colour and formatting, see our other ggplot help pages:\n* altering the overall appearance\n* adding titles and axis names\n* colours and symbols\nHelp on all the ggplot functions can be found at the The master ggplot help site.\nA useful cheat sheet on commonly used functions can be downloaded here.\nChang, W (2012) R Graphics cookbook. O’Reilly Media. - a guide to ggplot with online help on making bar and line graphs with error bars here \nAuthor: Alistair Poore (small edits by Will Cornwell) Last updated:\n## [1] \u0026quot;Thu Jan 20 14:34:38 2022\u0026quot; "
},
{
	"uri": "/statistics/gams/",
	"title": "Generalised Additive Models (GAMs)",
	"tags": [],
	"description": "",
	"content": "  Many data in the environmental sciences do not fit simple linear models and are best described by “wiggly models”, also known as Generalised Additive Models (GAMs).\nLet’s start with a famous tweet by one Gavin Simpson, which amounts to:\n1. GAMs are just GLMs\n2. GAMs fit wiggly terms\n3. use + s(x) not x in your syntax\n4. use method = \"REML\"\n5. always look at gam.check()\nThis is basically all there is too it - an extension of generalised linear models (GLMs) with a smoothing function. Of course, there may be many sophisticated things going on when you fit a model with smooth terms, but you only need to understand the rationale and some basic theory. There are also lots of what would be apparently magic things happening when we try to understand what is under the hood of say lmer or glmer, but we use them all the time without reservation! GAMs in a nutshell \nLet’s start with an equation for a Gaussian linear model: \\[y = \\beta_0 + x_1\\beta_1 + \\varepsilon, \\quad \\varepsilon \\sim N(0, \\sigma^2)\\] What changes in a GAM is the presence of a smoothing term: \\[y = \\beta_0 + f(x_1) + \\varepsilon, \\quad \\varepsilon \\sim N(0, \\sigma^2)\\] This simply means that the contribution to the linear predictor is now some function \\(f\\). This is not that dissimilar conceptually to using a quadratic (\\(x_1^2\\)) or cubic term (\\(x_1^3\\)) as your predictor.\nThe function \\(f\\) can be something more funky or kinky - here, we’re going to focus on splines. In the old days, it might have been something like piecewise linear functions.\nYou can have combinations of linear and smooth terms in your model, for example \\[y = \\beta_0 + x_1\\beta_1 + f(x_2) + \\varepsilon, \\quad \\varepsilon \\sim N(0, \\sigma^2)\\] or we can fit generalised distributions and random effects, for example \\[ln(y) = \\beta_0 + f(x_1) + \\varepsilon, \\quad \\varepsilon \\sim Poisson(\\lambda)\\] \\[ln(y) = \\beta_0 + f(x_1) + z_1\\gamma + \\varepsilon, \\quad \\varepsilon \\sim Poisson(\\lambda), \\quad \\gamma \\sim N(0,\\Sigma)\\]  A simple example \nLets try a simple example. First, let’s create a data frame and fill it with some simulated data with an obvious non-linear trend and compare how well some models fit to that data.\nx \u0026lt;- seq(0, pi * 2, 0.1) sin_x \u0026lt;- sin(x) y \u0026lt;- sin_x + rnorm(n = length(x), mean = 0, sd = sd(sin_x / 2)) Sample_data \u0026lt;- data.frame(y,x) library(ggplot2) ggplot(Sample_data, aes(x, y)) + geom_point() Try fitting a normal linear model:\nlm_y \u0026lt;- lm(y ~ x, data = Sample_data) and plotting the fitted line with data using geom_smooth in ggplot\nggplot(Sample_data, aes(x, y)) + geom_point() + geom_smooth(method = lm) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39; Looking at the plot or summary(lm_y), you might think the model fits nicely, but look at the residual plot - eek!\nplot(lm_y, which = 1) Clearly, the residuals are not evenly spread across values of \\(x\\), and we need to consider a better model.  Running the analysis \nBefore we consider a GAM, we need to load the package mgcv - the choice for running GAMs in R.\nlibrary(mgcv) To run a GAM, we use:\ngam_y \u0026lt;- gam(y ~ s(x), method = \u0026quot;REML\u0026quot;) To extract the fitted values, we can use predict just like normal:\nx_new \u0026lt;- seq(0, max(x), length.out = 100) y_pred \u0026lt;- predict(gam_y, data.frame(x = x_new)) But for simple models, we can also utilise the method = argument in geom_smooth, specifying the model formula.\nggplot(Sample_data, aes(x, y)) + geom_point() + geom_smooth(method = \u0026quot;gam\u0026quot;, formula = y ~s(x)) You can see the model is better fit to the data, but always check the diagnostics.\ncheck.gam is quick and easy to view the residual plots.\npar(mfrow = c(2,2)) gam.check(gam_y) ## ## Method: REML Optimizer: outer newton ## full convergence after 5 iterations. ## Gradient range [-1.507556e-05,1.166151e-05] ## (score 32.01782 \u0026amp; scale 0.1196669). ## Hessian positive definite, eigenvalue range [1.865754,30.6761]. ## Model rank = 10 / 10 ## ## Basis dimension (k) checking results. Low p-value (k-index\u0026lt;1) may ## indicate that k is too low, especially if edf is close to k\u0026#39;. ## ## k\u0026#39; edf k-index p-value ## s(x) 9.00 5.49 1.29 0.99 Using summary with the model object will give you the significance of the smooth term (along with any parametric terms, if you’ve included them), along with the variance explained. In this example, a pretty decent fit. The ‘edf’ is the estimated degrees of freedom - essentially, the larger the number, the more wiggly the fitted model. Values of around 1 tend to be close to a linear term. You can read about penalisation and shrinkage for more on what the edf reflects.\nsummary(gam_y) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## y ~ s(x) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.07802 0.04358 1.79 0.0788 . ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(x) 5.491 6.632 33.08 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## R-sq.(adj) = 0.779 Deviance explained = 79.9% ## -REML = 32.018 Scale est. = 0.11967 n = 63 \n Smooth terms \nAs mentioned above, we’ll focus on splines, as they are the smooth functions that are most commonly implemented (and are pretty quick and stable). So what was actually going on when we specified s(x)?\nWell, this is where we say we want to fit \\(y\\) as a linear function of some set of functions of \\(x\\). The default in mgcv is a thin plate regression spline - the two common ones you’ll probably see are these, and cubic regression splines. Cubic regression splines have the traditional knots that we think of when we talk about splines - they’re evenly spread across the covariate range in this case. We’ll just stick to thin plate regression splines, since I figure Simon made them the default for a reason,\nBasis functions OK, so here’s where we see what the wiggle bit is really made of. We’ll start with the fitted model, then we’ll look at it from first principles (not really). Remembering that the smooth term is the sum of some number of functions (I’m not sure how well this equation really represents the smooth term, but you get the point), \\[f(x_1) = \\sum_{j=1}^kb_j(x_1)\\beta_j\\] First we extract the set of basis functions (that is, the \\(b_j(x_j)\\) part of the smooth term). Then we can plot say the first and second basis functions.\nmodel_matrix \u0026lt;- predict(gam_y, type = \u0026quot;lpmatrix\u0026quot;) plot(y ~ x) abline(h = 0) lines(x, model_matrix[, \u0026quot;s(x).1\u0026quot;], type = \u0026quot;l\u0026quot;, lty = 2) lines(x, model_matrix[, \u0026quot;s(x).2\u0026quot;], type = \u0026quot;l\u0026quot;, lty = 2) Let’s plot all of the basis functions now, and then add that to the predictions from the GAM (y_pred) on top again.\nplot(y ~ x) abline(h = 0) x_new \u0026lt;- seq(0, max(x), length.out = 100) y_pred \u0026lt;- predict(gam_y, data.frame(x = x_new)) matplot(x, model_matrix[,-1], type = \u0026quot;l\u0026quot;, lty = 2, add = T) lines(y_pred ~ x_new, col = \u0026quot;red\u0026quot;, lwd = 2) Now, it’s difficult at first to see what has happened, but it’s easiest to think about it like this - each of those dotted lines represents a function (\\(b_j\\)) for which gam estimates a coefficient (\\(\\beta_j\\)), and when you sum them you get the contribution for the corresponding \\(f(x)\\) (i.e. the previous equation). It’s nice and simple for this example, because we model \\(y\\) only as a function of the smooth term, so it’s fairly relatable. As an aside, you can also just use plot.gam to plot the smooth terms.\nplot(gam_y) OK, now let’s look a little closer at how the basis functions are constructed. You’ll see that the construction of the functions is separate to the response data. Just to prove it, we’ll use smoothCon.\nx_sin_smooth \u0026lt;- smoothCon(s(x), data = data.frame(x), absorb.cons = TRUE) X \u0026lt;- x_sin_smooth[[1]]$X par(mfrow = c(1,2)) matplot(x, X, type = \u0026quot;l\u0026quot;, main = \u0026quot;smoothCon()\u0026quot;) matplot(x, model_matrix[,-1], type = \u0026quot;l\u0026quot;, main = \u0026quot;predict(gam_y)\u0026quot;) And now to prove that you can go from the basis functions and the estimated coefficients to the fitted smooth term. Again note that this is simplified here because the model is just one smooth term. If you had more terms, we would need to add up all of the terms in the linear predictor.\nbetas \u0026lt;- gam_y$coefficients linear_pred \u0026lt;- model_matrix %*% betas par(mfrow = c(1,2)) plot(y ~ x, main = \u0026quot;manual from basis/coefs\u0026quot;) lines(linear_pred ~ x, col = \u0026quot;red\u0026quot;, lwd = 2) plot(y ~ x, main = \u0026quot;predict(gam_y)\u0026quot;) lines(y_pred ~ x_new, col = \u0026quot;red\u0026quot;, lwd = 2) Out of interest, take a look at the following plot, remembering that X is the matrix of basis functions.\npar(mfrow = c(1,2)) plot(y ~ x) plot(y ~ rowSums(X)) Not so scary huh? Of course this is not quite the whole story - see gam.models and smooth.terms to see all of the options for types of smoothers, how the basis functions are constructed (penalisation etc.), types of models we can specify (random effects, linear functionals, interactions, penalisation) plus much more.  A quick real example \nWe’ll now look at a quick real example - we’ll just scratch the surface, and in a future We’ll now look at a quick real example - we’ll just scratch the surface, and in a future tutorial we will look at it in more detail. We’re going to look at some CO\\(_2\\) data from Manua Loa. We will fit a couple GAMs to the data to try and pick apart the intra- and inter-annual trends.\nFirst load the data - you can download it here.\nCO2 \u0026lt;- read.csv(\u0026quot;mauna_loa_co2.csv\u0026quot;) We want to look at inter-annual trend first, so let’s convert the date into a continuous time variable (take a subset for visualisation).\nCO2$time \u0026lt;- as.integer(as.Date(CO2$Date, format = \u0026quot;%d/%m/%Y\u0026quot;)) CO2_dat \u0026lt;- CO2 CO2 \u0026lt;- CO2[CO2$year %in% (2000:2010),] OK, so let’s plot it and look at a smooth term for time. \\[y = \\beta_0 + f_{\\mathrm{trend}}(time) + \\varepsilon, \\quad \\varepsilon \\sim N(0, \\sigma^2)\\]\nggplot(CO2_dat, aes(time, co2)) + geom_line() We can fit a GAM for these data using:\nCO2_time \u0026lt;- gam(co2 ~ s(time), data = CO2, method = \u0026quot;REML\u0026quot;) which fits a model with a single smooth term for time. We can look at the predicted values for this:\nplot(CO2_time) Note how the smooth term actually reduces to a ‘normal’ linear term here (with an edf of 1) - that’s the nice thing about penalised regression splines. But if we check the model, then we see something is amuck.\npar(mfrow = c(2,2)) gam.check(CO2_time) The residual plots have a very odd looking rise-and-fall pattern - clearly there is some dependance structure (and we can probably guess it has something to do with intra-annual fluctuations). Let’s try again, and introduce something called a cyclical smoother. \\[y = \\beta_0 + f_{\\mathrm{intrannual}}(month) + f_{\\mathrm{trend}}(time) + \\varepsilon, \\quad \\varepsilon \\sim N(0, \\sigma^2)\\] The cyclical smooth term, \\(f_{\\mathrm{intrannual}}(month)\\), is comprised of basis functions just the same as we have seen already, except that the end points of the spline are constrained to be equal - which makes sense when we’re modelling a variable that is cyclical (across months/years).\nWe’ll now see the bs = argument to choose the type of smoother, and the k = argument to choose the number of knots, because cubic regression splines have a set number of knots. We use 12 knots, because there are 12 months.\nCO2_season_time \u0026lt;- gam(co2 ~ s(month, bs = \u0026#39;cc\u0026#39;, k = 12) + s(time), data = CO2, method = \u0026quot;REML\u0026quot;) Let’s look at the fitted smooth terms:\npar(mfrow = c(1,2)) plot(CO2_season_time) Looking at both smooth terms, we can see that the monthly smoother is picking up that monthly rise and fall of CO\\(_2\\) - looking at the relative magnitudes (i.e. monthly fluctuation vs. long-term trend), we can see how important it is to disintangle the components of the time series. Let’s see how the model diagnostics look now:\npar(mfrow = c(2,2)) gam.check(CO2_season_time) Much better. Let’s look at how the seasonal component stacks up against the full long term trend.\nCO2_season_time \u0026lt;- gam(co2 ~ s(month, bs = \u0026#39;cc\u0026#39;, k = 12) + s(time), data = CO2_dat, method = \u0026quot;REML\u0026quot;) par(mfrow = c(1,2)) plot(CO2_season_time) There’s more to the story - pephaps spatial autocorrelations of some kind? gam can make use of the spatial autocorrelation structures available in the nlme package, more on that next time. Hopefully for the meantime GAMs now don’t seem qutie so scary or magical, and you can start to make use of what is really an inrecibly flexible and powerful modelling framework. Communicating the results \nYou can essentially present model results from a GAM as if it were any other linear model, the main difference being that for the smooth terms, there is no single coefficient you can make inference from (i.e. negative, positive, effect size etc.). So you need to rely on either interpretting the parital effects of the smooth terms visually (e.g. from a call to plot(gam_model)) or make inference from the predicted values. You can of course include normal linear terms in the model (either continuous or categorical, and in an ANOVA type framework even) and make inference from them like you normally would. Indeed, GAMs are often useful for accounting for a non-linear phenomonon that is not directly of interest, but needs to be acocunted for when making inferece about other variables.\nYou can plot the partial effects by calling the plot function on a fitted gam model, and you can look at the parametric terms too, possibly using the termplot function too. You can use ggplot for simple models like we did earlier in this tutorial, but for more complex models, it’s good to know how to make the data using predict. We just use the existing time-series here, but you would generate your own data for the newdata= argument.\nCO2_pred \u0026lt;- data.frame(time = CO2_dat$time, co2 = CO2_dat$co2, predicted_values = predict(CO2_season_time, newdata = CO2_dat)) ggplot(CO2_pred, aes(x = time)) + geom_point(aes(y = co2), size = 1, alpha = 0.5) + geom_line(aes(y = predicted_values), colour = \u0026quot;red\u0026quot;)  Further help \nThe R help ?gam is very good, and there is masses of information to read Check out ?gamm, ?gamm4 and ?bam Use citation(\"mgcv\") for a range of papers with more technical explanations - the book on GAMs with R is particularly good (there’s a 2017 version) A great blog with lots of stuff on GAMs: https://www.fromthebottomoftheheap.net/\n\nAuthor: Mitchell Lyons Last updated:\n## [1] \u0026quot;Mon Jan 24 2022\u0026quot;   "
},
{
	"uri": "/graphics/",
	"title": "Graphics",
	"tags": [],
	"description": "",
	"content": "  R has a very wide range of functions and packages for visualising data.\nThese pages have a brief introduction to:\n Basic plotting in R More advanced plotting with ggplot Visualising multivariate data Visualising spatial data (incl. mapping)  "
},
{
	"uri": "/getting-started-with-r/importing-data/",
	"title": "Importing Data",
	"tags": [],
	"description": "",
	"content": "  Before we can run any data analyses or create figures in R, we need to import that data into R. Preparing and cleaning the data for analyses is essential and often more time consuming than the statistical analyses themselves. It is unusual for raw data to be in the correct format and without errors. Data cleaning is the process of identifying and fixing any problems so data can be analysed easily.\nImporting data is a major challenge for beginners. This module will give instructions for one of most common ways we import data, and some of challenges you may face and how to overcome them. Some of these issues can be avoided by following good data entry and management practices (first read Data entry to get help with this. Importing data as a data frame \nWe recommend entering data into a spreadsheet program (e.g., Excel), and saving that data as a comma separated values (.csv) file. These are easily read into R and shared among users with different spreadsheet programs.\nIn this module, we are going to use a sample data set on feeding behaviour of a marine snail to demonstrate how to import the data, and the most common issues that arise with data import and cleaning in R.\nFirst, save the data file, Snail_feeding.csv to your working directory. See Getting started with R for help on for setting the working directory.\nSecond, import the data file to a data frame called Snail_feeding with the read.csv function.\nSnail_feeding \u0026lt;- read.csv(\u0026quot;Snail_feeding.csv\u0026quot;) \n Cleaning data frames \nWhen you use read.csv, R uses several default arguments which can be altered to ensure your data are imported with fewer errors. Have a look at the help file within R (by typing ?read.csv to familiarise yourself with some of these arguments.\nThe ones that are particularly useful are:\nheader = T - specifying this at T (i.e., TRUE) will ensure that the values in the first row of your data are treated as variable names.\nstrip.white = T - this will remove trailing and leading white space from factors. This is a common typing error made during data entry (i.e., “males” vs. “males_”). If we set this as TRUE, they both become “males”, otherwise R will think there are two different levels.\nna.strings = \"\" - this will ensure that empty cells are replaced by NA (the way R records missing data). Annoyingly, R imports missing values within characters/factors types as a value ““. Using na.strings = \"\" will insert NAs instead. In addition, if you have coded missing values as something other then blank space you can define that missing value using this argument (i.e na.strings = c(\"\", \"-\", \"*\")).\nPutting all these together in the read.csv function will give us a cleaner data frame.\nSnail_feeding \u0026lt;- read.csv(\u0026quot;Snail_feeding.csv\u0026quot;, header = T, strip.white = T, na.strings = \u0026quot;\u0026quot;) \n Checking the data \nIf something is a character when it should be numeric you might see messages such as “‘x’ must be numeric” or “non-numeric argument to binary operator”. Likewise, if something is a factor when it should be character, some character operations might fail. To avoid some of these issues, check your data using str and summary before analyses.\nstr enables you to check the structure of your data and that your variables are the correct type (i.e., numeric, characters, integers, or factors). See Data types and structure for explanations of these different types.\nstr(Snail_feeding) ## \u0026#39;data.frame\u0026#39;: 768 obs. of 12 variables: ## $ Snail.ID: int 1 1 1 1 1 1 1 1 1 1 ... ## $ Sex : chr \u0026quot;male\u0026quot; \u0026quot;male\u0026quot; \u0026quot;males\u0026quot; \u0026quot;male\u0026quot; ... ## $ Size : chr \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; ... ## $ Feeding : logi FALSE FALSE FALSE FALSE FALSE TRUE ... ## $ Distance: chr \u0026quot;0.17\u0026quot; \u0026quot;0.87\u0026quot; \u0026quot;0.22\u0026quot; \u0026quot;0.13\u0026quot; ... ## $ Depth : num 1.66 1.26 1.43 1.46 1.21 1.56 1.62 162 1.96 1.93 ... ## $ Temp : int 21 21 18 19 21 21 20 20 19 19 ... ## $ X : logi NA NA NA NA NA NA ... ## $ X.1 : logi NA NA NA NA NA NA ... ## $ X.2 : logi NA NA NA NA NA NA ... ## $ X.3 : logi NA NA NA NA NA NA ... ## $ X.4 : logi NA NA NA NA NA NA ... summary allows you to look at basic statistics for each of your variables and can be used to identify any obvious typos (i.e., extreme maximums or minimums relative to the mean or median or extra groups within a categorical vector).\nsummary(Snail_feeding) ## Snail.ID Sex Size Feeding Distance Depth Temp X X.1 X.2 X.3 X.4 ## Min. : 1.00 Length:768 Length:768 Mode :logical Length:768 Min. : 1.000 Min. :18.00 Mode:logical Mode:logical Mode:logical Mode:logical Mode:logical ## 1st Qu.: 4.75 Class :character Class :character FALSE:502 Class :character 1st Qu.: 1.260 1st Qu.:19.00 NA\u0026#39;s:768 NA\u0026#39;s:768 NA\u0026#39;s:768 NA\u0026#39;s:768 NA\u0026#39;s:768 ## Median : 8.50 Mode :character Mode :character TRUE :266 Mode :character Median : 1.510 Median :19.00 ## Mean : 8.50 Mean : 1.716 Mean :19.49 ## 3rd Qu.:12.25 3rd Qu.: 1.760 3rd Qu.:20.00 ## Max. :16.00 Max. :162.000 Max. :21.00 ## NA\u0026#39;s :6 Note that for the factor of sex, errors in data entry resulted in five levels (female, female s, male, Male and males) when there should be only two. See below for the fix.  Common problems when importing data \nYou don’t get the number of columns or rows you expect If you see a bunch of extra columns (X, X.1,X.2,X.3 etc) or rows in your data frame filled with NAs its likely because a character (most likely white space(i.e. space bar or tab) was entered in cells beyond your actual data in Excel. This problem can be avoided during data entry by removing all the colors/formatting and emptying columns/rows except for those needed.\nIf the problem is still there we can tackle it in R, by indexing within square brackets dataframe[row, column]. For example, the following code will replace the data frame in this example with one that only includes the first 7 columns and removes the 5 unwanted ones (X, X.1,X.2,X.3 etc).\nSnail_feeding \u0026lt;- Snail_feeding[,1:7] The package dplyr has several very neat functions for subsetting rows and columns - see Subsetting data for help with these.\nIf you had very many columns and didn’t want to count them, you could use logic (\u0026amp;, or, ==, \u0026gt;, \u0026lt; , !=) to remove the unwanted rows and columns. We don’t want to remove all NAs, only additional rows and columns that are entirely filled with NAs. These have the property of the number of NAs being equal to the number of rows in a given column (or number of columns in a given row).\nWe do this by selecting columns from our data frame where the column sum, colSums, of all the NAs, \u0026gt;is.na, in our data frame are not equal, != to the number of rows, nrow, of our data frame. Using the same logic you can do this for rows as well.\n# Selects rows that are not entirely NA Snail_feeding \u0026lt;- Snail_feeding[, colSums(is.na(Snail_feeding)) != nrow(Snail_feeding)] # Select columns that are not entirely NA Snail_feeding \u0026lt;- Snail_feeding[rowSums(is.na(Snail_feeding)) != ncol(Snail_feeding), ]  \nThe columns are not the type of data you expect Characters as factors When data frames are imported into R, characters are automatically coerced as factors. For statistical work this makes a lot of sense; we are more likely to want to work over factors (defined earlier) than over characters. Factors are fantastic when one is doing statistical analysis and actually exploring the data. However, prior to that when one is reading, cleaning, troubleshooting, merging and generally manipulating the data, factors are a total pain.\nYou can use the argument stringsAsFactors=FALSE when importing the data to avoid automatic coercion to factors or you can use as.character to convert individual vectors to characters.\nTip: Use factors as late as possible in the analysis process. Set stringsAsFactors=FALSE when importing your data, and when you need factors someplace within your script, then coerce the data to a factor.\nFactors as integers In this data frame, Snail ID is an integer where it should be a factor or character. This is because in the original data sheet Snail ID was coded using numbers. This is a common problem and is easy to fix. Simply use as.factor() or as.character(), and then class() to check our coercion worked. Remember to use $ to access the vector from within the data frame.\nSnail_feeding$Snail \u0026lt;- as.factor(Snail_feeding$Snail) class(Snail_feeding$Snail) ## [1] \u0026quot;factor\u0026quot; \nNumerics as characters (factors) Due to the automatic coercion in R, any non-numeric digits within a numerical variable will result in the whole variable being coerced to a character (R imports as factors). In this example, the variable Distance has been imported as a factor with 768 levels, when we would like it to be a numerical variable. This indicates a typo somewhere within the distance vector. Such typos are common (e.g., accidentally using comma instead of full stop when entering decimals), but a little trickier to solve.\nWith a small data set, it is quickest to go back to the original data and find the error. Once fixed, import again and the variable should now be numeric.\nWith a larger data set, we have the problem of needing to find the typos. Unfortunately, we can’t just convert our data straight into numeric from a vector of type Factor. This is because of the levels attribute (see Data types and structure). If you try and convert a factor directly to a numerical variable, the values become a number that corresponds to the number of levels (1:n, ordered alphabetically or ascending) rather than the actual value.\nThus, we must first convert to a character and then to a numeric. When converting to a numeric, you will get a warning message, NAs introduced by coercion. This is because the non numeric values (i.e., our typos) cannot be coerced to a numeric and get replaced by NA.\nWe can use this to our advantage, is.na in combination with which will identify where the typos or missing values are within the vector.\nSnail_feeding$Distance \u0026lt;- as.character(Snail_feeding$Distance) Snail_feeding$Distance \u0026lt;- as.numeric(Snail_feeding$Distance) ## Warning: NAs introduced by coercion which(is.na(Snail_feeding$Distance)) ## [1] 682 755 This tells us that something weird happened in rows 682 and 755. Now we have identified where the problem is, it is simple to replace values within our data frame with correct values (go back to your original datasheet). You could either fix the error in the data set and import again, or replace values in R by indexing within square bracketsand assigning, \u0026lt;-, the new value. Use which(is.na()) to check if your fix worked.\nSnail_feeding[682,\u0026quot;Distance\u0026quot;] \u0026lt;- 0.356452 Snail_feeding[755,\u0026quot;Distance\u0026quot;]\u0026lt;- 0.42336 which(is.na(Snail_feeding$Distance)) ## integer(0) \nYou have more variable levels then expected One of the most important steps in any data analyses or processing task is to verify that your data values are correct. For example a variable called “Sex” would be expected to have only two levels. However in our data frame it has five levels (see str and summary above).\nYou can check the levels of a factor, or unique character values with levels (for factors only), or unique (for characters and factors).\nlevels(Snail_feeding$Sex) ## NULL unique (Snail_feeding$Sex) ## [1] \u0026quot;male\u0026quot; \u0026quot;males\u0026quot; \u0026quot;Male\u0026quot; \u0026quot;female\u0026quot; \u0026quot;female s\u0026quot; There are several typos which we can correct with unique and which and the logical operators == (equals) and | (or) to identify and replace typos.\nTo replace any values that are are “males” or “Male” with “male”, we would use:\nSnail_feeding$Sex[which(Snail_feeding$Sex == \u0026quot;males\u0026quot; | Snail_feeding$Sex == \u0026quot;Male\u0026quot;)] \u0026lt;- \u0026quot;male\u0026quot; To replace any values that are “female s” with “female”, we would use:\nSnail_feeding$Sex[which(Snail_feeding$Sex == \u0026quot;female s\u0026quot;)] \u0026lt;- \u0026quot;female\u0026quot; Check it worked using unique, but also look what happens when you check levels.\nunique(Snail_feeding$Sex) ## [1] \u0026quot;male\u0026quot; \u0026quot;female\u0026quot; levels(Snail_feeding$Sex) ## NULL When we use unique to check our categories there are just male and female, however when we look at levels we still have the five different levels including the typos. This is because of the behavior of factors. Once the levels have been defined, they will still be there regardless if they are included in any samples. As our extra levels were typos not true levels, we should remove these from the attributes.\nfactor will remove extra levels from a vector.\nSnail_feeding$Sex \u0026lt;- factor(Snail_feeding$Sex) levels(Snail_feeding$Sex) ## [1] \u0026quot;female\u0026quot; \u0026quot;male\u0026quot; \nNumeric typos Using summary above is a useful tool to check for potential typos within our numeric variables. Compare the Max or Min against the Median of each numeric variable. If either value is an order of magnitude greater or less then your median it could be a typo. For example look at the max depth, this looks like the decimal point has been forgotten.\nAgain we, can use logical operators and indexing to identify potential numeric typos. Given all the values of our depth variable appear to be between 1 and 2 (based on inter quartile ranges from summary), we will look for rows with a depth greater then 2.\nSnail_feeding[which(Snail_feeding$Depth \u0026gt; 2), ] ## Snail.ID Sex Size Feeding Distance Depth Temp Snail ## 8 1 male small TRUE 0.6 162 20 1 There is only 1 row. After confirming with our original data that this is in fact a typo we will replace it with the real value. Selecting the row and column we replace the value 162 with 1.62.\nSnail_feeding[which(Snail_feeding$Depth \u0026gt; 2),6] \u0026lt;- 1.62 \n Why do this in R ? \nYou might be wondering why go through the trouble of fixing this in R? Why not just go to the .csv file and fix all the problems directly. It is usually OK to do this if you know the problem is a typo etc. However to maintain data integrity it is important to have a record of every change that has been made to your original data set. By doing all the manipulations and fixes in R, you are also keeping a record of all the changes that are occurring to your data.\nAlso, you may want to start to explore data before you have collected the entire data set. If you set up a script that checks all of these things before making graphs and running analyses, it is quick to run the script again on the full data once you have it all. The script acts to remind you of all the things to check and is better at picking up typos than you are in a huge spreadsheet.  The final check \nFinally, once you have checked and fixed all the problems in your data re run str and summary. Actually it is a good idea to run these functions regularly throughout data cleaning to keep tabs on any changes you make.\nstr(Snail_feeding) ## \u0026#39;data.frame\u0026#39;: 768 obs. of 8 variables: ## $ Snail.ID: int 1 1 1 1 1 1 1 1 1 1 ... ## $ Sex : Factor w/ 2 levels \u0026quot;female\u0026quot;,\u0026quot;male\u0026quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Size : chr \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; \u0026quot;small\u0026quot; ... ## $ Feeding : logi FALSE FALSE FALSE FALSE FALSE TRUE ... ## $ Distance: num 0.17 0.87 0.22 0.13 0.36 0.84 0.69 0.6 0.85 0.59 ... ## $ Depth : num 1.66 1.26 1.43 1.46 1.21 1.56 1.62 1.62 1.96 1.93 ... ## $ Temp : int 21 21 18 19 21 21 20 20 19 19 ... ## $ Snail : Factor w/ 16 levels \u0026quot;1\u0026quot;,\u0026quot;2\u0026quot;,\u0026quot;3\u0026quot;,\u0026quot;4\u0026quot;,..: 1 1 1 1 1 1 1 1 1 1 ... summary(Snail_feeding) ## Snail.ID Sex Size Feeding Distance Depth Temp Snail ## Min. : 1.00 female:384 Length:768 Mode :logical Min. :0.0000 Min. :1.000 Min. :18.00 1 : 48 ## 1st Qu.: 4.75 male :384 Class :character FALSE:502 1st Qu.:0.2775 1st Qu.:1.260 1st Qu.:19.00 2 : 48 ## Median : 8.50 Mode :character TRUE :266 Median :0.5100 Median :1.510 Median :19.00 3 : 48 ## Mean : 8.50 Mean :0.5120 Mean :1.507 Mean :19.49 4 : 48 ## 3rd Qu.:12.25 3rd Qu.:0.7500 3rd Qu.:1.760 3rd Qu.:20.00 5 : 48 ## Max. :16.00 Max. :1.0000 Max. :2.000 Max. :21.00 6 : 48 ## NA\u0026#39;s :6 (Other):480 \n Further help \nIntro to data cleaning in R by de jonge and van de Loo\nR-bloggers- common errors in table import Author: Keryn Bain Last updated:\n## [1] \u0026quot;Tue Jan 18 18:23:23 2022\u0026quot;  "
},
{
	"uri": "/data-manipulation/reshaping-data/",
	"title": "Reshaping data",
	"tags": [],
	"description": "",
	"content": "  Learning how to format data is an essential skill to allow you to easily produce figures and run analyses. You should always aim for data that are formatted with each observation as a row and each variable as a column (see help on Data entry). For some types of variables, however, there are choices to be made about how you input the data.\nFor example, it is very common in the biological sciences that we record the abundance of many species of organisms from each of our replicate observations (transects, quadrats, surveys etc). We then have two choices for how to input that data:\n1. a separate column for every species that records its abundance, or,\n2. two columns - one that identifies the species and one that records the abundance.\nConsider a data set that recorded the abundance of fish from each of three transects that were set up on two reefs in two separate months. First, import this sample data set, ReefFish.csv, to see the way it is formatted.\nReefFish \u0026lt;- read.csv(file=\u0026quot;ReefFish.csv\u0026quot;, header =T) ## Site Month Transect Species Abundance ## 1 Reef1 January 1 RedFish 4 ## 2 Reef1 January 1 BlueFish 5 ## 3 Reef1 January 1 BlackFish 10 ## 4 Reef1 January 2 RedFish 42 ## 5 Reef1 January 2 BlueFish 13 ## 6 Reef1 January 3 RedFish 3 This data frame is arranged in a long format with one variable that identifies the fish species, and one variable that holds the abundance data. The other three variables identify each transect (Site, Month and Transect),\nThis format is efficient for data entry as you only need to have rows for the species that were present in that particular transect, and don’t have to keep adding columns every time a new species is recorded. You would need the data in this format if you wanted to use a plot to contrast the abundance of fish among the three species.\nIf, however, you would like to contrast the abundance of one of the species, or create a species by sample matrix that is required by the various multivariate analyses that contrast species composition, the data will need to be manipulated in some way.\nFortunately, there are some very handy packages in R that make this possible. If you have ever used pivot tables in Excel, they are doing similar things. Reshaping from long to wide format \nIn this example, we will use the package tidyr to convert this data frame to a wide format that will allow further data exploration. First, install and load the package.\nlibrary(tidyr) To convert this data set into a wide format with a separate column for each fish species, we use the function spread.\nReefFish.wide \u0026lt;- spread(ReefFish, Species, Abundance, fill = 0) The arguments of spread are:\n* The data frame you would like to convert (in this case, ReefFish)\n* The variable whose levels are being converted to new columns (in this case, Species)\n* The variable that holds the values that will fill in the new columns (in this case, Abundance)\n* fill=0 tells spread to fill in a zero for when a species was missing from a given transect.\n## Site Month Transect BlackFish BlueFish RedFish ## 1 Reef1 February 1 47 12 52 ## 2 Reef1 February 2 69 3 0 ## 3 Reef1 February 3 0 0 8 ## 4 Reef1 January 1 10 5 4 ## 5 Reef1 January 2 0 13 42 ## 6 Reef1 January 3 8 0 3 Note that the wide format of this data now has a column for each species with all the abundance values. You would get as many columns as you had unique levels in the Species column. You get as many rows as you have unique combinations of the variables that are not being split up (Site, Month and Transect in this example).\nYou can now plot or analyse any single species against possible predictor variables of Site or Month. Multivariate analyses of species composition against possible predictor variables also need each of the species to be in separate columns. You can select them from this data frame with the select function of dplyr (see Subsetting data).\n*Note that if you had a transect with no fish observations, you would need to add a row to the original data set, perhaps with a species code of “none”. If you didn’t, that replicate observation would be missing from the wide format - needed if you want to contrast abundance across reefs etc.  Reshaping from wide to long format \nThe function gather will convert data from the wide format to a long format.\nHere, we can use this code to get our original data set back from the wide format data set we just made.\nReefFish.long \u0026lt;- gather(ReefFish.wide, Species, Abundance, 4:6) ## Site Month Transect Species Abundance ## 1 Reef1 February 1 BlackFish 47 ## 2 Reef1 February 2 BlackFish 69 ## 3 Reef1 February 3 BlackFish 0 ## 4 Reef1 January 1 BlackFish 10 ## 5 Reef1 January 2 BlackFish 0 ## 6 Reef1 January 3 BlackFish 8 The arguments of gather are:\n* The data frame that we would like to convert\n* key - the name of the new variable that will hold the names of the variables being gathers (in this case, Species)\n* value - the name of the new variable that will hold the values from the variables being gathered (in this case, Abundance)\n* the names of the columns to be gathered (by name or by column number)\nIn that code, we chose the three variables with the species data by their column numbers (4 to 6). We could also just use their names, or the first and last column in a sequence of columns. For example,\nReefFish.long \u0026lt;- gather(ReefFish.wide, Species, Abundance, BlackFish, BlueFish, RedFish) ReefFish.long \u0026lt;- gather(ReefFish.wide, Species, Abundance, BlackFish:RedFish) We have now recreated our original data set. The only difference is that the rows have been sorted and that species that were absent from a given transect have their own row with an abundance value of zero.  Reshaping with reshape2 \nThe package reshape2 also allows us to reshape data, and has a few extra capabilities that are not present in tidyr.\nlibrary(reshape2) Instead of spread, dcast is used to go from a long to wide format. This code will do the same as we saw above.\nReefFish.wide \u0026lt;- dcast(ReefFish, Site + Month + Transect ~ Species, value.var = \u0026quot;Abundance\u0026quot;, fill = 0) The arguments of dcast are:\n* The data frame you would like to convert (in this case, ReefFish)\n* The variable(s) you would like to include unchanged as columns in the new data frame are to the left of the ~ (Site, Month and Transect)\n* The variable(s) that is being converted to new columns are to the right of the ~ (in this case, Species)\n* The variable that holds the values that will fill in the new columns (specified by value.var, in this case, Abundance.\n* fill=0 tells dcast to fill in zeroes for when a species was missing from a given transect.\nInstead of gather, melt is used to go from a wide to long format.\nReefFish.long \u0026lt;- melt(ReefFish.wide, id.vars = c(\u0026quot;Site\u0026quot;,\u0026quot;Month\u0026quot;,\u0026quot;Transect\u0026quot;), measure.vars = c(\u0026quot;RedFish\u0026quot;,\u0026quot;BlueFish\u0026quot;,\u0026quot;BlackFish\u0026quot;), variable.name = \u0026quot;Species\u0026quot;, value.name = \u0026quot;Abundance\u0026quot;) The arguments of melt are:\n* The data frame that we would like to convert\n* id.vars specifies the columns that remain unchanged (here the predictor variables that label each replicate observation)\n* measure.vars specifies which variables hold the data that will go into the new column * variable.name and value.name provide the names of the new column.\nWhat reshape2 can do that tidyr cannot is the ability to summarise data as you reshape from long to wide.\nIn the above example, there was only one row that belonged to each combination of Site, Month and Transect. If there are duplicate rows for each combination of the variables that you want to keep in the new data frame (the ones to the left of the ~) you need to tell dcast how you would like to deal with the duplicates (e.g., add them up or calculate their mean)\nFor example, if we wanted to pool the transects from each survey, we could remove Transect from the list of variables to include in the new data frame and add an argument (fun.aggregate = sum) to tell dcast that we would like to add up the values from the three transects in each Site/Month combination.\nReefFish.wide_sum \u0026lt;- dcast(ReefFish, Site + Month ~ Species, value.var = \u0026quot;Abundance\u0026quot;, fun.aggregate = sum, fill = 0) ## Site Month BlackFish BlueFish RedFish ## 1 Reef1 February 116 15 60 ## 2 Reef1 January 18 18 49 ## 3 Reef2 February 42 106 18 ## 4 Reef2 January 137 110 29 If we wanted the mean of the three transects, we can use fun.aggregate = mean.\nReefFish.wide_mean \u0026lt;- dcast(ReefFish, Site + Month ~ Species, value.var = \u0026quot;Abundance\u0026quot;, fun.aggregate = mean, fill = 0) You can also put more complex expressions in the reshape formula to create new variables that are combinations of old ones. For example, you could create a new column for each of the combinations of Species and Month by adding both variables to the right of the ~\nReefFish.wide_combined \u0026lt;- dcast(ReefFish, Site + Transect ~ Species + Month, value.var = \u0026quot;Abundance\u0026quot;, fill = 0) ## Site Transect BlackFish_January BlueFish_February BlueFish_January ## 1 Reef1 1 10 12 5 ## 2 Reef1 2 0 3 13 ## 3 Reef1 3 8 0 0 ## 4 Reef2 1 72 0 0 ## 5 Reef2 2 0 22 9 ## 6 Reef2 3 65 84 101 ## RedFish_February RedFish_January ## 1 52 4 ## 2 0 42 ## 3 8 3 ## 4 0 5 ## 5 3 0 ## 6 15 24 \n Further help \nType ?gather and ?spread to get the R help for these tidyr functions.\nType ?dcast and ?melt to get the R help for these reshape2 functions.\nData wrangling with dplyr and tidyr cheat sheet produced by Rstudio.\nData wrangling with dplyr and tidyr\nAn introduction to reshape2 Author: Alistair Poore Last updated:\n## [1] \u0026quot;Fri Jan 21 15:53:45 2022\u0026quot;  "
},
{
	"uri": "/graphics/spatial-vis/",
	"title": "Spatial Data",
	"tags": [],
	"description": "",
	"content": "  R has a very wide range of functions and packages for visualising spatial data. This page will link to a series of tutorials for handling spatial data and making maps.\n Making simple maps with ggmap\n [Making maps from shapefiles] More soon…  "
},
{
	"uri": "/statistics/catagorical/",
	"title": "Catagorial Data Analyses",
	"tags": [],
	"description": "",
	"content": "  Some commonly used tests for contrasting the counts of observations across categorical variables.\n Goodness of fit tests\n Contingency tables  "
},
{
	"uri": "/getting-started-with-r/data-types-structure/",
	"title": "Data Types + Structure",
	"tags": [],
	"description": "",
	"content": "  One of the most common sources of frustration for beginners in R is dealing with different data structures and types. Here is an overview of the most important data structures, types and how to check and manipulate them.\nThe terms ‘structure’ and ‘type’ are often used interchangable. To avoid confusion, for this help page, data structure refers whether the data is a vector, matrix or data frame etc. and type refers to whether the data or variable is an integer, character or numeric etc. One dimensional data (vectors) \nThe most basic data structure in R is a vector, a one-dimensional set of numbers or characters. This is the data structure that you will work with the most, albeit from within a data frame (see below). Vectors can be either atomic or list, atomic vectors differ to lists in that all elements within an atomic vector must be of the same type (see below). For the most part we work with atomic vector and the following help file refers to this type of data.\nCommon types of vectors \nCommon types of atomic vectors are logical, integer, numeric (i.e., double), character and factor. You can easily create each of these data types by using c(). In the integer example, the L forces R to consider those numbers as integers rather than numerical. eg_logical \u0026lt;- c(T, T, T, F, F) eg_integer \u0026lt;- c(1L, 6L, 1L, 5L, 4L) eg_numeric \u0026lt;- c(0, 2.3, 2.45, 2.99, -1.1) eg_character \u0026lt;- c(\u0026quot;things\u0026quot;, \u0026quot;in\u0026quot;, \u0026quot;apostrophe\u0026quot; ,\u0026quot;are\u0026quot;, \u0026quot;characters\u0026quot;) eg_factor \u0026lt;- factor(c(\u0026quot;NSW\u0026quot;, \u0026quot;NSW\u0026quot;, \u0026quot;ACT\u0026quot;, \u0026quot;WA\u0026quot;, \u0026quot;WA\u0026quot;)) \n Factors (a special data type) \nNotice how I couldn’t just use the c() to create a factor. Though factors look (and behave for the most part) like characters, they are actually a special type of integer with predefined categories, known as levels. The factor in this example has three levels: NSW, ACT and WA.\nYou can check how many levels any factor has using:\nlevels(eg_factor) ## [1] \u0026quot;ACT\u0026quot; \u0026quot;NSW\u0026quot; \u0026quot;WA\u0026quot; This makes them behave differently to integers. Once created, factors can only contain a pre-defined set levels. For example, if you collecting data from sites across Australia you could have the fixed number of states as a factor, but it would be better to have a variable like site as a character if you were going to add data from more sites later on.\nBy default, R will always sort levels in alphabetical order. If you want your factors to be ordered (i.e., small, medium, high), use ordered to define the sequence you would like the levels to be presented. This is particularly useful for graphics to present the categories along an x axis in a more logical order.\nsizes \u0026lt;- factor(c(\u0026quot;small\u0026quot;, \u0026quot;large\u0026quot;, \u0026quot;large\u0026quot;, \u0026quot;small\u0026quot;, \u0026quot;medium\u0026quot;)) sizes ## [1] small large large small medium ## Levels: large medium small sizes \u0026lt;- ordered(sizes, levels = c(\u0026quot;small\u0026quot;, \u0026quot;medium\u0026quot;, \u0026quot;large\u0026quot;)) sizes ## [1] small large large small medium ## Levels: small \u0026lt; medium \u0026lt; large See here for more info on ordered factors.  Checking data types \nYou can check the data type of any vector using the class or is functions.\nclass(eg_logical) ## [1] \u0026quot;logical\u0026quot; is.integer(eg_integer) ## [1] TRUE is.factor(eg_factor) ## [1] TRUE \n Automatic coercion \nAs all elements within an atomic vector must be the same type, combining different types will coerce the data to the most flexible. Types from least to most flexible are: logical, integer, double, and character. For example, combining and integers and character will produce a character vector. This is something to be aware whilst manipulating your own data, especially when merging data frames.\neg_coerced \u0026lt;- c(\u0026quot;tricks\u0026quot;, 1, 2, 3, 4) class(eg_coerced) ## [1] \u0026quot;character\u0026quot; \n Coercing data \nIf you find your data is the wrong type, you can use the as functions to coerce data from one type to another. Be aware of what happens to your data after coercion. For example, coercing logical to numeric replaces F with 0s and Ts with 1s and any nonsensical coercion (like trying to make character “NSW” into a numeric) will result in NAs.\nas.numeric(eg_logical) ## [1] 1 1 1 0 0 as.numeric(eg_character) ## Warning: NAs introduced by coercion ## [1] NA NA NA NA NA \n  Two dimensional data (matrices and data frames) \nFor the most part, we tend to work with two dimensional data containing both columns and rows. Like the one dimensional vectors, they come in two forms: matrices, where all vectors must be of all the same type of data, and data frames, which can be made up of vectors containing different data types. Matrices \nMatrices are easily constructed in R and can you check if its a matrix using the class function. For example, to make a matrix with 3 rows and 2 columns with 6 values:\neg_matrix \u0026lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 3, ncol = 2) ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 Think of matrices as atomic vectors with dimensions; the number of rows and columns. Like atomic matrices, you can check the type of data with is and coerce using the as functions.\nis.logical(eg_matrix) ## [1] FALSE as.numeric(eg_logical) ## [1] 1 1 1 0 0 \n Data frames \nThe most common data structure we work with is the data frame. Data frames are just a collection of atomic vectors of equal length stuck together. They are different to matrices as they can contain vectors of different types.\nTo make a simple data frame that combines three of the vectors we made above, we could use:\neg_data_frame \u0026lt;- data.frame(eg_character, eg_factor, eg_numeric) ## eg_character eg_factor eg_numeric ## 1 things NSW 0.00 ## 2 in NSW 2.30 ## 3 apostrophe ACT 2.45 ## 4 are WA 2.99 ## 5 characters WA -1.10 More commonly, we import data entered into a spreadsheet straight into a data frame using read.csv (see help Importing data).\nTo check the data types within a data frame, use the str function. This gives an output listing for each column (i.e., variables) and the respective data type.\nstr(eg_data_frame) ## \u0026#39;data.frame\u0026#39;: 5 obs. of 3 variables: ## $ eg_character: chr \u0026quot;things\u0026quot; \u0026quot;in\u0026quot; \u0026quot;apostrophe\u0026quot; \u0026quot;are\u0026quot; ... ## $ eg_factor : Factor w/ 3 levels \u0026quot;ACT\u0026quot;,\u0026quot;NSW\u0026quot;,\u0026quot;WA\u0026quot;: 2 2 1 3 3 ## $ eg_numeric : num 0 2.3 2.45 2.99 -1.1 Note that data types can change. In this example, the character vector has been coerced to a factor in the process of making the data frame.\nIf you wish to check the data type of just one variable, or change that variable to another type, we use $ to access that variable from within the data frame. For example:\nstr(eg_data_frame$eg_character) ## chr [1:5] \u0026quot;things\u0026quot; \u0026quot;in\u0026quot; \u0026quot;apostrophe\u0026quot; \u0026quot;are\u0026quot; \u0026quot;characters\u0026quot; levels(eg_data_frame$eg_factor) ## [1] \u0026quot;ACT\u0026quot; \u0026quot;NSW\u0026quot; \u0026quot;WA\u0026quot; is.numeric(eg_data_frame$numeric) ## [1] FALSE \n  Further help \nFurther information on data types in R can be found here and here Author: Keryn Bain Last updated:\n## [1] \u0026quot;Tue Jan 18 18:26:28 2022\u0026quot;  "
},
{
	"uri": "/statistics/",
	"title": "Statistics",
	"tags": [],
	"description": "",
	"content": "  These pages have some introductions to a wide range of commonly used statistical analyses in the environmental sciences.\nSome simple hypothesis tests with the t statistic:\n One sample t tests - contrasting a single sample parameter to a population parameter\n Independent samples - contrasting the means of two samples Paired t-tests - contrasting two groups when data are paired  Linear models:\n Linear regression Analysis of variance: single factor Analysis of variance: factorial\n Understanding interactions  Generalised linear models:\n Generalised linear models 1: Introduction and binomial data\n Generalised linear models 2: Count data  Mixed models:\n Mixed models 1: Linear mixed models with one random effect\n Mixed models 2: Linear mixed models with several random effects\n Mixed models 3: Generalised linear mixed models  Generalised additive models\nCategorical data analyses:\n Goodness of fit tests\n Contingency tables  Power analyses: calculating power and deciding on sample sizes\nIntroduction to mvabund: model-based analysis of multivariate abundance data\nForecasting with time series\nMeta-analyses\n Meta-analyses 1: Introduction and calculating effect sizes\n Meta-analyses 2: Fixed effect and random effect models\n Meta-analyses 3: More complex models  \nLast updated:\n## [1] \u0026quot;Fri Jan 21 15:51:54 2022\u0026quot; "
},
{
	"uri": "/statistics/mvabund/",
	"title": "Multivariate Analysis with mvabund",
	"tags": [],
	"description": "",
	"content": "  Multivariate data are common in the environmental sciences, occurring when ever we measure several response variables from each replicate sample. Questions like how does the species composition of a community vary across sites, or how does the shape of trees (as measured by several morphological traits) vary with altitude are multivariate questions.\nWe will use the package mvabund to specify and fit multivariate statistical models to these sorts of data.\nHow does this method differ from other multivariate analyses? Many commonly used analyses for multivariate data sets (e.g. PERMANOVA, ANOSIM, CCA, RDA etc.) are “distance-based analyses”. This means the first step of the analysis is to calculate a measure of similarity between each pair of samples, thus converting a multivariate dataset into a univariate one.\nThere are a couple of problems with these kinds of analysis. First, their statistical power is very low, except for variables with high variance. This means that for variables which are less variable, the analyses are less likely to detect a treatment effect. Second, they do not account for a very important property of multivariate data, which is the mean-variance relationship. Typically, in multivariate datasets like species-abundance data sets, counts for rare species will have many zeros with little variance, and the higher counts for more abundant species will be more variable.\nThe mvabund approach improves power across a range of species with different variances and includes an assumption of a mean-variance relationship. It does this by fitting a single generalised linear model (GLM) to each response variable with a common set of predictor variables. We can then use resampling to test for significant community level or species level responses to our predictors.\nAlso, the model-based framework makes it easier to check our assumptions and interpret uncertainty around our findings.\nIf you’re interested in this method, watch the introductory video, Introducing mvabund and why multivariate statistics in ecology is a bit like Rick Astley…\nIn this example, we use a data set where researchers wanted to contrast the species composition of marine herbivores on five species of macroalgae. Twenty replicate individuals of each of seven species of macroalgae were collected from Sydney Harbour, and the abundance of seven species of herbivorous crustacean recorded from each replicate (data from Poore et al. 2000). The data are multivariate because seven response variables (the species) were measured from each of the samples.\nWe could reduce this into a univariate dataset by calculating the 4950 (100*99/2) pairwise differences between samples, and use these differences to visualise patterns in the data (e.g, as we did in our multi-dimensional scaling example) or test hypotheses about groups of samples by resampling these differences.\nHere, we will use mvabund to contrast species composition across habitats using models that are appropriate for the mean-variance relationships and allowing us to check assumptions of those models. Running the analysis \nFirst, install and load the mvabund package.\nlibrary(mvabund) Your data should be formatted so that each sample is a row and each variable is a column. Download the herbivore specialisation data set, and import into R to see the desired format.\nHerbivores \u0026lt;- read.csv(file = \u0026quot;Herbivore_specialisation.csv\u0026quot;, header = TRUE) The first two columns are categorical variables that label the samples as coming from each of the five habitats or as being collected during the day or the night. The third column is the replicate number per combination of habitat and day/night. The fourth column is the biomass of the habitat sampled and the rest of the columns are the counts of each herbivore species in each sample.\nWe will now use the just the abundance data (in columns 5 to 11) and convert it to an mvabund object format used by the mvabund package.\nHerb_spp \u0026lt;- mvabund(Herbivores[,5:11]) We can have a quick look at the spread of our data using the boxplot function.\npar(mar=c(2,10,2,2)) # adjusts the margins boxplot(Herbivores[,5:11],horizontal = TRUE,las=2, main=\u0026quot;Abundance\u0026quot;) It looks like some species of marine herbivores (e.g. Ampithoe ngana) are much more abundant and variable than others (e.g. Cymadusa munnu). It’s probably a good idea to check our mean-variance relationship then! We can do this using the meanvar.plot function:\nmeanvar.plot(Herb_spp) You can clearly see that the species with high means (on the x axis) also have high variances (y axis).\nWe can deal with this relationship by choosing a family of GLMs with an appropriate mean-variance assumption. The default family used by mvabund when fitting multivariate GLMs is negative binomial which assumes a quadratic mean-variance relationship and a log-linear relationship between the response variables and any continuous variables. In this example, we only have categorical variables so that one’s not too important. If you are unsure of these relationships, don’t worry, we can check our model fit later.\nNow let’s get back to our research questions. Are there differences in the species composition of the seven marine herbivores sampled? Do some of them specialise on particular types of algae while others are more generalised feeders? Which species? Let’s start by eyeballing the data.\nThere is a ‘quick and dirty’ built-in plotting function in the mvabund package that allows us to contrast transformed abundances to the predictor variables of our choice. To contrast abundances against habitat, we would use:\nplot(Herb_spp~as.factor(Herbivores$Habitat), cex.axis=0.8, cex=0.8) ## ## PIPING TO 2nd MVFACTOR Alternatively, we can include the argument transformation=\"no\" to look at the raw abundance data. Because this plot is based on the base plotting language in R, you can add extra arguments to customise the graph. We have made the axis text (cex.axis=0.8) and the symbols (cex=0.8) smaller so that we can better see what’s going on.\nIt is quite a messy graph but a couple of things jump out at us. It looks like the herbivore Ampithoe ngana is very abundant and will eat just about anything. On the other hand, Cymadusa munnu and Plumithoe quadrimana are quite rare. Ampithoe ngana, A. caddi, A. kava and Exampithoe kutti are generalist feeders whereas Perampithoe parmerong is largely specialised to the two species of Sargassum.\nLet’s now contrast the species composition across algal species to see if the models support our observations.\nThe model syntax below fits our response variable (the mvabund object Herb_spp with the 100 counts of 7 species) to the predictor variable Habitat (type of algae).\nmod1 \u0026lt;- manyglm(Herb_spp ~ Herbivores$Habitat, family=\u0026quot;poisson\u0026quot;) \n Assumptions to check \nBefore we examine the output, we need to check our model assumptions. We can use the plot function to generate a plot of residuals.\nplot(mod1) If the model is a good fit, we should see a random scatter of points. What we don’t want to see is a relationship, either linear or curvilinear, or a fan shape. This could mean that one of our assumptions was wrong: either our mean-variance relationship was wrongly specified, or our assumed relationship between our response and predictors was incorrect. Or, we could have missed a key explaining variable in our model which leaves a lot of unexplained variance.\nIn this example, we see a clear fan shape in the residual plot, this means we have misspecified our mean-variance relationship. We can use the family argument to choose a distribution which is better suited to our data. For count data which does not fit the 'poisson distribution, we can use the negative_binomial distribution.\nmod2 \u0026lt;- manyglm(Herb_spp ~ Herbivores$Habitat, family=\u0026quot;negative_binomial\u0026quot;) plot(mod2) ## Warning in default.plot.manyglm(x, res.type = res.type, which = which, caption = ## caption, : Only the first 7 colors will be used for plotting. This residual plot is much better, there is now no discernible fan shape and we will use this model for all further analysis.  Interpreting the results \nWe can test the multivariate hypothesis of whether species composition varied across the habitats by using the anova function. This gives an analysis of deviance table where we use likelihood ratio tests and resampled p values to look for a significant effect of Habitat on the community data.\nanova(mod2) ## Time elapsed: 0 hr 0 min 7 sec ## Analysis of Deviance Table ## ## Model: Herb_spp ~ Herbivores$Habitat ## ## Multivariate test: ## Res.Df Df.diff Dev Pr(\u0026gt;Dev) ## (Intercept) 99 ## Herbivores$Habitat 95 4 625.2 0.001 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## Arguments: ## Test statistics calculated assuming uncorrelated response (for faster computation) ## P-value calculated using 999 iterations via PIT-trap resampling. We can see from this table that there is a significant effect of Habitat (LRT = 625, P = 0.001), meaning that the species composition of herbivores clearly differs between the species of algae that they are found on.\nTo examine this further, and see which herbivore species are more likely to be found on which algal species, we can run univariate tests for each species separately.\nThis is done by using the p.uni=\"adjusted\" argument in the anova function. The “adjusted” part of the argument refers to the resampling method used to compute the p values, taking into account the correlation between the response variables. This correlation is often found in ecological systems where different species will interact with each other, competing with or facilitating each others’ resource use.\nanova(mod2, p.uni=\u0026quot;adjusted\u0026quot;) ## Time elapsed: 0 hr 0 min 7 sec ## Analysis of Deviance Table ## ## Model: Herb_spp ~ Herbivores$Habitat ## ## Multivariate test: ## Res.Df Df.diff Dev Pr(\u0026gt;Dev) ## (Intercept) 99 ## Herbivores$Habitat 95 4 625.2 0.001 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Univariate Tests: ## Peramphithoe_parmerong Ampithoe_caddi ## Dev Pr(\u0026gt;Dev) Dev Pr(\u0026gt;Dev) ## (Intercept) ## Herbivores$Habitat 148.716 0.001 91.659 0.001 ## Ampithoe_kava Ampithoe_ngana ## Dev Pr(\u0026gt;Dev) Dev Pr(\u0026gt;Dev) ## (Intercept) ## Herbivores$Habitat 85.366 0.001 90.221 0.001 ## Cymadusa_munnu Exampithoe_kutti ## Dev Pr(\u0026gt;Dev) Dev Pr(\u0026gt;Dev) ## (Intercept) ## Herbivores$Habitat 21.452 0.001 107.254 0.001 ## Plumithoe_quadrimana ## Dev Pr(\u0026gt;Dev) ## (Intercept) ## Herbivores$Habitat 80.575 0.001 ## Arguments: ## Test statistics calculated assuming uncorrelated response (for faster computation) ## P-value calculated using 999 iterations via PIT-trap resampling. Even after adjusting for multiple testing, there is an effect of habitat on all species.\nSo far, we have considered just one predictor variable of habitat. By altering the formula in mvabund, we can test more complex models. For example, to fit a model with both habitat and day or night, we would use:\nmod3 \u0026lt;- manyglm(Herb_spp ~ Herbivores$Habitat*Herbivores$DayNight, family=\u0026quot;negative_binomial\u0026quot;) anova(mod3) ## Time elapsed: 0 hr 0 min 23 sec ## Analysis of Deviance Table ## ## Model: Herb_spp ~ Herbivores$Habitat * Herbivores$DayNight ## ## Multivariate test: ## Res.Df Df.diff Dev Pr(\u0026gt;Dev) ## (Intercept) 99 ## Herbivores$Habitat 95 4 625.2 0.001 *** ## Herbivores$DayNight 94 1 6.2 0.581 ## Herbivores$Habitat:Herbivores$DayNight 90 4 25.4 0.474 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## Arguments: ## Test statistics calculated assuming uncorrelated response (for faster computation) ## P-value calculated using 999 iterations via PIT-trap resampling. You can see that the species composition of herbivores varies with habitat, but not between day and night.  Communicating the results \nWritten. If we were writing a paper about the differences in habitat use by marine herbivores, we may write the following: There were different marine herbivores communities on different algal substrates (LRT = 625, P \u0026lt; 0.001). We can be more descriptive about the community differences by using a graphical representation of our results.\nVisual. Multivariate data are best visualised by ordination plots. See the boral package for model based ordination. To get started, watch this video.  Further help \nThis method was created by UNSW’s Ecostats research group, you can keep up with their latest research on their blog. They have been updating the mvabund package with many new exciting features, including block resampling and fourth corner analyses.\nWang, Y, U Naumann, ST Wright \u0026amp; DI Warton (2012) mvabund - an R package for model-based analysis of multivariate abundance data. Methods in Ecology and Evolution 3: 471-474. \nAuthors: Rachel V. Blakey \u0026amp; Andrew Letten Last updated:\n## [1] \u0026quot;Mon Jan 24 12:47:34 2022\u0026quot;  "
},
{
	"uri": "/statistics/meta-analysis/",
	"title": "Meta-Analyses",
	"tags": [],
	"description": "",
	"content": "  Meta-analyses are increasingly used in ecology, evolution and the environmental sciences to find general patterns among many studies, settle controversies among conflicting studies and to generate new hypotheses. These tutorials provide an introduction to running meta-analyses with the R package metafor.\n Meta-analyses 1: Introduction and calculating effect sizes\n Meta-analyses 2: Fixed effect and random effect models\n Meta-analyses 3: More complex models  "
},
{
	"uri": "/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Welcome to Environmental Computing Quantitative tutorials for the environmental sciences Getting started with R, data manipulation, graphics and statistics Students and researchers in the environmental sciences require a wide range of quantitative skills in analytical and data processing software, including R, geographic information systems (GIS) and the processing of remotely sensed data. There is increasingly a need to ensure transparency of data processing supported by statistical analyses to justify conclusions of scientific research and monitoring for management and policy. This site is a brief introduction to techniques for data organisation, graphics and statistical analyses.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]